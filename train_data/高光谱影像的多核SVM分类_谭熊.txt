

 35   2 
2014  2 











Vol. 35 No. 2
Feb． 2014

Chinese Journal of Scientific Instrument

*
 SVM 

（ 1． 


1，
2
1
1
1
 ， ， ，

 450002； 2．  

 330000）

： 。

。 SVM 。，
， SVM ，
。 AVIＲIS  PHI  2 ， SVM 。
： ；  SVM； 
： TP751

： A

： 420． 2099

Multiple kernel SVM classification for hyperspectral images
Tan Xiong1，2 ，Yu Xuchu1 ，Qin Jinchun1 ，Wei Xiangpo1
（ 1． Institute of Surveying and Mapping，Information Engineering University，Zhengzhou 450002，China；
2． Jiangxi Province Key Lab for Digital Land，East China Institute of Technology，Nanchang 330000，China）

Abstract： Support vector machine is a typical kernel method，which has been widely applied in hyperspectral image processing． However，because of the characteristics of hyperspectral image data，the classification based on single
kernel learning model has some limitations． In this paper，a hyperspectral image classification method based on multiple kernel SVM is proposed． The multiple kernel function is formed with the linear weighted combination of the single
kernel functions． Then，the weights are calculated through solving the standard SVM optimization problem iteratively
starting from the original problem of simple multiple kernel learning model． Finally，a series of two-class classifiers are
used to achieve the multi-class classification． The experiments on the AVIＲIS and PHI images were performed，and the
results prove the advantage of the hyperspectral image classification method based on multiple kernel SVM．
Keywords： hyperspectral image； multiple kernel SVM； classification
［2-3］

、

1





。

，，
，。


［1］
 。

，“Hughes 
”。，（ support vecter

，

machine，SVM） ，

，。

，
“Hughes ”。 SVM ，

、、、、
、、、、

 Fisher （ kernel fisher discriminant analysis，
KFDA） ［4］、     （ kernel principal cemponent a-

，、、

nalysis，KPCA） ［5-6］、      （ generalized discrimi-

。、、

： 2013-06

Ｒeceived Date： 2013-06

* ： （ 41201477） 



406









nant analysis，GDA） ［7］、       （ kernel inde-

n

w，
b，
ξ

［9-11］

（ kernel fuzzy C-neeans clustering，KFCM）

（ Gaussian process，GP）

1
2
‖w‖ + C ∑ ξ i
2
i =1

min

pendence component analysis，KICA） ［8］、 C 
［12］

35 



s． t．

。

x ） + b） ≥ 1 － ξ
； i = 1，
2，…，n
{ξy （≥w·φ（
0
i

i

i

i

（ 1）

，
、，
，

                 
：

，
。，
［13］

，

α

，



s． t．

，，
。
、
、
。，
。（ quadratic constrained
quadratic programming，QCQP ） ［14］、       
（ like sequential minimal optimization， SMO） ［15-16］、
     （ Semi-infinite linear programming，SILP ）
［17-18］



 （ simple multiple kernel leaming，

SMKL） ［19］。
。
，
 SMKL 
， SVM（ multiple kernel SVM，MKSVM） 

{

n

1
2

max －

。

2
2． 1

 SVM 
SVM 

j =1

， VC 

i =1

∑α

∑α y
i

= 0

i

i =1

i

i =1

（ 2）

n

； i = 1，
2，…，n

0 ≤ αi ≤ C

： k（ x i ，x j ）  Mercer ，C 
。、
（ polynomial kernel function，POLY） 、       
（ Gaussian radial basis function，GＲBF ）  Sigmoid  
。
2． 2

MKSVM 
 Mercer ， K1  K2  X × X

n
，X  Ｒ ，：

1） K（ x，z） = K1 （ x，z） + K2 （ x，z）
2） K（ x，z） = aK1 （ x，z）
 X × X  M ， 1）  2） 
：
M

M

∑d

K（ x，z） =

m =1

m

K m （ x，z） ，d m ≥ 0，∑ d m = 1 （ 3）
m =1

（ 3） ，
， K m ，M 
，d m 。
SMKL ［20］ ：
min

w m，
b，
d
ξ，

SVM ，


n

∑ ∑ α i α j y i y j k（ x i ，x j ） +

， SVM
， MKSVM 

n

s． t．

， 2 
。

M

1
2

{

1

∑d
m =1

n

2
‖w m ‖ H + C ∑ ξ i
m

m

i =1

M

yi （ ∑ wm ·φ（ xi ） + b） ≥ 1 － ξi
m =1

； i = 1，
2，…，n

ξi ≥ 0
M

∑d

m

= 1，d m ≥ 0

m =1

（ 4）

， T = ｛ （ x1 ，y1 ） ，
（ x2 ，y2 ） ，…，（ x n ，y n ） ｝ ， x i ∈ χ = Ｒ n ，

（ 4） ， d m ：

y i ∈Y = ｛ + 1，－ 1｝ ，n ，

{

 φ（ x i ） ， x i  χ 
 F ， ξ i ， SVM 
：

min J（ d）
d

（ 5）

M

s． t．

∑d
m =1

J（ d） =

m

= 1，d m ≥ 0



2 
M

 ：  SVM 

n

 min 1 ∑ 1 ‖w m ‖2H + C ∑ ξ i
i =1
 w ，b，ξ 2 m = 1 d m
M
 s． t． y （
2，…，n）
i ∑ w m ·φ（ x i ） + b） ≥ 1 － ξ i （ i = 1，

m =1
ξ ≥ 0
m

m

（ 12）
d tm + γ t D t → d m t + 1
： γ t ，； D t
。
，MKSVM ：
MKSVM ：

i

（ 6）
（ 5）  J（ d）  SVM 
， d m ，
 J（ d） ，：
1
2

L（ w m ，b，ξ，α，υ） =
n

M

n

∑
m =1

1
2
‖w m ‖ H + C ∑ ξ i +
dm
i =1
m

M

∑α （ 1
i

－ ξi － yi （

i =1

m

·φ m （ x i ） + b） ） +

m =1

∑υ ξ
i

（ 7）

i

i =1

： α i 、υ i 。
（ 7）  w m 、b、ξ ，：

 w L（ w m ，b，ξ，d，α，υ，λ，η） = 1 w m －
dm

 n
∑ αi yi φm （ xi ） = 0
（ 8）
 i =1
n

 b L（ w m ，b，ξ，d，α，υ，λ，η） = ∑ α i y i = 0
i =1

 L（ w ，b，ξ，d，α，υ，λ，η） = C － α － υ = 0
ξ
m
i
i
m

（ 8） （ 7） ：
max －
α

s． t．

{

1
2

n

n

M

∑∑α α y y ∑d
i

j =1

i

j

i

j

i =1

m

k m （ x i ，x j ） +

m =1

= 0

i

；
Step2：  t ： （ 1）  k（ x i ，
x j ）  SVM  J（ d） ；
Step3： （ 11） 、 D t 
 γt ；
Step4： （ 12）  d tm+1 ， d tm+1 

∑α

i =1

i

i =1

（ 9）

Step2 ～ Step4 。
KKT 
DG） ，
（ duality gap，
DG ：
，Δd 。
，
n

0 ≤ αi ≤ C

i =1

n

∑d

m

k m （ x i ，x j ） 

m =1

2． 3

M

∑∑α
j =1

*
i

i =1

MKSVM 

，：
J（ d） =

*
α j y i y j ∑ d m k m （ x i ，x j ） +
m =1

*
i

k

： K         ； J k （ d）   k   
SVM 。 SVM 
， J（ d） ：

（ 10）

1
J
=－
2
d m

i =1

*
（ 10）  α  d m ， J（ d）  d m 

：
J（ d m ）
1
=－
2
d m

（ 14）

∑ J （ d）

n

∑α

（ 13）

m =1

k∈K

， d m ， J（ d） ：
1
2

*
*
α j y i y j ∑ d m K m （ x i ，x j ） ≤ ε

OAA） （ one-against-one，OAO） 。 k
，OAA  k ； OAO  k（ k －

*

J（ d） = －

j =1

*
i

： ε 。

 SVM 。 α （ 9） 
n

M

∑∑α
i =1

j =1

n

 J（ d） ，

M

n

n

max∑ ∑ α *i α *j y i y j K m （ x i ，x j ） －
m

1） /2 。 MKSVM ，
， MKSVM 

； i = 1，
2，…，n

（ 9）  k（ x i ，x j ） =

；
Step5： ，，

 SVM ，
       ，       （ one-against-all，

n

n

∑α y

2，…，M） ，M
Step1：  d m ： d1m = 1 / M，（ m = 1，

n

∑w

407

n

n

∑∑∑α
k∈K

i =1

*
i，k

*
α j，k y i y j K m （ x i ，x j ）

（ 15）

j =1

*
*
： α j，k （ α i，k ）  k  j（ i）

。
n

n

∑∑α
j =1

*
i

*
α j y i y j k m （ x i ，x j ）

（ 11）

i =1

2． 4

MKSVM 
 MKSVM ，

（ 11）  J（ d） 。
 Mercer ， J（ d） 
， J（ d） ，

    。 ，           
（ minimum noise fraction，MNF） 

 d ：

，。 MKSVM 

、，，



408









35 



－4
－4
iter max = 200。
0． 01，
Δσ = 10 ，
λ = 10 ，

 1 。

 1

3． 2

 1992  6  AVIＲIS 
 Indiana （ Indian Pines image） ，
 145 pixel × 145 pixel， 20 m，
 400 ～ 2 500 nm， 224 ，
33、
97  161  220 。
 1、
 2（ a） 、（ b） ，
 1 。

1

MKSVM 

Fig． 1 Flowchart of the MKSVM hyperspectral image
classification scheme
2

AVIＲIS 

Fig． 2 AVIＲIS false color image and the reference data

3



1

 SVM 
，，
（ POLY） 

AVIＲIS 

Table 1 AVIＲIS image sample information










54

27

27

1



SVM  MKSVM 

2



1 434

100

1 334

  。            Intel Corei5-

3



834

84

750

4



234

117

117

5

 / 

497

50

447

6

 / 

747

75

672

2410M CPU 2． 3 GHz、ＲAM 4． 0 GB， Windows
7（ 64 ） 、MATLAB 2012b。
3． 1


，
 2 ： 

； 
。 2 ，


7

 / 

26

13

13

8



489

49

440

 ＲBF  POLY ，
：

9



20

10

10

（ 16）

10



2 468

100

2 368

（ 17）

11



968

97

871

12



614

62

552

13

--

380

38

342

14



212

106

106

15



1 294

100

1 194

16



95

48

47

2

2

k（ x，z） = exp（ － ‖x － z‖ /2σ ）
k（ x，z） = （ x·z + 1）

p

： σ ，p 。
MKSVM  C、

 σ、
 p  d m 。
，
， 1 / M，
M ，
C
－4

－3

4

10 ，
…，
10 ｝ ，
σ 
｛ 10 ，
p ｛ 1，
｛ 0． 2，
0． 4，
…，
2． 0｝ ，
2，
3｝ 。
 SimpleMKL toolbox 

 AVIＲIS 

 d m ； C 

。，
。 MNF ，

4

， 10 ； σ  p 。
： ε =



2 

 ：  SVM 

409

 13 ，
， 2 。

，
。
2

AVIＲIS  MKSVM 

Table 2 Ｒesult of MKSVM classification for AVIＲIS image
 / s



OAO

OAA


OAO

OAA

 （ % ）
OAO

OAA

ＲBF

339． 9

49． 3

6 315

4 224

91． 17

90． 11

POLY

24． 2

18． 2

2 095

1 455

85． 19

78． 62

ＲBF + POLY 336． 7

45． 3

6 293

4 224

91． 22

90． 91

    MKSVM          ，
SVM ， C  10 4 ， σ 

3

PHI 

Fig． 3 PHI gray image and the sample distribution
4

PHI 

Table 4 HPI image sample information


1




870



2

3

4

  
234 1 176 453

5

6

7

8


560


584


315


255

 p ， 3
，
。
3

。，
。 MNF ，

AVIＲIS  SVM 

Table 3 Ｒesult of SVM classification for AVIＲIS image
 / s

SVM 



 PHI 

（ % ）

 5 ，
 5 ，

σ

OAO

OAA

OAO

OAA

OAO

OAA

0． 2

9． 2

283． 0

720

803

89． 88

89． 59

0． 4

22． 5

61． 5

589

558

88． 11

88． 22

0． 6

42． 1

226． 2

531

508

87． 76

88． 68

0． 8

95． 8

81． 8

479

537

88． 39

88． 56

1． 0

233． 6

227． 5

458

549

87． 31

87． 94

1． 2

317． 6

147． 1

460

587

87． 65

87． 02

1． 4

530． 9

69． 7

437

607

88． 22

86． 56

1． 6

416． 0

234． 2

437

642

88． 62

85． 94

1． 8

384． 8

76． 6

429

666

88． 51

85． 13

2． 0

790． 8

66． 9

426

680

88． 28

84． 11

p

OAO

OAA

OAO

OAA

OAO

OAA

1

653． 3

172． 6

427

711

84． 85

75． 41

 C  10 ， σ 
 p ， PHI  SVM  6

2

819． 9

9 998． 2

422

552

87． 08

86． 85

，                  

3

303． 3

29 791

417

504

87． 19

87． 08

。

。
5

PHI  MKSVM 

Table 5 Ｒesult of MKSVM classification for PHI image
 / s


ＲBF



（ % ）

OAO

OAA

OAO

OAA

OAO

OAA

7． 9

2． 9

592

426

94． 70

94． 55

POLY

3． 8

3． 0

208

365

93． 82

92． 57

ＲBF + POLY

9． 1

2． 6

592

426

94． 70

94． 55

4

3． 4
3． 3

 2



 PHI-1307  2009 

 2  3 ：  ＲBF-POLY
                 （ ＲBF +

5 ，
 1 m， 130 ，

POLY-MKSVM） ，
 91． 22% ， 90． 91% 。

5 nm， 400 ～ 1 000 nm， 616  × 731

ＲBF  SVM（ ＲBF-SVM） 89． 88%  89． 59% 

。
 3 。，

     POLY     SVM （ POLY-SVM ）
81． 79%  87． 08% 。，

， 4 。

POLY ， POLY-SVM 



410





，； 
 6 PHI  SVM 
Table 6 Ｒesult of SVM classification for PHI image
 / s
OAA
 σ OAO
0． 2
1． 5
18． 3





35 

。
，

 ＲBF-SVM 。

SVM 




OAO
OAA

（ % ）
OAO
OAA

，，

。



146

162

94． 52

94． 07

0． 4

28． 3

327． 4

117

97

94． 30

92． 92

0． 6

6． 2

154． 6

104

86

94． 67

93． 42

0． 8

8． 5

153． 2

102

90

94． 57

93． 47

1． 0

2． 1

67． 1

94

87

93． 82

93． 82

YU X CH，
FENG W F，
LIN L X． Hyperspectral remote sens-

1． 2

3． 2

2 244． 6

95

94

94． 05

93． 97

ing———A new opportunity for surveying and mapping［J］．

1． 4

6． 9

500． 4

97

99

94． 40

94． 17

1． 6

0． 9

254． 3

99

101

94． 27

94． 10

1． 8

3． 9

54． 1

96

101

94． 30

94． 02

2． 0

0． 9

92． 5

93

109

94． 17

93． 92

 p OAO

OAA

OAO

OAA

OAO

OAA

［1 ］ ，，． ———
2006，
23（ 2） ： 101-105．
［J］． ，

Journal of Zhengzhou Institute of Surveying and Mapping，
2006，
23（ 2） ： 101-105．
［2 ］ ，，，． 
［J］． ，

1

27． 7

129． 4

93

294

93． 95

83． 15

2013，
30（ 3） ： 279-283．

2

8． 0

308． 4

95

91

94． 25

93． 45

TAN X，YU X CH，ZHANG P Q，et al． A classification al-

3

70． 7

1 130． 2

89

90

94． 60

93． 32

gorithm for hyperspectral images based on fuzzy mixed
pixel decomposition［J］． Journal of Geomatics Science and

 2  5  6 ，ＲBF + POLY-MKSVM 
 SVM ，

Technology，
2013，
30（ 3） ： 279-283．
［3 ］ ，，，． 

，。，
，ＲBF + POLY-MKSVM       ，

2008（ 10） ： 1-4．
［J］． ，

 9． 1 s  2． 6 s，，
 ＲBF-SVM  6． 2 s  500． 4 s   POLY-SVM 

ment and application of hyperspectral ＲS technology［J］．

70． 7 s 1130． 2 s，。
，：
1）  MKSVM ，ＲBF + POLY-MKSVM 
 ＲBF-MKSVM ， POLYMKSVM  ；      ＲBF-MKSVM    
， POLY-MKSVM 。
2）  SVM ，MKSVM 
，
。
3）  MKSVM  SVM ，

。

4



YANG G P，YU X CH，FENG W F，et al． The developBulletion of Surveying and Mapping，
2008（ 10） ： 1-4．
［4 ］ ，，，．  Fisher 
     ［J］．    ，2008，12 （ 4 ） ：
579-585．
YANG G P，YU X CH，CHEN W，et al． Hyperspectral remote sensing image classification based on kernel fisher
discriminant analysis［J］． Journal of Ｒemote Sensing，
2008，
12（ 4） ： 579-585．
［5 ］ ，． 
［J］． ，2009 （ 3） ：
41-44，
49．
SHEN Z Q，TAO J B． Hyperspectral remote sensing image
feature extraction based on fuzzy kernel principal component analysis［J］． Ｒemote Sensing for Land ＆ Ｒesources，



 MKSVM 
。

2009（ 3） ： 41-44，
49．
［6 ］ ，，．  KPCA 
2011，
40（ 6） ： 847-851．
［J］． ，
WANG Y，GUO L，LIANG N． A dimensionality reduction
method based on KPCA with optimized sample set for hy-

，

perspectral image ［J］． Acta Photonica Sinica，2011，

，
 SVM ，

40（ 6） ： 847-851．

。 AVIＲIS 
PHI ，MKSVM 

［7 ］ ，，，． 
     ［J］．        ，2008，
34（ 3） ： 59-63．

2 



 ：  SVM 

YANG G P，YU X CH，ZHOU X，et al． Hyperspectral im-

［15］

411

BACH F． Consistency of the group Lasso and multiple

age feature extraction based on generalized discriminant

kernel learning［J］． Journal of Machine Learning Ｒe-

analysis［J］． Journal of Dalian Maritime University，
2008，

search，
2008（ 9） ： 1179-1225．

34（ 3） ： 59-63．
［8 ］ ．  ICA 

［16］ BACH F，LANCKＲIET G，JOＲDAN M． Multiple kernel
learning，conic duality，and the SMO algorithm［J］． Pro-

2009，
［J］． ： ，

ceedings of the 21st International Conference on Machine

33（ 4） ： 772-775．

Learning，
2004： 41-48．

XIE Q L． Feature selection using KICA combining class

［17］ SONNENBUＲG S，ＲTSCH G，SCHFEＲ C，et al． Large

separability and genetic algorithm［J］． Journal of Wuhan

scale multiple kernel learning［J］． Journal of Machine

University of Technology： Transportation Science ＆ Engineering，
2009，
33（ 4） ： 772-775．
［9 ］ ，，．  C 
2010，
31（ 7） ： 1657-1663．
［J］． ，

Learning Ｒesearch，
2006，
7（ 1） ： 1531-1565．
［18］ ZIEN，ONG C S． Multiclass multiple kernel learning［J］．
In Proceedings of the 24th International Conference on
Machine Learning （ ICML 2007） ，
2007： 1191-1198．

KANG J Y，JI ZH CH，GONG CH L． Kernelized fuzzy

［19］ ＲAKOTOMAMONJY A，BACH F，CANU S，et al． More

C-means clustering algorithm and its application［J］． Chi-

efficiency in multiple kernel learning［J］． Proceedings of

nese Journal of Scientitlc Instrument，2010，3l （ 7 ） ：

the 24th Annual International Conference on Machine

1657-1663．
［10］ ，，，． 

Learning （ ICML 2007） ，
2007： 775-782．
［20］ ＲAKOTOMAMONJY A，BACH F，CANU S，et al． Simple

       ［J］．      ，2009，

MKL［J］． Journal of Machine Learning Ｒesearch，2008：

30（ 10） ： 2226-2231．

1-34．

XU H X，
LIU G H，
ZHOU D W，
et al． Soft sensor modeling
based on modified kernel fuzzy clustering algorithm［J］． Chi-


（ ） ，   2008 、2011

nese Journal of Scientific Instrument，2009，30 （ 10 ） ：

   ，

2226-2231．

，   

［11］ ，．  C-
2012，
33（ 9） ： 2016-2021．
［J］． ，
ZHAO CH H，QI B． Hyperspectral image classification
based on fuzzy kernel weighted C-means clustering［J］．

 、 
。
E-mail： kjadetx@ 163． com
Tan Xiong （ Corresponding author ） received bachelor and

Chinese Journal of Scientific Instrument，2012，33 （ 9 ） ：

master degrees both from Information Engineering University in

2016-2021．

2008 and 2011，respectively； now，he is a Ph． D． candidate in

［12］ ，，． 
2012，
［J］． ： ，
46（ 7） ： 1295-1300．
YAO F T，QIAN Y T，LI J M． Semi-supervised learning

Information Engineering University，and majors in hyperspectral
image remote sensing and pattern recognition．
， 1983、1990  1997 
、

based gaussian processes for hyperspectral image classifi-

，、，

cation［J］． Journal of Zhejiang University： Engineering

           、  

Science，
2012，
46（ 7） ： 1295-1300．

。

［13］ ，，，． ［J］． 
2010，
36（ 8） ： 1037-1050．
，
WANG H Q，SUN F CH，CAI Y N，et al． On multiple ker-

E-mail： xuchu_yu@ sina． com
Yu Xuchu received bachelor，master and doctor degrees all
from Institute of Surveying and Mapping in 1983，1990 and 1997，

nel learning methods［J］． Acta Auto Matica Sinica，
2010，

respectively； now，he is a professor and Ph． D． supervisor in In-

36（ 8） ： 1037-1050．

formation Engineering University； his main research direction is

［14］ LANCKＲIET G，
CＲISTIANINI N，
ELGHAOUI L，
et al． Learning the kernel matrix with semi-definite programming［J］． Journal of Machine Learning Ｒesearch，
2004（ 5） ： 27-72．

photogrammetry and remote sensing，and pattern recognition．