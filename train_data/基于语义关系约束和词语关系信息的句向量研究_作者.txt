：2018-04-12 08:50:45
：http://kns.cnki.net/kcms/detail/51.1196.TP.20180412.0813.046.html

————————————————————————————————————————————————




，



 

DOI

10.3969/j.issn.1001-3695.2018.01.0029



《》 2019  36  7 



、，
 PV-DM （RISV）
， PV-DM 
，，
，（RCM），
， RISV 
。， RISV 。



；RISV ；PV-DM ；；



（1990-）
，，，，､
（yiyele@126.com）
；（1967-）
，，，，
､､，．



TP391



http://www.arocmag.com/article/02-2019-07-025.html



2018  1  17 



2018  3  8 



2018  4  12 



, . [J/OL]. 2019, 36(7). [201804-12]. http://www.arocmag.com/article/02-2019-07-025.html.

 36  7 

Vol. 36 No. 7


Application Research of Computers



Online Publication


，



( , 230009)


：、， PV-DM 

（RISV）， PV-DM ，
，，（RCM）
，， RISV 
。， RISV 。
：；RISV ；PV-DM ；；
：TP391

doi: 10.3969/j.issn.1001-3695.2018.01.0029

Sentence vector based on semantic relationship constraints and word relationship information
Xia Xiaoqiang, Shao Kun
(School of Computer & Information, Hefei University of Technology, Hefei 230009, China)
Abstract: In view of the fact that the existing sentence vector learning method can not well learn the relational knowledge
information and express the complicated semantic relation, this paper proposed a relational information sentence vector model
(RISV) based on the PV-DM model and the relational information model. This model used the PV-DM model as the basic model
of sentence vector training, and then added the knowledge constraint of relational information to make the improved model can
learn the relationship between the words in the text and uses the RCM model as Pre-training model to further integrate the
information of the semantic relationship constraints, and finally validates the validity of the RISV model in two tasks: document
classification and short text semantic similarity. The experimental results show that sentence vectors learned by RISV model
can better represent the text.
Key words: sentence vector; RISV Model; PV-DM Model; Relationship information; Pre-training

0

,。Q



Liu  15  SWE [8]， skip-gram 

，
[1]

。 2013  Mikolov  
word2vec ，

POS Tagging[2]

[3]

、 、

[4]

（，）。Xu
[9] Skip-gram ，
 RC-NET。2016  Nguyen [10] Skip-gram

 。

， DLCE ，

，，，

。

，

，Le [11]  word2vec 

。

paragraph id， doc2vec ，

。

。

[5] word2vec ， TF-IDF 

 [12]，

。[6]

 TF-IDF ，[13]，

，、，

 doc2vec 。

。[7]

，



，，Liu  SWE [8] DLCE 

——————————
：2018-01-17；：2018-03-08
：（1990-），，，，､（yiyele@126.com）；（1967-），，
，，､､，．



[10]

 36  7 

，：

， word2vec ，

1.2 RISV 

，。 DLCE 

，

，

，“”，“”“

，（SIMLEX999，

”，“”“”，“”

MEN3000，WS353），，SWE 

“” ，“”，

，

“”“”，

。， SWE 

， Word2vec 

[14]



，，

（RISV）， SWE ，

，

 RISV  PV-DM ，

。

 RCM 

（RCM），

（RWE） CBOW 

。，

，，

。

， PV-DM ，
           （ relational Information sentence



1

vector,RISV），RISV ：

1.1 RWE 

C

，(h,r,t)，

Lrisv   (  log p( wi | Cont ( wiicc , d ))  
i 1 d D

 log p(w | h  r )) （3）

 Rwi

i

r  t ，(vegetable, _hyponymy,

：d  paragraph id ，D  paragraph id 。

tomato)。，。

cont ( wiicc , d )  wi  paragraph id 。

(h,r,t)，， h+r≈t，
h+r  t ，。

 Negative Sampling  RISV ，

 t (h,r,t)，

（u,wi）， u  E ，

，。

。

 CBOW ，，
。

1, wi  E
0, wi  E

 ( wi | u )  {

             （ relational information word
embedding）。：

（4）

 RISV ，


C

Lriwe   (log p( wi | w )  
i 1

i c
i c

 log p(w | h  r ))
i

 Rwi

（1）

C

Lfront   log p( wi | Context ( wiicc , d ))

： CBOW ，
，  ，C 。

p( wi | h  r )  h  r，
 w i ，：



 u   u   ( ( wi | u )   ( X wT u )) X w

exp(e
 )
h  r wi
T
V
 j 1 exp(eh r  wi )

：e h r  e h  e r ， e h  r

w

i

 w i 。

（6）

lw

V ( w)  V ( w)    ( ( wi | u )   ( X wT  u )) u

（7）

j 2

T

p ( wi | h  r ) 

（5）

d D i 1

（2）

：

Xw

，

 ( x)  exp{x} /(1  exp{x}) ， ，V(w)
 e h  er ，

。 L front （4） E 。




 36  7 

，：

C

Lrear  

 log p(w | h  r )


i 1 Rwi

（8）

i

2


，，

，。

，：

，

 u   u   ( ( wi | u )   (ehT r u ))eh  r

（9）

e h  e h    ( ( wi | u )   (ehT r u )) u

（10）

e r  e r    ( ( wi | u )   (ehT r u )) u

（11）

， 202363 。 RCM 
‘’ PPDB（），

uU

，，，<X,Y>
  PPDB ，    <Y,X>    。       

uU

Freebase，。 1 。
1

：U ，  ， L rear 
（4） E 。 eh  r 
 e hr

 e h  er 。

RISV  dco2vec ，











202363

PPDB 

PPDB

57829

1583



Freebase

69023

1657





 2 。
 2 

，，，PV-DM 
，，







，，

Anarchism is a political philosophy that advocates self-

。

governed societies based on voluntary institutions.These

 RWE ， RISV 



are often described as stateless societies, although several

，。，RISV 

authors have defined them more specifically as institutions

 paragraph id ，

based on non-hierarchical free associations.

，，

<planning,plans>,<monitoring,monitor>,

PPDB 

 RWE 。

<seemed,suggested>,<pyramidal,pyramid>

1.3 

<The Trail Blazer,is-a,TV Episode>,

，[15]。，
Yu M[14] CBOW ，

<The Trail Blazers,Country of origin,United States of
America>,



。 Yu M ， RCM 

<Playing Guitar,is-a,Book>,

。

<Playing Hardball,is-a,TV Episode>

 Rw  w  R 。
 N ：

1
N

N



2.1.1 
 Reuters Corpus,Volume I(RCV1)[16]，

 log p(w | wi )

（12）

i 1 wRwi



2.1 

 806791 ，，
，。，

p( w | wi )  exp( X wi Vw ) /  exp( X Vw ) ，X，V 
T

T
wi

w

。 RCM 。

， C，E，G  M， C 
，E ，G  M 。
 3 。

 RCM ， RISV 
 3 

， RISV 。，RCM
， L1
 L2 ， semi-superviesed  early
stopping 。 RISV 
，。







C

6000

1000

E

1000

500

G

3000

1000

M

3000

1000



 36  7 

，：

2.1.2 
， 3

RISV

72.12 73.21 72.21 72.94 72.54

RISV + 

72.26 73.29 72.34 72.97 72.63

，， C，E，G  M，

 3 ， RISV  C，E  M

，，

 word2vec  RWE 。

，，，，

。， RISV 

。 1 。

，，。

 1 ，

2.2 

， RISV ，RISV 

2.2.1 

doc2vec ，，

[17]，

，，   0.12 ，。

[18~20]。 5 801 

，，RCV1 

，。

，，

 3 900 ， 1 901 ，

<data,label> SVM ，

 4 076 ，1 725 。

，<x,y>，
SVM  y＇ y ，，
，，。

2.2.2 
。
，
“”“ 0.3％
”，“ 12 ， 5.3％
 1,540 ”“ 12 ， 5％”





，，


，


。，
，，
，1 ，0 
。，



RCM

， 2 。
RISV








（SVM）









（1）






（SVC）

（0）

 1 

 2 

2.1.3 
 word2vec 
tf_idf ， doc2vec  RWE 
 tf_idf 。 RCV1 ，
， SVM，

 2 ，，，
，，
 0  1，1 ，0 。
，<string,label>，
 SVC  p_label  label ，

。 4 。

，，，。
 4 

2.2.3 

（%）


C

E

G

M



 p(precision)，r(recall)
 F1 ， RBF  SVC ，

Word2vec+

67.56 69.23 71.25 65.32 68.21

Word2vec+tf_idf

69.26 69.56 70.24 68.67 69.41

Doc2vec

70.35 70.67 69.25 71.26 70.34

RWE+

71.25 72.34 71.21 72.39 71.72





p

r

F1

RWE+tf_idf

70.35 72.53 72.36 72.25 71.77

Word2vec+

0.6991

0.7123

0.8425

0.7719

，。
 5 



，：

Word2vec+tf_idf

0.7012

0.7621

0.8521

0.8046

Doc2vec

0.6929

0.7235

0.9137

0.8076

RWE+

0.7102

0.7426

0.8969

0.8125

RWE+tf_idf

0.7201

0.7716

0.9123

0.8361

RISV

0.7312

0.7821

0.9237

0.847

RISV+

0.7319

0.7826

0.9314

0.8505

 36  7 

, 2016, 43 (6): 214-217.
[6] , , , .  [J].
, 2015, 32 (10): 2905-2909.
[7] , , . 
 [J]. , 2014, 31 (11): 3333-3336.
[8] Liu Quan, Jiang Hui, Wei S, et al. Learning semantic word embeddings

 5 ，RISV  p,r,F1 

based on ordinal knowledge constraints [C]// Proc of the 53th Annual

 word2vec  RWE 。，

Meeting of the Association for Computational Linguistics. 2015: 1501-1511.

。
2.3 
 RISV ，
。
， 6 ， 6 
SVM ， RISV  RCM 。
 RISV 
。， 4 ，RISV
，，
（RCM），，
RISV ，。

[9] Xu C, Bai Y, Bian J, et al. RC-NET: a general framework for incorporating
knowledge into word representations [C]// Proc of ACM International
Conference on Conference on Information and Knowledge Management.
New York: ACM Press, 2014: 1219-1228.
[10] Nguyen K A, Walde S S I, Vu N T. Integrating distributional lexical contrast
into word embeddings for antonym-synonym distinction [C]// Proc of the
54th Annual Meeting of the Association for Computational Linguistics.
2016: 454-459.
[11] Le Q V, Mikolov T. Distributed representations of sentences and documents
[C]// Proc of the 31st International Conference on Machine Learning. 2014.
[12] Xing C, Wang D, Zhang X, et al. Document classification with distributions
of word vectors [C]// Proc of Asia-Pacific Conference on Signal and

3



Information Processing Association. 2014: 1-5.
[13] Han K K, Kim H, Cho S. Bag-of-concepts: comprehending document

 RWE  RISV ， RWE 

representation through clustering words in distributed representation

，RISV ，，

[EB/OL]. http://dm. snu. sc. kr//static//docs//TR//SNUDM-TR-2015-05. pdf.

，

[14] Yu M, Dredze M. Improving Lexical Embeddings with Semantic

，paragraph id ，，

Knowledge [C]// Proc of Meeting of the Association for Computational

。，RISV ，

Linguistics. 2014: 545-550.

。 RWE  word2vec 

[15] Erhan D, Bengio Y, Courville A, et al. Why does unsupervised pre-training

， RISV ，

help deep learning? [J]. Journal of Machine Learning Research, 2010, 11 (3):

。，

625-660.

，。

：

[16] Lewis D D, Yang Y, Rose T G, et al. RCV1: a new benchmark collection for
text categorization research [J]. Journal of Machine Learning Research,
2004, 5 (2): 361-397.

[1] Mikolov T, Sutskever I, Chen K, et al. Distributed representations of words
and phrases and their compositionality [C]// Proc of International
Conference on Neural Information Processing Systems. [S. l. ] : Curran
Associates Inc. , 2013: 3111-3119.
[2] Zheng X, Chen H, Xu T. Deep learning for Chinese word segmentation and
POS tagging [C]// Proc of Conference on Empirical Methods in Natural
Language Processing. 2013: 647-657.
[3] Zhang M, Zhang Y, Che W, et al. Chinese Parsing Exploiting Characters
[C]// ACL. 2013: 125-134.
[4] Devlin J, Zbib R, Huang Z, et al. Fast and robust neural network joint models
for statistical machine translation [C]// Proc of Meeting of the Association
for Computational Linguistics. 2014: 1370-1380.
[5] , , .  Word2Vec  [J]. 

[17] Quirk C, Brockett C, Dolan W B. Monolingual machine translation for
paraphrase generation [C]// Proc of Conference on Empirical Methods in
Natural Language Processing. 2004: 142-149.
[18] Annesi P, Croce D, Basili R. Semantic compositionality in tree kernels [C]//
Proc of the 23rd ACM International Conference on Conference on
Information and Knowledge Management. 2014: 1029-1038.
[19] Fernando S, Stevenson M. A semantic similarity approach to paraphrase
detection [C]// Proc of Annual Research Colloquium on Computational
Linguistics. 2008.
[20] Hu B, Lu Z, Li H, et al. Convolutional neural network architectures for
matching natural language sentences [C]// Proc of International Conference
on Neural Information Processing Systems. Cambridge: MIT Press, 2014:
2042-2050.