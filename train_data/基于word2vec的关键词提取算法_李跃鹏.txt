
2015, 6(4): 54–59

·  / TECHNOLOGY ·

 word2vec 
 1,3， 2 ， 1
1., 100190
2., 100083
3.， 100049


： ，；
，。， word2vec 
。 word2vec ；
，。

。
： word2vec；；
doi:10.11871/j.issn.1674-9480.2015.04.007

A Keyword Extraction Algorithm Based on Word2vec
Li Yuepeng1,3, Jin Cui2, Ji Junchuan1
1. Computer Network Information Center, Chinese Academy of Sciences, Beijing 100190, China
2. University of Science and Technology Beijing，Beijing 100083, China
3. University of Chinese Academy of Sciences, Beijing 100049, China
Abstract:	 With the rapid development of deep learning, a major breakthrough has been made to the word
representation of computers, while for a long time the keyword extraction algorithms is based on the
feature of words, and it is not very ideal. In this paper, we present a keyword extraction algorithm based on
word2vec, which is a well known tool for deep learning. Firstly, this algorithm projects all the words into a
more abstract word vector space, then based on the word vectors, it calculates the similarity between words
to cluster all the words in the target article, and the center of the cluster can be selected as the keyword.
According the result of the experiment, this algorithm is better than other algorithms for long articles.
Keywords:	word2vec; keyword extraction; word vector
54

 ： word2vec 



，。
               ，  

，

。

。，

 SVM[6]、 [7] ；

，

K-means、 [8] 。

。

，

，

，。

、、、

、，

。，

，、。

。

，

，，

，

。、

。

； CSDN 

，

，

。

。


，。

1 

 [9]，
 PCA 、Fisher ；

，

 DSNPE[10] (Discriminant

。

Sparse Neighborhood Preserving Embedding)、GSM-

 20  70 ， 30 ，

PAF [11] (Group Sparse Multiview Patch Alignment



Framework) 。

。 ：



(1) （

，，

）；(2) 。

，。

、、



，

，，

，。

。

 [1]  TF-DF 

。

；， [2] 

，

 PAT-tree ，

。

，

，。

； [3] 

，，

 TextRank，

。

，。



， [4] 

google  word2vec。

；
 [5] 

       ，         
word2vec 。
55

，2015, 6 (4)

2 

 f ( w1 ,......, wn −1 , wn ) 。
，，

2.1 word2vec 
 2006  Hinton ，

f ( w1 ,......, wn −1 , wn ) 。
， logistic 

。

。，

，

n-gram ，word2vec 

，

，

。

。

，，

，，

；

。

（Convolutional
Neural Network, CNN）、
（Deep Neural Network, DNN）
  (Restricted Boltzmann Machine, RBM)    
。
， 2012 
 word2vec，
。 bag-of-word  [12]，
 skip-gram  [13]。
，。

 1 n-gram 
Fig.1 n-gram model


。；
“”。
word2vec ，
， n-gram 
。n-gram  n -1
 w1 ,......, wn −1 ， n  wn 
。， D 
， n-gram 
n −1
 A D  w1 ,......, wn −1 

 2 Continue bag of word 
Fig.2 Continue bag of word model

2.2 

P( wn | w1 ,......, wn −1 )。word2vec ，

：（1）

word2vec  P( wn | w1 ,......, wn −1 ) = f ( w1 ,......, wn −1 , wn )，

，

  f ( w1 ,......, wn −1 , wn )           

；（2），

。

。

 1  2 ， n-gram ，

 k-means

 w1 ,......, wn −1  wn 

，

；

。 k-means 

continue bag of word ，

 word2vec 。

56

 ： word2vec 

，，

。，

，

，

 5 。

。，

： ICAS 

。
， 20 ，

，。
：，

10 。 3、

 100 。

5、7、10 。 3 

，。

，：

： F，
 =

； word2vec  F 




、。
：，
。 kmeans 
，，


 3 
1 。
 1 
Table 1 Comparison of the recall rate of 3 algorithms

。，

3

5

7

10

TF-IDF

31.2%

26.5%

25.7%

23.4%

Textrank

34.1%

33.4%

32.9%

32.4%

Word2vec

27.4%

32.0%

35.1%

37.8%



。



 10 ，
。

3 

，
，

 90MB， 4G 

。

 40  180MB 

，，

。

。

，

，，

 TF-IDF ， textrank

。，

， 3 

，

。

：（1），，





：（1），

。（2），，

；（2）

。（3）

，

，，

，

；，，



。（4）

。

，

，，；

，

，

；，
57

，2015, 6 (4)

，

，

。

。，

。，

：（1）

、（

；（2）

），，

；（3）

。

；（4） word2vec 



（ 2 ），

。，

，；（5）

（

 hadoop  mapreduce 

），

。

；

，

，。，



，，

，。

，



；，

。，

，

，

。

。

4 

 word2vec ，

[1]

Yih W, Goodman J, Carvalho V R. Finding advertising

。。

keywords on web pages[C]//Proceedings of the 15th

，

international conference on World Wide Web. ACM,

，

2006: 213-222.

，、

[2] Chien L F. PAT-tree-based keyword extraction for Chinese
information retrieval[C]//ACM SIGIR Forum. ACM,


。

。，
。
：，

1997, 31(SI): 50-58.
[3] Mihalcea R, Tarau P. TextRank: Bringing order into
texts[C]//Proceedings of EMNLP. 2004, 4(4): 275
[4]

[J]. , 2012, 38(01): 1-4.
[5]

，，；
，。

, . 

,,. 
[J]. ,2010,36(19):93-95.

[6]

Zhang K, Xu H, Tang J, et al. Keyword extraction using

，

support vector machine[M]//Advances in Web-Age

，

Information Management. Springer Berlin Heidelberg,

，

2006: 85-96.

，。
，
58

[7]

Uzun Y. Keyword Extraction Using Naïve Bayes[C]//
Bilkent University, Department of Computer Science,

 ： word2vec 
Turkey www. cs. bilkent. edu. tr/~ guvenir/courses/CS550/

[13] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado,

Workshop/Yasin_Uzun. pdf. 2005.

and Jeffrey Dean. Distributed Representations of Words

[8] ,. 

and Phrases and their Compositionality. In Proceedings of
NIPS, 2013.

[J]. ,2011,09:23-27.
[9] Gui, Jie, et al. “How to estimate the regularization
parameter for spectral regression discriminant analysis

：2015  6  6 

and its kernel version?.” Circuits and Systems for
Video Technology, IEEE Transactions on 24.2 (2014):
211-223.
[10] Gui, Jie, et al. “Discriminant sparse neighborhood
preserving embedding for face recognition.” Pattern
Recognition 45.8 (2012): 2884-2893.
[11] Gui, Jie, et al. “Group sparse multiview patch
alignment framework with view consistency for image
classification.” Image Processing, IEEE Transactions on

：，
，，。
E-mail: 908065729@qq.com


：，，

。
E-mail: cuicuijin@163.com

23.7 (2014): 3126-3137.
[12] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey

：，

Dean. Efficient Estimation of Word Representations in

，。

Vector Space. In Proceedings of Workshop at ICLR, 2013.

E-mail: jcji@cashq.ac.cn

59