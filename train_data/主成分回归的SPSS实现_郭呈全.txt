DOI:10.13546/j.cnki.tjyjc.2011.05.003
知 识 丛 林
主成分回归的 SPSS 实现
郭呈全，陈希镇
（温州大学 数学与信息科学学院，浙江 温州 325000 ）
摘
要 ：文 章 结 合 主 成 分 分 析 和 线 性 回 归 分 析 的 原 理 ，利 用 SPSS15.0 的 Descriptives 、Data Re-
duction 、Linear Regression 、Compute Variable 模块的功能 ， 把 主 成 分 回 归 的 每 一 步 计 算 过 程 用 SPSS
展现出来，并且对结果给出 SAS 验证。这不仅使学生更好地掌握主成分回归的相关知识，而且可以培
养学生灵活使用 SPSS 软件。
关键词：共线性；主成分回归；特征值；特征向量；SPSS
中图分类号：O21
文献标识码：A
文章编号：1002－6487 （2011 ）05-0157-03
如今主成份回归方法已经被广泛采用，成为回归分析中解决
0
引言
多重共线性比较有效的方法。
在进行多元线性回归分析时，经常会遇到自变量之间存
λ1≥λ2≥ … ≥λp 为 X'X 的 特 征 根 ，Φ=(φ1，φ2，… ，φp) 为 对 应 的
设 Y= （y1，y2， … ，yn）， 假 设 X 设 计 矩 阵 已 经 中 心 化 ，记
在近似线性关系的现象，这种现象被称为共线性 [1]。 当共线性
标准正交化特征向量。 主成分回归的计算步骤是：
（1 ）为 了 使 结 果 不 受 量 纲 的 影 响 ，先 把 原 始 数 据 进 行 标
严重时， 用最小二乘法建立的回归模型将会增加参数的方
差 ，使 得 回 归 方 程 变 的 很 不 稳 定 ，有 些 自 变 量 对 因 变 量 影 响
准化；
的显著性被隐藏起来，某些回归系数的符号与实际意义不相
（2 ）求 X'X 的特征值和对应的标准正交化特征向量；
符 [2] ，回归方程和回归系数通不过显著性检验。 处理共线性
（3 ）做回归自变量选择。 最大的特征值对应的特征向量
的主要方法有筛选变量法、岭回归法、主成分回归法、偏最小
即为第一主成分的系数，第二大的特征值对应的特征向量即
二乘法等。在文献 [2] 中高惠旋使用 SAS 软件对处理共线性的
为第二主成分的系数，以此类推。 取几个主成分取决于主成
主成分回归方法进行了实现，但是很多人只熟悉 SPSS 操作，
分对因变量的解释程度。 如果前 i 个特征值之和与所有特征
SPSS 没 有 直 接 提 供 主 成 分 回 归 的 模 块 ，文 献 [3] 虽 然 也 提 出
值之和的比达到一定的程度比如 85% 时，就可以认为这些主
使用 SPSS 进行主成分回归，但是他首先使用了筛选变量法，
分就能代替所有的自变量体系。 剔除对应的特征值比较小的
没能真正体现主成分回归方法提取主成分的优势，而且其操
那些主成分。
作过程非常繁琐，没有灵活使用 SPSS 软件模块功能。 本文结
（4 ）做正交变换 Z=XΦ ，获得新的自变量；
合主成分分析和线性回归分析的原理，巧用 SPSS15.0 的 De-
（5 ）将 剩 余 的 成 分 对 因 变 量 进 行 普 通 最 小 二 乘 回 归 ，再
scriptives 、Data Reduction 、Linear Regression 、Compute Vari-
返回到原来的参数， 便得到因变量对原始变量的主成分回
able 模 块 的 功 能 , 把 主 成 分 回 归 的 每 一 步 计 算 过 程 用 SPSS
归。
展现出来，并且对结果给出了 SAS 验证。 不但得出了正确结
总结这些步骤可以看出：主成份回归解决多重共线性问
果 , 而且把每一 步 计 算 过 程 完 整 地 呈 现 出 来 ，这 样 既 有 利 学
题是通过求特征值和特征向量达到降维来实现的。 因为在降
生掌握有关方面的知识，还能加深学生对统计软件的灵活使
维前指标之间的多重共线性可能是由于某个指标或者少数
用和掌握。
指标所包含的信息与其他指标所包含的信息之间的相关性
引 起 的 ，通 过 降 维 的 处 理 我 们 提 取 出 了 主 成 份 ，就 像 是 把 指
1
基本原理和计算步骤
标体系所包含的信息分了类， 某一大类由一个主成份来表
现，这样就消除了产生多重共线性问题的根源：信息的交迭[4]。
1933 年，Hotelling 提出主成分分析方法， 主成份分析的
核心思想就是通过降维， 把多个指标化为少数几个综合指
2
S PS S 对计算过程的实现
标 ， 而 尽 量 不 改 变 指 标 体 系 对 因 变 量 的 解 释 程 度 。 W.F.
Massy 于 1965 年根据主成份分析的思想提出了主成份回归。
利 用 文 献 [1] 中 的 外 贸 数 据 ：因 变 量 Y 为 进 口 总 额 ，自 变
基金项目：国家统计局资助项目（LX08081 ）；浙江省精品课程“统计学概论”和温州大学研究生精品课程“多元统计学分析”
资助
统计与决策 2011 年第 5 期（总第 329 期）
157
知 识 丛 林
表1
表2
1
2
X1
149.3
161.2
X2
4.2
4.1
X3
108.1
114.8
3
4
5
6
7
8
9
10
11
171.5
175.5
180.8
190.7
202.1
212.4
226.1
231.9
239.0
3.1
3.1
1.1
2.2
2.1
5.6
5.0
5.1
0.7
123.2
126.9
132.1
137.7
146.0
154.1
162.3
164.3
167.6
序号
2.1
Y
15.9
16.4
19.0
19.1
18.8
20.4
22.7
26.5
28.1
27.6
26.3
描述性统计量表
样本数
x1
x2
x3
y
11
11
11
11
均值
sion→Linear，在 Dependent 中 选 择 导 入 ，在 Independent
标准差
中 导 入 Zx1，Zx2，Zx3， 在 statistics 中 选 中 Colinearity
194.5909 29.99952
3.3000
1.64924
139.7364 20.63440
21.8909 4.54367
statistics ，其它选项默认，得表 3 。
表 3 给出线性回归方程中回归系数 的 估 计 值 和 共
线性统计量， 表中 ZX1 和 ZX3 容忍 度 都 为 0.005<0.1 ，并
量 X1 为 国 内 总 产 值 ， X2
且其方差膨胀因子 VIF 都很大，说明它们之间存在严重的共
为 存 储 量 ， X3 为 总 消 费 。
线性。
为了建立 Y 对自变量
从 表 4 可 以 看 出 ， 条 件 数 1.999/0.003≈666.33 ， 故 共 线
X 1， X 2 和 X 3 之 间 的 依 赖
性程度较严重。 从方差百分比上看，ZX1 和 ZX3 变量间也存在
关系， 收集了 11 组数据
明显相关性。
见表 1 。
2.3
数据标准化
主成分分析
执行：Analyze→Data Reduction→Factor ， 选 定 标 准 化 后
执 行 ：Analyze →Descriptives Statistics →Descriptives ， 将
的 变 量 Zx1，Zx2，Zx3 进 入 Variables 中 ，Extraction 中 的 选 项 ，
变量 y ，x1，x2，x3 选入 Variables 的 对 话 框 中 ， 选 定 Save stan-
method 选 用 principal components ，Analyze 选 用 covariance
dardized values as variables ， 即将标准化后的数据作为变量
matrix ， 在 提 取 主 成 分 的 Extract 中 选 用 Number of factor 并
保存。 见表 2 。
在 后 面 的 框 中 填 入 3 ， 提 取 三 个 主 成 分 。 在 Scores 中 选 择
描 述 性 统 计 量 表 中 显 示 各 变 量 的 样 本 数 （N ）、 均 数
（mean ）和 标 准 差 （Std.Deviation ）， 以 便 于 对 中 心 化 后 的 自 变
Save as variables ；在 method 中选择 reg ；不进行旋转，结果输
出如表 5 。
量进行完主成分回归后还原为原始变量。
2.2
表 5 显 示 三 个 特 征 值 分 别 为 λ1 =1.999 ，λ2 =0.998 ，λ3 =
共线性诊断
0.003 ，前两个特征值的累计贡献率达到 99.91% ，因此剔除第
共 线 性 就 是 对 自 变 量 观 测 数 据 构 成 的 矩 阵 X'X 进 行 分
析，使用各种指标反映自变量间的相关性。 进行共线性诊断
三个主成分，相应的因子载荷矩阵如表 6 。
2.4
的方法有很多种，目前较为常用的诊断方 法 有 ：条 件 数 （con-
dition index ）、容 忍 度 Tolerance （或 方 差 膨 胀 因 子 （VIF ））、特
征根（Eigen value ）分解法。
求特征向量和主成分
前两个特征值 λ1=1.999 ，λ2=0.998 ，对 应 的 标 准 正 交 化 特
征向量分别为：
k=λ1/λp，它刻画了特征值差异的大小。 一般情况下 k<100 ，则
'
'
φ1 =（ 0.999 ， 0.062 ， 0.999 ），φ2 =（ -0.036 ， 0.998 ， -0.026 ）
姨λ1 姨λ1 姨λ1
姨λ2
姨λ2
姨λ 2
下面 使 用 Compute Variable 模 块 的 功 能 ，计 算 第 一 和 第
认为复共线性很小；100≤k≤1000 认为存在中等程度的复共
二主成分。
（1 ）条 件 数 ：是 指 X'X 的 最 大 特 征 根 与 最 小 特 征 根 之 比
线性；若 k>1000 则认为存在严重共线性。
执行：Analyze→Transform→Compute Variable ， 在 Target
（2 ）容 忍 度 ：以 每 个 自 变 量 作 为 因 变 量 对 其 他 自 变 量 进
行 回 归 分 析 时 得 到 残 差 比 例 ，用 1 减 去 决 定 系 数 来 表 示 (1-
Variable 中输入 Z1，在 Numeric Expression 中计算公式为：Z1=
表5
主成分提取汇总表
R2) ， 越小 说 明 共 线 性 越 重 ，T<0.1 时 共 线 性 非 常 严 重 （陈 希
孺）。 由此方差膨胀因子（VIF ）：定义 VIF=1/T ，VIF 越大，说明
初始
主成分
共线性越严重。
1
2
3
（3 ）特征根分解法：对自变量进行主成分分析，若相当多
维度的特征根为 0 ，则共线性严重。
本例共线 性 诊 断 操 作 步 骤 如 下 ：执 行 ：Analyze→Regres表3
提取项
累计方差
方差百分比
百分比
特征植
方差百分比
百分比
1.999
.998
.003
66.638
33.372
.090
66.638
99.910
100.000
1.999
.998
66.638
33.272
66.638
99.910
表6
得分矩阵
1
.999
.062
.999
回归系数和共线性统计量
模型
标准化
变量
系数
1
常数
Zx1
Zx2
Zx3
-.339
.213
1.303
表4
Zx1
Zx2
Zx3
共线性统计
t
.000
-.731
6.203
2.809
P
1.000
.488
.000
.026
Tolerance
VIF
.005
.981
.005
185.997
1.019
186.110
表7
Z1
Z2
-2.13 -1.62 -1.12 -0.89 -0.64 -0.19 0.36 0.97
0.64 0.56 -0.07 -0.08 -1.13 -0.06 -0.74 1.35
158
特征植
条件指数
常数
1
2
3
4
1.999
1.000
.998
.003
1.000
1.414
1.415
27.257
.00
1.00
.00
.00
Zx1
.00
.00
.00
1.00
统计与决策 2011 年第 5 期（总第 329 期）
Zx2
.00
.00
.98
.02
Zx3
.00
.00
.00
1.00
非标准化系数
模型
1
1.56
0.96
1.77 1.93
1.02 -1.66
回归系数
方差百分比
维数
2
-.036
.998
-.026
主成分表
表8
共线性诊断指标
累计方差
特征值
B
Std.Error
常数 7.07E-017
.036
z1
.690
.027
z2
.191
.038
标准化
系数
Beta
.976
.191
Collinearity Statistics
t
P
Tolerance
.000 1.000
25.486 .000
1.000
4.993 .001
1.000
VIF
1.000
1.000
知 识 丛 林
FAC1_1*sprt(1.999) ，单击 OK 产生新变量 Z1，同上得：
Z2=FAC2_1*sqrt(0.998) ，于是得：
的符号都是有意义的；各个回归系数的方差膨胀因子均小于
1.1 ；主 成 分 回 归 的 均 方 根 误 差 是 ：RMSE=0.55001 ，虽 然 比 最
Z1= 0.999 Zx + 0.062 Zx + 0.999 Zx ，
姨λ 1
姨λ 1
姨λ1
小 二 乘 的 均 方 根 误 差 （RMSE=0.48887 ）有 所 增 加 ， 但 增 加 很
Z2= -0.036 Zx + 0.998 Zx + 0.026 Zx
姨λ 2
姨λ 2
姨λ2
为：
1
2
1
3
2
小。 在删去第三个主成分（PCOMIT=1 ）后的主成分回归方程
3
y=-9.1301+0.7278x1+0.960922x2+0.10626x3
输出变量结果如表 7 。
2.5
这一结果与我们 SPSS 处理结果近似相等， 进而互相验
线性回归
证了彼此的正确性。
对第一主成分 Z1 和第二主成分 Z2 做关于中心化因变量
Zy 的最小二乘回归分析。
4
结束语
执 行 ：Analyze→Regression→Linear ， 在 Dependent 中 选
择 Zy 导 入 ， 在 Independent 中 导 入 Z1 和 Z2， 做 最 小 二 乘 回
归。 见表 8 。
→
→
回归系 数 估 计 值 为 ：β 1=0.690 ，β 2=0.191 ，常 数 项 近 似 为
零。 把上面关系式代入：
操 作 菜 单 的 命 令 下 就 可 以 完 成 , 本 例 用 SPSS15.0 的 De-
Zy =0.69 ×[ 0.999 Z x + 0.062 Z x + 0.999 Z x ] +0.191 ×
姨λ1
姨λ1
姨λ1
1
2
2
注意有关软件的使用，开动脑筋，灵活使用，不但能很好地实
因此，Zy=0.4806Zx +0.2298Zx +0.4825Zx 。
2
able 模块的功能， 因此对软件 SPSS 的使用要求就 上 升 到 能
熟练运用的高度。 本文说明 , 如果能在多元统计教学的同时
3
1
scriptives 、Data Reduction 、Linear Regression 、Compute Vari-
3
[ -0.036 Zx + 0.998 Zx + 0.026 Zx ]
姨λ2
姨λ2
姨λ2
3
根据 y=Zy 姨Dy +y 和 x=Zx 姨Dx +x ，还原到原始变量的关
系为：
y=-9.1057+0.0727x1+0.6091x2+0.1062x3。
3
们利用 SPSS 的计算过程与结果是正确的。 另一方面 , 由计
算过程可以看出, 一 道 题 的 计 算 过 程 的 实 现 不 只 是 在 一 个
Zy=0.69Z1+0.191Z2+7.07E-017 ，求得：
1
本数据选自文献 [1] ，在文献 [1] 中的人工计算结果以及文
献 [2] 通 过 SAS 编 程 得 到 的 计 算 结 果 都 与 此 相 同 , 这 说 明 我
S AS 验证
现每一步的计算过程，而且还可用来解决更多新问题。 这不
但有利于学生掌 握 有 关 方 面 的 知 识, 而 且 加 深 了 对 统 计 软
件的使用和掌握, 从而达到培养学生灵活应用统计软件
SPSS 的目的。
参考文献：
[1] 王 松 桂 , 陈 敏 , 陈 立 萍 . 线 性 统 计 模 型 ：线 性 回 归 与 方 差 分 析 [M]. 北
使 用 SAS 的 REG 过 程 ，对 上 述 数 据 做 主 成 分 分 析 ，SAS
程序如下：
Proc reg data=a outset=out1 ；
Model y=x1-x3/pcomit=1,2 outvif ；
Proc print data=out1 ；
Run 后输出如下结果：
京：高等教育出版社，2004.
[2] 高惠旋 . 处理多元线性回归中自变量共线性的几种方法 [J]. 数 理 统
计与管理，2000 ，20(5).
[3] 刘 润 幸 ，萧 灿 培 ，宫 齐 等 . 利 用 SPSS 进 行 主 成 分 回 归 分 析 [J]. 数 理
医药学杂志，2001,14(2).
[4] 周松青 . 解决多重共线性问题的线性回归方法 [J]. 江 苏 统 计 ，2000 ，
（11 ）.
（责任编辑 / 易永生）
由 SAS 运行结果可以看出，这个主成分回归中回归系数
统计与决策 2011 年第 5 期（总第 329 期）
159