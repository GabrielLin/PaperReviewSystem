 42 
Vol． 42

2 
No． 2

    
Computer Engineering

··

： 1000-3428（ 2016） 02-0169-06

2016  2 
February 2016
： A

： TP391


，，，
（ ， 730070）

 ： ，，
。，。，，
，，。
，，
。
： ； ； ； ； 
2016，42（ 2） ：
： ，，，． ［J］． ，
169-174．
： Zhang Zhichang，Zhou Huixia，Yao Dongren，et al． Ｒecognition of Chinese Lexical Entailment Ｒelation
Based on Word Vector［J］． Computer Engineering，
2016，
42（ 2） ： 169-174．

Ｒecognition of Chinese Lexical Entailment Ｒelation Based on Word Vector
ZHANG Zhichang，ZHOU Huixia，YAO Dongren，LU Xiaoyong
（ School of Computer Science and Engineering，Northw est Normal University，Lanzhou 730070，China）

【Abstract】Automatic recognition of English lexical entailment relation has many researches，and many recognition
models are presented． But study on Chines lexical entailment is not sufficient while there have many studies on English
lexical entailment from different points of view ． This paper proposes a recognition method of Chinese lexical entailment
relation based on w ord vector，it uses word vector technology on Chinese Wikipedia corpora，and w ord is represented as
w ord vector． Word vector based classification features are designed，and Support Vector M achine （ SVM ） model for
Chinese noun lexical entailment classification is trained on manually created Chinese lexical entailment data set．
Experimental results show that the method and designed classification features have good performance on lexical
entailment relation recognition compared with traditional cosine similarity method．
【Key words】textual entailment； lexical entailment； word vector； entailment feature； Support Vector M achine（ SVM ）
DOI： 10． 3969 / j． issn． 1000-3428． 2016． 02． 031
［1-3］

1



 （ Ｒecognition Texutal Entailment，
ＲTE） ［1］，
 2  （ 
 T， H） ， T 
H， H  T 。 
、、
。
，，

。，

，，
。 ，
       2          
。

，
，，
， SVM 
 。

61163036，
61363058） ； （ NWNU：  （ 61163039，
LKQN-10-2，
NWNU-LKQN-12-23） 。
： （ 1976 － ） ，，、，、Web ； 、，； ，。
E-mail： zzc@ nw nu． edu． cn
： 2015-08-17
： 2015-09-16



170

2






，

4 ：
（ 1） 。 
。 ［4］
，
、
、
、。
（ 2） 。 
，，
、、。 ［5］
 WordNet  Word Similarity Database 
。 WordNet  dog  animal ， dog
 animal。
（ 3） 。
1） 。
，，
。［6-7］， u 
 v ， u  v，
 WeedsPrec。  WeedsPrec
，
［7］ WeedsPrec ［8］
， balPrec。 
［9］
。［10］ WordNet 
。 ［11］，
 u  v 
，            ，   
balAPinc 。，［12］
  -   ， jLSI （ java Latent Semantic
Indexing） 、
，，
，。
2） 。［13］
“
  （  big cat
cat） ”，，
，
，，
 SVM 、。 
［14］“ ”
，、
， SVM 。 ［15］
SimDiffs ， 2 ： ，
 4 ，
。
，





2016  2  15 

，，
。 ，
，。 
， 。

。
，
，
，
SVM ，
。
： （ 1） ，
 ； （ 2） 
SVM ，；
（ 3）  ，
，
 。

，100 
、 python ，
http： / / pan． baidu． com / s /1gdfIXuN 。

3




 2 ，
。 ，
，
，
。  w，
， w 
2，…，N） ， w 
 c i （ i = 1，
 c i 、 PMI 
， w  ＜ w1 ，w2 ，…，w N ＞ ，
。
，，
、。 
- M  SVD ，
。
，-、，
。
，［16］
，，
，
，
。，w ord2vec
 Google  2013 
 k ，
“-- ”，
 Huffman ，

3． 1

 42 

2 

，，，： 

，
，
。 w ord2vec ，
 。
3． 2 
，
，
。 ，
SVM ，，
 。
 2  u  v， word2vec
 U = ＜ u1 ，u2 ，…，
un ＞  V = ＜ v 1 ，
v2 ，
…，
v n ＞ 。
，
：
（ 1）  f diff
 2 
， 2 
，。 
，：
f diff = U － V = ＜ u1 － v 1 ，u2 － v 2 ，…，u n － v n ＞
（ 1）
（ 2）  f mul
 2 ，
，
，
。
，
，。
， u  v，
，
、， 2 ，
 。，2 

 f mul ，：
f mul = ＜ u1 × v 1 ，u2 × v 2 ，…，u n × v n ＞
（ 2）
（ 3）  f add

，。
 2  u  v ，
 u  v ，。
，， 2 
，， 2 
。：
f add = U + V = ＜ u1 + v 1 ，u2 + v 2 ，…，u n + v n ＞
（ 3）
（ 4）  f cat
 2 

171

，。 ，
，
。 
 f cat ：
f cat = ＜ u1 ，u2 ，…，u n ，v 1 ，v 2 ，…，v n ＞
（ 4）
（ 5） balAPinc  f bal
［6］，“
”， u  v 
， v  u ，
 u  v。， u  v 
 u  v 
。［8］， u 
 v ， v
 u ，
  u  v        。  ，
［8］ balAPinc 。
 w ord2vec ，
。
， w ord2vec ， balAPinc
，。
 u  v，
 u  F u  v 
F v ， balAPinc ：
fbal = balAPinc（ u，
v） = APinc（ u，
v） ·LIN（ u，
v）
（ 5）
LIN ：
LIN（ u，
v） =

∑ f∈F ∩F W u （ f） + W v （ f）
∑ f∈F W u （ f） + ∑ f∈F W v （ f）
u

u

v

（ 6）

v

，W u （ f）  f  u 
； W v （ f） 。 2 
，， W u （ f） ＞ 0， f ∈F u ；
 W u （ f） ＜ 0， f F u ；  v ，。
 APinc ， Kotlerman
，。
 F w  w ，
，| F w |  0
。 F w 
，：
rank（ f wr ，F w ） = r
（ 7）
，f wr  F w  r 。 rank 
 0-1 ，：
rank（ f，F w ）
if f ∈ F w
1 －
rel（ f，F w ） =
Fw + 1
（ 8）

{

0

if f  F w

， inc （ r，F u ，F v ） ，
 F u  r  F v ，：



172





inc（ r，F u ，F v ） = ｛ f | rank（ f，F u ）
（ 9）
≤ r and f ∈ （ F u ∩ F v ） ｝

， （ 9） ， u  v，u  v 
 0， inc （ r，F u ，F v ） ，
。 inc ：
inc（ r，F u ，F v ）
p（ r，F u ，F v ） =
（ 10）
r
 APinc ：
Fu

APinc（ u，v） =

[ p（ r，
F u ，F v） ·rel（ f ur ，F v ） ]
∑
r =1

Fu
（ 11）

4



， Google 
 w ord2vec ； ，
 ； ，
3． 2 ， libsvm ，
 SVM ； ，
，
。
4． 1 

zhw iki-20150325-pages-articles． xml． bz2 
， 763 M B 。
 opencc ，
， ICTCLAS2015 
、。 Google  w ord2vec
      ，    100 、200 、
300 、
400 。
，
 （ “”、“ ”）  280 ，
   w ord2vec        ，  
280  ，
 10 。，
，，
。    
，、 1 400 
1 400 ， 2 800 。
 2 800 ： 1 400 
，    700            
700 ；  1 400 
，
。
4． 2 
， 2 × 2
 C = （ c ij ） 2 × 2，，c ij 





2016  2  15 

 i  j 
（ i，j ∈ ｛ 0，1｝ ） ， 1 
， 0 。 、
、F ：
Pre 0 = c 00 / （ c 00 + c 10 ）
（ 12）
Pre 1 = c 11 / （ c 11 + c 01 ）
（ 13）
Ｒec 0 = c 00 / （ c 00 + c 01 ）
（ 14）
Ｒec 1 = c 11 / （ c 11 + c 10 ）
（ 15）
F0 = 2·Pre 0 ·Ｒec 0 / （ Pre 0 + Ｒec 0 ）
（ 16）
F1 = 2·Pre 1 ·Ｒec 1 / （ Pre 1 + Ｒec 1 ）
（ 17）
，Pre 0 ，Ｒec 0 ，F0 
        、  、F     ；
Pre 1 ，Ｒec 1 ，F1 
。 2 
、、F ，：
w 0 = （ c 00 + c 01 ） / （ c 00 + c 01 + c 10 + c 11 ） （ 18）
w 1 = （ c 11 + c 10 ） / （ c 00 + c 01 + c 10 + c 11 ） （ 19）
Pre = w 0 ·Pre 0 + w 1 ·Pre 1
（ 20）
Ｒec = w 0 ·Ｒec 0 + w 1 ·Ｒec 1
（ 21）
F = w 0 ·F0 + w 1 ·F1
（ 22）
，Pre，Ｒec，F 
、、F 。
4． 3 
 4． 1 ， w ord2vec 
， 3． 2 ，
 SVM ，
 。  
libsvm  SVM ，
。 ，
libsvm  c = 32． 0，g = 0． 007 812 5。
 w ord2vec 
，。 
， 3． 2 
， SVM 
。
 1  100 、200 、300 、400 
， f diff 、 f mul 、
 f add 、 f ca t  4  SVM
 F 。
1


、 F 
 f add

 f diff  f cat

 f mul

100

0． 603

0． 568

0． 586

0． 507

200

0． 597

0． 567

0． 542

0． 496

300

0． 661

0． 555

0． 520

0． 496

400

0． 575

0． 544

0． 556

0． 466


， 1 ，
 1 。

 42 

1

，，，： 

2 

 F 

 1  1  ，
 。
 ， ，
 。  ， 100   ，
 f diff 、 f cat 、 f mul 3 
 ，
 。  ，
 100  ， 。   ，
  ， 100  ，    
2

173

           ，      
SVM       。     ，    
 Pre 1 、 Ｒec 1 、
F  F 1 ； 
Pre 0 、  Ｒec 0 、F  F 0 ，  F 0  F 1   
F 。
， 2 ，
，
 （ baseline） 。  100 
， （ u，v ） ，
u  v ， （ 
 0． 7） ，。
，
。
 2 ，
SVM 。 
， f mul ，
， SVM 
，。





Pre 0

Ｒec 0

F0

Pre 1

Ｒec 1

F1

Pre

Ｒec

F

f add

0． 608

0． 583

0． 595

0． 599

0． 624

0． 611

0． 604

0． 604

0． 603

f cat

0． 622

0． 469

0． 535

0． 574

0． 716

0． 637

0． 598

0． 592

0． 586

f diff

0． 563

0． 611

0． 586

0． 575

0． 526

0． 549

0． 569

0． 568

0． 568

f mul

0． 507

0． 529

0． 517

0． 507

0． 486

0． 496

0． 507

0． 507

0． 507

f bal

0． 527

0． 573

0． 549

0． 532

0． 486

0． 508

0． 530

0． 529

0． 528

f add + f diff

0． 610

0． 564

0． 586

0． 594

0． 639

0． 616

0． 602

0． 601

0． 601

f add + f cat

0． 637

0． 393

0． 486

0． 561

0． 776

0． 651

0． 599

0． 584

0． 568

f add + f mul

0． 605

0． 589

0． 597

0． 599

0． 616

0． 607

0． 602

0． 602

0． 602

f add + f bal

0． 605

0． 636

0． 620

0． 617

0． 586

0． 601

0． 611

0． 611

0． 610

f add + f bal + f diff

0． 605

0． 627

0． 616

0． 613

0． 590

0． 601

0． 609

0． 609

0． 608

f add + f bal + f cat

0． 638

0． 441

0． 522

0． 573

0． 750

0． 650

0． 606

0． 596

0． 586

f add + f bal + f mul

0． 602

0． 600

0． 601

0． 602

0． 604

0． 603

0． 602

0． 602

0． 602

f add + f bal + f diff + f mul

0． 596

0． 579

0． 587

0． 591

0． 609

0． 600

0． 594

0． 594

0． 593



0． 545

0． 913

0． 683

0． 732

0． 239

0． 360

0． 639

0． 576

0． 521

 2 
， F  F0 、
 F  F1  F0  F1  F 。

2

 F 

，，
f add      ，  0． 603  F 。 
， f add ， f add 
balAPinc ，F 
 0． 610。， f add  f bal 
 ，。 ，
 f diff ， F  0． 608，
。f add ，f add + f bal ，f add + f bal + f diff 3 

 2 。

，
1） ，i = 1，
 ｛ （ leftw i ，rightw i ，
2，…，M ｝ ，，



174





                 
｛ （ rightw i ，leftw i ，－ 1） ，i = 1，2，…，M ｝ ，
 ，      。  ，  f add ，
f add + f bal ，f add + f bal + f diff 3 
， F0 ，F1 ，F3 
 3 。
3

4  F 


F0

F1

F

f add

0． 574

0． 468

0． 539

f add + f bal

0． 593

0． 464

0． 550

f add + f bal + f diff

0． 605

0． 482

0． 564

f add + f bal + f diff + f mul

0． 591

0． 477

0． 553


， f add  balAPinc  f bal 
， f add ； 
，f add ，f bal ，f diff 3           
f add ，f bal 2 ， f diff 

，。  u 
 v  v  u ，u  U  v  V
 U － V， V － U ，
 f diff 。

5




。 ，
，
。 ，
，

  ； “   ” 、“  balAPinc 
”、“” 3 ，
。 ，
 F  0． 6 ，
。 
，
， 。

［1］ Androutsopoulos I， Malakasiotis P． A Survey of
Paraphrasing and Textual Entailment Methods［J］． Journal
of Artificial Intelligence Ｒesearch，2010，38 （ 1 ） ：
135-187．





2016  2  15 

［2］ ，  ．             
2010，
24（ 2） ： 3-13．
［J］． ，
［3］ ， ， ，． 
2015，
41（ 5） ： 180-184．
［J］． ，
［4］ Shnarch E，
Dagan I． Lexical Entailment and Its Extraction from
Wikipedia［D］． Israel，
Jaffa： Bar-Ilan University，
2008．
［5］ Kouylekov M，Magnini B． Building a Large-scale Ｒepository of Textual Entailment Ｒules［C］/ / Pro-ceedings of the
5th International Conference on Language Ｒesources and
Evaluation． Genoa，
Italy： ［s． n． ］，
2006： 2437-2440．
［6］ Weeds J，Weir D． A General Framework for Distributional Similarity ［C］/ / Proceedings of EMNLP ’03．
Sapporo，Japan： ［s． n． ］，
2003： 81-88．
［7］ Weeds J，Weir D，McCarthy D． Characterizing Measures of
Lexical Distributional Similarity［C］/ / Proceedings of the
20th International Conference on Computational
Linguistics） ． Geneva，Switzerland： ［s． n． ］，2004： 10151021．
［8］ Lin Dekang． Automatic Ｒetrieval and Clustering of Similar
Words［C］/ / Proceedings of COLING-ACL’98． Montreal，
Canada： ［s． n． ］，
1998： 768-774．
［9］  ，，，． 
2006，
32（ 16） ： 191-193．
［J］． ，
［10］ Szpektor I，Dagan I． Learning Entailment Ｒules for Unary
Templates［C］/ / Proceedings of the 22nd Inter-national
Conference on Computational Linguistics． Manchester，UK： ［s．
n． ］，
2008： 849-856．
［11］ Kotlerman L，Dagan I，Szpektor I，et al． Directional
Distributional Similarity for Lexical Inference［J］． Natural
Language Engineering，
2010，
16（ 4） ： 359-389．
［12］ Kouylekov M，
Mehdad Y，Negri M． Mining Wikipedia for
Large-scale Ｒepositories of Context-sensitive Entail-ment
Ｒules ［C］/ / Proceedings of the 7th Conference on
International Language Ｒesources and Evaluation．
Washington D． C． ，USA： IEEE Press，
2010： 3550-3553．
［13］ Baroni M，Bernardi Ｒ． Entailment Above the Word Level
in Distributional Semantics［C］/ / Proceedings of the 13th
Conference of the European Chapter of the Association for
Computational Linguistics． Avignon，France： ［s． n． ］，
2012： 23-32．
［14］ Weisman H，Berant J． Learning Verb Inference Ｒules from
Linguistically Motivated Evidence［C］/ / Proceed-ings of
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural Language
Learning． Jeju Island，Korea： ［s． n． ］，
2012： 194-204．
［15］ Turney P D，Mohammad S M． Experiments with Three
Approaches to Ｒecognizing Lexical Entailment ［J］．
Natural Language Engineering，
2015，
21（ 3） ： 437-476．
［16］ Hinton G E． Learning Distributed Ｒepresentations of
Concepts［C］/ / Proceedings of the 8th Annual Conference of the Cognitive Science Society． Hillsdale，USA：
［s． n． ］，
1986： 1-12．
 