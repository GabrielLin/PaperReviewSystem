


*
 1   2  3  1 
1
(  100101)

2

2

(  100101)

3

(  100101)

: 【】 IPC , 
。【】 TFIDF 、 TFIDF 、、
, 、、AdaBoost , –,  F1
,  IPC 。【】 2014 –2016 “” 10 
,  Top Prediction、All Categories  Two Guesses : 78.9%、80.1%、91.2%。
【】 2014 –2016 , 。
【】“”, 
。
:    
: G250



1

(2) ;



(3) , 
[1]

 , 

;

, 

(4) , ;

、。

(5) , 

, 
[2]

。

 。, 

, , 

(International Patent Classification,

。, 

[3]

IPC) , 

, 、

, 、 50 

, , 

。

[2]。, 

 IPC , 

, 
。

:
(1) , ,  IPC 
7 , 5 ;


。, , 

: , ORCID: 0000-0003-3533-9736, E-mail: pengtao@buu.edu.cn。
*“”(: 2016YFC0802107)
(: SQKM201411417013)。

76



 8 

2017 

8

: [3],

。
 4 :  TFIDF 、

。

 TFIDF 、、

[8], 

。(–)、

, 。

、AdaBoost  4 

,  4 : 

12 。

,  TFIDF , 

。 4 

DIC_TFIDF ; 

–,  F1

,  TFIDF ,  IG_

, , 。

TFIDF ; , 
Document Vector ;  LDA, 



2

 Topic Model Vector 。 4 , 

。

 NB、SVM、AdaBoost 。

 IPC 

, –,  F1 

 20 。IPC 、

。

、、 5 。 1971 
,  5 (), 

3

 IPC  7 。


 1 ,  4 : 

:

;  4 ; ( S、N、A

(1) , 

 SVM、NB、AdaBoost ); 。

[4]

。, Venugopalan  
,  10 201 




/;

XML ,  TXT ,  MySQL

[5]

3.1

  LDA ,

。、、、、

 LDA  KNN  10%

、, 、①、

。

②。

(2) 。 [2]
,  H  10  1 500 

4 
 4 , :

, ,  72.2%。

(1) , 

[6]

3.2

 ,  SVM 

。 TFIDF③

,  SVM

,  TFIDF 

 3.25%。

。

(3) , 
[7]

(2) , 

。  M3-SVM , 、

, 。,  4 351 

, 、 F1 

。、, 

 SVM 。

TFIDF 。

。

 TFIDF 。

①https: //stanfordnlp.github.io/CoreNLP/.
②http: //www.nltk.org/.
③http: //scikit-learn.org/stable/.

Data Analysis and Knowledge Discovery

77



1



(3) : 
; 。
                (Document
Vector)。
Le  [9]              
(Distributed Memory Model of Paragraph Vector①)
。 Word2Vec [10-11]
, 、
,  2 。
①http: //radimrehurek.com/gensim/.

78



2

 [9]

 8 

2017 

8

, “there are many animals in

 Pnm ( x) 

this room”“the cat sat on table”,  50 

。: 

 50 。:  2 

, 。

50  D 、12  50  W  Softmax 

, 

。“the”、“cat”、“sat”,  D

, ,

 1 、W 

 F1 

“the”、“cat”、“sat” 3 ,  4 

。,  1  x  1 

(),  Softmax 。

 P11 ( x) , 

,  D、W、

。, 

Softmax 。:  W  Softmax

, 

, 

F1 。 F1 ,

。

,  F1 

(4) , 

。

。 LDA 


[12]

F1 (2)。

, 。 LDA 

 F11

 F1
F1   2

 F1
 N

“”, 
, 
。
3.3


、 AdaBoost 

,  4 。, 
。,
, 
4 。
 N :
:

w1 , w2 , , wN  , M 

C1 , C2 , , CM  。 x ,

 Pnm ( x)  Cm 
wn 。 Pnm ( x)  M  N 

 F1 。

(Multi-Feature Multi-Classifier Integration, MFMCI), 
( Pnm ( x) )
F1 ( Fnm )。 Fnm  Pnm ( x)  Fnm 
,  m  x  n , 
 m 。 Sn ( x) 
(3)。
S n ( x )  R ( x )  F1
M

  Fnm  Pnm ( x), n  1, 2, , N

R ( x) , 

(3)

m 1

:

, 

(2)

, FNM  M  N 

: – R ( x) (1), 

 P11 ( x) P21 ( x)  PN1 ( x) 


 P12 ( x) P22 ( x)  PN2 ( x) 
R( x)  
(1)



 
 
 P M ( x) P M ( x)  P M ( x) 
N
2
 1

, 

F12  F1M 

F22  F2M 

   
FN2  FNM 

, M , N 
。

4



4.1


               ① (United

States Patent and Trademark Office),  2014 –2016

①United States Patent and Trademark Office: https://www.uspto.gov/.

Data Analysis and Knowledge Discovery

79


“”(Engine and Pump)

4.3

。 800 , 

4 
(45 432 )。

F01L、F01N、F02B、F02C、F02D、F02M、F03D、

, 

F04B、F04C、F04D  10 ,  8 000 ,

TFIDF ,  TFIDF 。
 Python , 

 5 500 , 2 500 。
 CentOS7 64bit 、
16GB     。   Python  Java   , 

,  4 351 , 
 1 。

PyCharm  Eclipse 。

1

 sklearn、Stanford CoreNLP、gensim、NLTK
。



()



Smoother

6.64337682087


、、F1 

vesda

6.64274815818

undamp

6.64274815818

。 IPC , 

engin

6.25488032208

4.2

,  3 。Fall [13]

,  50、100、150  200 

。 Top Prediction 

,  SVM , 

; Two Guesses 

 100 。

             ; All

 LDA , 

Categories , 

。 10 , 

。

 10、12、15、18  20 , 
 15 。
4.4


, : 

(NB)–(Gaussian-NB)、
(SVM) AdaBoost。, 
。
3

 2 。

 [13]
2






F1 





NB

 TFIDF

Top Prediction

71.4%

71.1%

71.4%

72.3%

NB

 TFIDF

Top Prediction

43.9%

44.7%

43.9%

46.1%

SVM

 TFIDF

Top Prediction

64.6%

64.4%

64.6%

68.0%

AdaBoost

 TFIDF

Top Prediction

71.7%

71.9%

71.7%

72.9%

Gaussian-NB



Top Prediction

23.3%

21.4%

23.3%

24.3%

SVM



Top Prediction

48.4%

48.2%

48.4%

48.7%

AdabBoost



Top Prediction

23.6%

23.6%

23.6%

24.1%

Gaussian-NB



Top Prediction

39.7%

38.3%

39.7%

39.6%

SVM



Top Prediction

41.7%

40.4%

41.7%

42.2%

AdaBoost



Top Prediction

41.6%

40.8%

41.6%

40.7%



80





 8 

, 
。 TFIDF 
,  TFIDF  AdaBoost

2017 

8

5



5.1


,  3

,  SVM , 

。

 SVM 。
3







1

All Categories

Ⅰ TFIDF

2

All Categories

Ⅱ TFIDF



F1 





NB

73.6%

73.5%

73.6%

74.6%

AdaBoost

74.0%

73.0%

74.0%

76.7%





3

All Categories

Ⅲ

SVM

49.4%

49.1%

49.4%

49.6%

4

All Categories

Ⅳ

SVM

42.0%

41.3%

42.0%

41.6%

5

All Categories

Ⅱ、Ⅲ、Ⅳ

Gaussian-NB

31.2%

30.8%

31.2%

31.6%

6

All Categories

Ⅲ、Ⅳ

SVM

34.4%

33.2%

34.4%

34.1%

7

All Categories

Ⅰ、Ⅱ、Ⅲ、Ⅳ



72.2%

73.5%

72.2%

74.0%

8

All Categories

Ⅱ、Ⅲ、Ⅳ

MFMCI

54.1%

52.0%

54.1%

56.6%

9

All Categories

Ⅰ、Ⅲ、Ⅳ

MFMCI

79.4%

78.8%

79.4%

81.7%

10

All Categories

Ⅰ、Ⅱ、Ⅲ、Ⅳ

MFMCI

80.1%

79.5%

80.1%

82.4%

11

Top Prediction

Ⅰ TFIDF

NB

71.4%

71.1%

71.4%

72.3%

12

Top Prediction

Ⅱ TFIDF

AdaBoost

71.7%

71.9%

71.7%

72.9%

13

Top Prediction

Ⅲ

SVM

48.4%

48.2%

48.4%

48.7%

14

Top Prediction

Ⅳ

SVM

41.7%

40.4%

41.7%

42.2%

15

Top Prediction

Ⅱ、Ⅲ、Ⅳ

Gaussian-NB

31.2%

30.8%

31.2%

31.6%

16

Top Prediction

Ⅰ、Ⅱ、Ⅲ、Ⅳ

MFMCI

78.9%

78.2%

78.9%

81.2%

17

Two Guesses

Ⅰ TFIDF

NB

88.1%

88.1%

88.1%

88.4%

18

Two Guesses

Ⅱ TFIDF

AdaBoost

89.4%

89.2%

89.4%

89.8%

19

Two Guesses

Ⅲ

SVM

68.6%

68.5%

68.6%

68.7%

20

Two Guesses

Ⅳ

SVM

61.8%

61.4%

61.8%

61.9%

21

Two Guesses

Ⅰ、Ⅱ、Ⅲ、Ⅳ

MFMCI

91.2%

91.0%

91.2%

91.7%


(1-4、11-14、17-20)

45 432 , 。

:  TFIDF 

,

> TFIDF >

。

5.2

 SVM 。

>。, 

 3 , 

, 

, All Categories  80.1%,

, 。

Top Prediction  78.9%, Two Guesses  91.2%。

 45 432 ,  4 351 ,  100

 4 :

,  15 , , 

(1) 4 

。, 

。4 ()、

, ,  100 

()、()、

 200 。, 

()。

, 。, 

, 
Data Analysis and Knowledge Discovery

81


5

。
(2)  TFIDF 









F1 



72.2%

70.7%

71.0%

。 1-2、11-12、17-18 , 

RBFNN() Top Prediction

 TFIDF 。

MFMCI()

Top Prediction

78.9%

78.2%

78.9%

 8-10 , , 

MFMCI()

All Categories

80.1%

79.5%

80.1%

MFMCI()

Two Guesses

91.2%

91.0%

91.2%

。, 
 F1 ,  4 。

MFMCI  6 。

, 

6

。, 

。
4

 TFIDF  TFIDF

F1 



MFMCI 

IPC 

F1 





F01L

86.21%

98.8%

76.5%

F01N

85.60%

86.8%

84.4%

F02B

66.67%

53.2%

89.3%

F02C

82.93%

81.6%

84.3%

F02D

73.31%

95.6%

59.5%

IPC



TFIDF



TFIDF



TFIDF



TFIDF


F01L

86.1%

83.4%

66.5%

11.342%

F01N

78.1%

74.2%

0.6%

10.001%

F02B

59.8%

53.8%

10.9%

10.019%

F02C

76.0%

87.2%

0.6%

9.588%

F02D

67.1%

58.3%

9.6%

10.022%

F02M

57.7%

50.6%

3.2%

10.006%

F03D

94.1%

96.4%

0.3%

9.035%

F04B

72.6%

75.6%

7.1%

10.004%

F04C

74.7%

77.2%

1.0%

9.992%

(1)  10 , 

F04D

69.0%

62.7%

0.3%

9.989%

 IPC : F02B: 

F02M

64.99%

51.6%

87.8%

F03D

91.01%

97.2%

85.6%

F04B

79.29%

71.2%

89.5%

F04C

84.54%

90.8%

79.1%

F04D

80.87%

74.4%

88.6%

 6 , MFMCI  F01L、F01N、F02C、
F03D、F04C、F04D , F1 
 80%。 F02B、F02D、F02M、F04B 
, :

; ( F01L; 
(3)  4 

 F01M;  F01N;

,  3  5  6 , 

 F01P;  F02C; 

, 。, 

 F02C, F02G)。F02B “

。

; ”。

(4) 
,  7  10 , 

 F02C, 
 F02C。

, , 

(2) 

, 。

, 。, 

F1 –, 

, ,

。

。

[2]

 (
RBFNN), 
10 , 。
,  5 。

82



6






。( TFIDF )、

 8 

( TFIDF )、(
)、(), 

2017 

8

University, 2016. )
[7]

. [D]. : 

, –

     , 2011. (Kong Qi. Large-scale Patent

,  F1 , 

Classification Based on Parallel Machine Learning [D].

10 。、、
、[2]

Shanghai: Shanghai Jiaotong University, 2011.)
[8]

, , . 
[J]. , 2016, 39(8): 103-105, 91.

, 。

(Miu Jianming, Jia Guangwei, Zhang Yunliang. The Rapid

: 

Automatic Categorization of Patent Based on Abstract Text



[J]. Information Studies: Theory & Application, 2016, 39(8):

; , 

103-105, 91.)

。 2001 
 17 , , 
, 。

and Document[OL]. arXiv Preprint, arXiv: 1405.4053.
[10] Mikolov T. Statistical Language Models Based on Neural
Networks[D]. Brno University of Technology, 2012.
Simple and General Method for Semi-supervised Learning

, , . 

[C]//Proceedings of the 48th Annual Meeting of the

[J]. , 2015, 24(3): 314-320. (Cai Hong,

Association for Computational Linguistics. 2010: 384-394.

Jiang Renai, Wu Kai. Contribution of Intellectual Property
Protection
[J].

to

the

Technological

Progresses

in

China

Journal of Systems & Management, 2015, 24(3):

314-320.)
[2]

Le Q V, Mikolov T. Distributed Representations of Sentences

[11] Turian J, Ratinov L, Bengio Y. Word Representations: A

：
[1]

[9]

[12] Rosen-Zvi M, Griffiths M, Steyvers M, et al. The
Author-topic

Model

for

Authors

and

Documents[C]//

Proceedings of the 20th Conference on Uncertainty in
Artificial Intelligence. 2012: 487-494.

.  RBFNN [J]. 

[13] Fall C J, Törcsvári A, Benzineb K, et al. Automated

   , 2011(12): 58-63. (Ma Fang. Research of Patent

Categorization in the International Patent Classification[J] .

Automatic Classification Based on RBFNN [J]. New

ACM SIGIR Forum, 2003, 37 (1): 10-25.

Technology of Library and Information Service, 2011(12):
58-63.)
[3]

, , . 

:

[J]. , 2016 , 35(9) : 187-191,

: , , , ;

173. (Liu Guifeng, Wang Manrong, Liu Haijun. Probabilistic

: 、;

Hypergraph Based Semi-supervised Learning Method for

, , , : 。

Patent Document Categorization[J]. Journal of Intelligence,
2016, 35(9): 187-191, 173.)
[4]

Venugopalan S, Rai V. Topic Based Classification and
Pattern Identification in Patents[J]. Technological Forecasting
and Social Change, 2015, 94: 236-250.

[5]

, , . LDA 
  [J].     , 2017, 37(3): 35-39. (Liao Liefa, Le

[6]

:
。

:
, E-mail: pengtao@buu.edu.cn。

Fugang, Zhu Yalan. The Application of LDA Model in Patent

[1] , , , , . .

Text Classification[J]. Journal of Modern Information, 2017,

doc. 、.

37(3): 35-39.)

[2] , , , , . – 2  3 

. 

.txt. .

[D]. : , 2016. (Ma Shuanggang. The Study
of Automatic Chinese Patent Classification Based on Deep
Learning Theory and Method [D]. Zhenjiang: Jiangsu

: 2017-05-31
: 2017-08-15

Data Analysis and Knowledge Discovery

83



Patent Classification Based on Multi-feature and Multi-classifier
Integration
Jia Shanshan1 Liu Chang2 Sun Lianying3 Liu Xiaoan1 Peng Tao2
(College of Intellectualized City, Beijing Union University, Beijing 100101, China)
2
(College of Robotics, Beijing Union University, Beijing 100101, China)
3
(College of Urban Rail Transit and Logistics, Beijing Union University, Beijing 100101, China)
1

Abstract: [Objective] This paper aims to automatically allocate correct IPC to patent applications with the help of
multi-feature and multi-classifier integration method. [Methods] First, we extracted the TFIDF features of all
dictionaries and information gains, as well as the vector features of document and topic models from patent applications.
Then, we used the collected data to train the NB, SVM, and AdaBoost classifiers. Finally, we established the
feature-class matrix and predicted the final IPC with the F1 weight matrix. [Results] We examined our new method
with 10 patent classes from 2014 to 2016 in the field of engine and pump. The accuracy of top prediction, all categories,
and two guesses were 78.9%, 80.1% and 91.2% respectively. [Limitations] The size of training corpus is limited,
which only includes 3 years patent data. [Conclusions] The proposed method could effectively improve the accuracy of
patent classification in the field of engine and pump.
Keywords: Patent Classification Document Vector Topic Model Vector

Classifier Integration

、、  

 2017 , 、
  (Springer Nature)《——》。
, , 
, 。。
, 。
、Nano , , 
。, 。
、, , 
, , 。
(1) : ;
(2) Nano ;
(3) : , 。
, , 。,
, 。
()

84

