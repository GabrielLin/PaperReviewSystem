软件学报中国科学院软件研究所版权所有基于机器学习特性的数据中心能耗优化方法王肇国易涵张为华复旦大学计算机科学技术学院上海通讯作者王肇国摘要随着互联网的发展各种类型的数据呈爆炸式增长通过机器学习的方法对大量数据进行实时或离线的分析获取规律性信息已成为各行业提升决策准确性的重要途径因此这些机器学习算法成为各个数据中心运行的主要应用然而随着数据规模的增大和数据中心面临的能耗问题的突出如何实现这些算法的低功耗处理已成为实现绿色数据中心亟待解决的关键问题之一为了实现对这些机器算法的绿色计算首先对运行在数据中心中的关键算法进行了深入的分析并观察到在这些算法中存在大量的冗余计算在此基础上设计和实现了一种面向数据中心典型应用的低功耗调度策略该算法通过对不同计算部分的输入数据进行匹配来判断计算过程中的冗余部分并对算法进行调度实验数据显示对于数据中心的两种典型应用和该算法可以实现和的能耗节约关键词节能分布式计算机器学习中图法分类号中文引用格式王肇国易涵张为华基于机器学习特性的数据中心能耗优化方法软件学报英文引用格式随着互联网的发展各种不同类型的数据呈爆炸式增长如在年每天产生的数据年每天产生超过的数据而作为最大的互联网公司在年每天会对的数据进行处理为了应对数据规模的不断扩大和对这些数据进行实时分析以及处理的需要各个互联网公司都不断扩大数据中心的规模和数量如和微软等公司都在全球拥有多个规模超过十几万个节点的数据中心基金项目上海市科委科技攻关项目国家自然科学基金国家高技术研究发展计划收稿时间定稿时间王肇国等基于机器学习特性的数据中心能耗优化方法随着数据规模的扩大如何利用机器学习算法对这些数据进行实时或离线的分析发掘数据的内在规律已成为各行业提升决策准确性的重要途径如公司基于机器学习算法对每分钟新涌现的个新的网站进行创建索引和排名全球最大的零售商沃尔玛超市需要对每小时超过万笔的交易数据进行分析和处理从而为其进一步的商业活动提供决策微软亚洲研究院提出根据现有监测站所提供的空气质量数据以及城市里的其他多种数据来源运用机器学习技术对大数据加以充分分析可以实时推断出包含细颗粒物信息的城市空气质量数据因此机器学习已成为数据中心中必不可少的功能性模块在这种背景下各种运行于数据中心的机器学习系统不断涌现如以及等其中是基于实现的分布式机器学习类库已被很多公司如等广泛使用然而随着数据规模的急剧增加以及数据中心数量及规模的不断扩大数据中心的能量消耗也飞速增长根据美国环保署报告年美国的数据中心全年累计耗电亿千瓦时其耗电量是美国当年总耗电量的而电费则高达亿美元全世界的数据中心在年共耗去亿千瓦时的电力约是全球年总发电量的年我国数据中心总耗电量达到亿千瓦时数据中心能耗占全国能源耗电总量的随着云计算的快速发展未来年我国对数据中心流量处理能力的需求将增长倍曾经公布其用电量数据年用电量为亿千瓦时到目前为止单个数据中心的耗电量已经上升到万千瓦时级别因此节约数据中心的能耗已成为当前数据中心所面临的主要挑战之一如何实现数据中心的绿色处理也成为研究的热点之一目前数据中心的能耗管理主要使用或休眠唤醒技术将空闲节点置于低能耗状态对于数据中心的计算任务的节能目前大部分研究都是针对实现任务节能虽然这些算法都可以在一定程度上降低数据中心的能量消耗但这些算法在设计过程中并没有充分利用运行于数据中心的典型应用机器学习任务的特点从而使其效果受到一定的限制为了进一步对数据中心的能量消耗进行优化我们首先对数据中心的典型机器学习算法进行了深入的特性分析机器学习任务属于计算密集型应用因此其主要的能耗体现在数据的分析和计算上然而这些算法在机器学习的过程中需要不断地对数据进行迭代归类和分析在这个过程中存在大量的冗余计算这些冗余计算带来了不必要的能耗开销与此同时在数据中心中机器学习主要用于进行数据分析发现数据潜在的规律所以用户对其计算结果的精准度并没有非常严格的要求如在推荐系统中只需要得到用户倾向于哪个物品过于精确的计算结果在这里并没有太大意义基于机器学习算法的以上特点我们设计和实现了一种面向数据中心中机器学习计算的节能机制提出了通过匹配输入数据来去除冗余从而达到节能的方法其核心思想是通过匹配两次的输入来分析其输出的相似性并通过重用计算结果以及合理的调度达到节能的效果实验数据显示该算法在保证算法精确性的基础上可以有效降低数据中心机器学习算法的冗余计算从而达到节能的效果对于算法在将误差范围保证在之内的前提下可以最大节约的能耗对于算法在将误差值保证在之内的前提下最大可以节约的能耗为了进一步验证算法的有效性我们还随机选取了个点共个点对算法进行测试该系统只会对的点的归类产生影响本文第节介绍相关工作第节分析数据中心能耗特点和数据中心机器学习算法的特点第节介绍本文的节能算法第节给出实验数据和相关分析相关工作随着能源问题在各国国计民生中地位的进一步凸显如何设计和实现数据中心的节能技术已成为研究的热点之一本节将从如下两个方面介绍相关工作首先介绍目前已有的面向数据中心的节能技术然后介绍针对框架目前的节能方法早在世纪初研究人员就已经开始研究面向网络服务器的节能技术等人在年提出通过使用动态调整电压和批处理网络请求来降低能耗的方法该方法的主要思想是当系统负载较低时可以将网络请求缓存起来此时通过技术使得处理器处于低能耗状态当请求数目超过一定阈值时再提高处理器的供电量并将这些请求发送给处理器进行处理该技术在一定程度上牺牲了系统实时软件学报性在此条件下降低了处理器的能耗由于服务一般是多层应用包含了交互层逻辑层和存储层因此等人提出面向运行多层应用的服务器的节能技术该系统提供了一套完整的算法和优化框架使得在降低能耗的同时并不影响服务请求的响应时间实验结果表明在不影响响应时间的情况下该系统达到了的节能效果该课题组同时还提出通过提供优先级的方式对客户端归类划分对于不同优先级的客户端使用不同的节能策略实验结果表明该技术在降低系统能耗的同时还提高了系统的吞吐量等人通过对请求的跟踪识别对不同请求进行归类并利用技术对系统能耗进行控制随着虚拟化技术的广泛应用通过来控制系统的能耗变得困难等人设计并实现了面向虚拟化环境节能的系统系统是一个基于控制理论设计的两层控制系统主控制器通过采用多输入多输出控制技术为所有虚拟机提供负载均衡辅助控制器通过动态调整处理器频率以降低功耗同时他们还提出了系统该系统仍然基于两层架构并保证每个虚拟机在低能耗的状态下仍然可以达到需要的性能除了通过改变处理器频率降低系统能耗之外还可以通过关闭集群中零负载的物理机以达到节能目的等人提出以物理机为单位进行动态资源的分配和调度等人解决了异构集群中如何以物理机为单位进行资源调度和分配的问题为了使得更多机器可以关闭等人和等人提出在不影响整个系统吞吐量的情况下尽量将服务请求转到某一部分服务器使得剩下的服务器处于零负载状态因而可以被移出集群的方法等人和等人提出根据负载情况动态调整数据中心服务器的在线算法等人设计并实现了调度系统在计算中心的能耗单个工作效率和网络通信需求中取得了平衡计算框架是目前在数据中心广泛被使用的编程模型因此它对数据中心的能耗至关重要目前已有很多工作关注于研究模型的能耗以及具体的控制方法计算框架的实现一般分为两个部分一个是分布式存储另一个是分布式计算设计并实现了绿色分布式存储的方法它将系统的存储节点分为两个部分一部分是热点区域另一部分是非热点区域不同类型的数据会存储在不同的区域中与此同时非热点区域会长时间处于低能耗状态等人研究了中不同的配置参数对能耗的影响他们还提供了针对测量能耗的企业级基准等人通过在一定程度上牺牲性能来降低能耗等人发现与计算时只用一部分计算节点并关掉其他计算节点相比运行一个计算任务应该使用所有的计算节点当任务完成之后再关掉所有的计算节点因为这样会达到更好的节能效果等人发现可以通过调整或者控制虚拟机的物理位置来达到降低能耗的目的等人通过数据压缩的方式降低了系统的能耗等人使用技术面向计算密集型的应用进行能耗控制等人以及等人均提出了不同的面向异构集群能耗的调度机制使得可以在不严重影响系统吞吐量的情况下达到低功耗的效果分布式机器学习的特点和能耗问题本节将以经典的算法和算法为例详细分析介绍分布式机器学习的特点我们首先对其基本算法进行介绍然后对中两种算法的实现进行评测并通过对评测结果的分析和观察总结出机器学习的基本特点和能耗问题算法描述聚类算法聚类算法在年被提出迄今为止仍然被广泛使用该算法的核心思想是以迭代计算的方式找出个中心点使得每个点到其所在聚类的中心点距离之和最小其具体运算过程如下初始化指定个中心点一般可以通过随机的方式选取也可以通过伞聚类的方法初始化中心点以减计算每一个数据点到各个中心点的距离将数据点分配到距离最近的那个中心点所在的类通过计算每一个聚类中所有数据点的平均值得到新的中心点如果所有的中心点坐标都保持不变则意味着结果收敛停止计算否则返回第步继续计算少迭代次数王肇国等基于机器学习特性的数据中心能耗优化方法这里介绍库中基于实现的算法每个点以向量的形式进行存储和计算所有点被存储在分布式文件系统的不同数据块中函数接收一个数据点和当前个中心点作为输入计算出距离该数据点最近的中心点并将该数据点和距离最近的中心点作为运算结果输出函数接收本地所有函数的计算输出并将属于同一类的点相加同时计算该类中相加的点的数目函数接收所有节点任务的计算结果通过计算属于每个类的所有点的平均值来得到新的中心点并通过原中心点和新中心点的坐标差是否小于某一个阈值来判断该中心点是否收敛若所有中心点已经收敛则结束本次计算基本算法算法由创始人拉里佩奇和谢尔盖布林于年提出主要用于表示网页等级的重要性其中心思想是每一个页面都使用值来表示它的重要程度若一个页面的入链程度越多则这个页面越重要与此同时若指向这个页面的入链权重越高则这个页面所获得的权重也就越高具体计算步骤如下每一个网页抽象成一个点根据连接关系构建一个有向图对每一个点分配一个相同的值并对于每一个点进行以下两步操作每一个点将其部分值平均分配到其指向的点上每个点将其通过所有入链获得的权重加和以及保留的值得到本点新的值当所有的点收敛时结束本次运算否则继续执行第步在库中应用会使用一个分布式矩阵来表示这个有向图如果第行第列的值为则表示点有条出边其中一条出边指向点同时程序中会使用一个向量存储所有点的权重而矩阵和向量的乘积便是所有点获得的最新的权重所以计算事实上是矩阵和向量不断相乘的过程函数会传入两个参数一个是分布式矩阵的某一行另一个参数是所有点权重的向量函数会将两个向量相乘并将最终结果传给函数函数负责将所有传过来的数值组成一个新的权重向量特性分析为了根据数据中心机器学习算法的特点对能耗进行优化我们首先收集了利用率和网络传输情况并在此基础上分析了这些算法的能耗特性和计算冗余特性利用率和网络传输情况的分析首先我们测量了运行两个不同程序时处理器利用率和网络数据传输情况为了隔离不同任务之间的影响我们将输入的大小配置成一个基本块的大小因此计算过程中只会运行一个和一个我们让任务在同一个处理器上顺序执行图和图显示了在和中该处理器在整个计算过程中的利用率我们可以看到和在整个计算阶段的利用率均处于较高状态其中的利用率平均值就达到左右在网络传输方面当输入数据为时应用的只会产生的数据传输给应用的也只会产生左右的数据传输给由此可见这两种典型应用均属于计算密集型任务利用率利用率利用利用率时间时间图利用率图利用率软件学报能耗特性对于应用能耗计算我们使用功率插座对单个计算节点的实时功率进行检测图和图展示出和执行多次迭代计算任务中一次迭代的测试结果其中横坐标是单次迭代计算的执行时间纵坐标是该时间点的单节点功率在中处于空闲状态时该机器的功率处在左右的低功耗状态而当机器的利用率提升后其实时功率可以达到左右的高功耗状态从图中也可以看出在计算过程中系统大部分时间处于高能耗状态在中阶段利用率低于中的利用率所以阶段的功率略低于中左右的功率峰值与此同时其曲线与上一节的利用率曲线也非常匹配也就是说这里的能源消耗主要是用于执行处理器的计算因此面向计算密集型的任务通过减少处理器的计算可以有效降低系统能耗实时功率实时功率功率功率时间图时间图实时功率实时功率计算冗余性的分析我们测试了随着迭代次数的增加不同聚类的收敛情况测试将个点分为个聚类最大迭代次数为次从图中可以看出当第次迭代计算完成时已有个聚类的中心点处于收敛状态在第次完成时已经有个聚类的中心点收敛然而由于在计算过程中有一些数据点会从一个聚类被移到另一个聚类因此我们从图中可以看到在第次迭代结束时一部分已经收敛的点会重新变为不收敛点直到次迭代计算结束仍然存在个聚类的中心点处于不收敛状态图和图展示了每一次迭代每一个数据块中属于收敛的聚类的点的比例我们分别测试了数据块大小为和的情况从图中可以看出当数据块为时第次迭代之后在的数据块中有超过的点属于收敛的聚类而当数据块为时第次迭代之后的数据块中有超过的点属于收敛聚类可以看出减小数据块的大小能更容易地在数据块的粒度聚类收敛情况百分比收敛聚类个数上发现应用中存在的冗余计算数据块收敛点百分比最小值中位数最大值迭代次数图中聚类收敛情况迭代次数图数据块中收敛点百分比王肇国等基于机器学习特性的数据中心能耗优化方法对于我们测试了随着迭代次数的增加每一个点的收敛情况图显示了收敛点的比例随着迭代次数的变化情况从图中可以看出当迭代次数超过时超过的点都处于收敛状态由于随机生成的数据不同的数据块上收敛的数据分布非常均匀当迭代次数超过时所有数据块上超过的点收敛而在第次迭代时所有的点均已处于收敛状态迭代次数图数据块收敛点百分比收敛点百分比百分比百分比数据块收敛点百分比最小值中位数最大值迭代次数图收敛点百分比从以上的结果中可以看出对于和应用在整个任务执行过程中大部分数据的计算结果在较少的迭代次数后就已经进入收敛状态即计算结果的变化在可忽略的范围内只有少数的数据需要重复计算得到准确的结果因此对于已经属于收敛的聚类或者点进行重复计算在一定程度上属于冗余计算在接下来的章节将介绍我们所提出的系统如何通过匹配计算输入的相似度来去除可能存在的冗余计算从而达到节能的目的系统的设计实现本节介绍了我们的系统的设计和具体实现首先介绍该系统的核心算法然后介绍总体架构以及系统中每一个功能模块的具体实现最后以和为例介绍特定的应用如何在该系统上运行以达到节能的目的核心思想在研究过程中我们发现面向机器学习的分布式计算对计算结果的精准度并没有苛刻的要求如聚类算法中各聚类的划分推荐算法中不同用户和不同商品的相关度以及中每一个点最后计算得到的排名这些均不需要非常精确的计算结果用户允许这些计算结果存在一定范围内的误差由于存在随机初始化等特性这些算法对于同一数据集合的两次运行结果也不完全相同事实上有些程序计算过程中并不能保证计算结果的误差范围如和推荐算法等程序在计算时用户倾向于指定一个收敛值当前后两次计算结果小于该值时则认为计算收敛同时用户需要指定程序运行时的最大迭代次数当计算次数超过最大迭代次数时即使计算结果不收敛也会终止计算并向用户输出最终计算结果由此看来对于面向机器学习的计算用户对计算结果的误差有很大的容忍度基于以上观察本文提出通过比较计算的输入数据来判断是否可以重用之前的计算结果以达到去除冗余计算节省能耗的目的与此同时保证计算结果的误差被控制在一定范围之内本文的核心技术在于如何判断本次计算可能为冗余计算为此首先提出输入数据的相匹配度输入输出相关度等概念相匹配度在本文中两次输入数据相匹配度是指使用这两次数据进行输入输出得到的结果相似程度如果两次计算结果完全一致则称这两次输入完全匹配输入与输出的相关性我们使用相关性来描述输入数据的变化对计算输出的影响在研究过程中我们发现机器学习中的输入数软件学报据可以被分为多个独立的输入它们与计算结果的相关度可以单独表示例如在中每一个中心点的变化对本次计算结果的影响可以单独使用一个数值来进行描述而这些相关度最终组成了一个相关度向量相关度向量是本文中的核心数据结构主要用于描述系统的相关性在了解了以上基本概念之后接下来本文将通过对输入数据本身不同输入数据的差异度以及输入对输出的影响进行建模以介绍基本的输入匹配算法输入向量我们发现对于大部分应用的输入可以用多维向量来表示向量的每一个维度代表一块独立的输入数据如在中表示每次输入中第个聚类的中心点的位置相关度向量我们使用相关度向量来描述输入数据和输出数据的相关度其维度与输入向量相同其中为的一个数值表示数据的改变对计算结果影响的可能性如当为时表示输入数据的改变不会影响计算结果当为时则表示的改变有的可能性对输出产生影响差异度向量我们使用向量来表示两个输入向量和的差异度即其中表示对应的和的差异其具体计算公式如下其中函数由用户根据程序的语义进行实现输入差异度两个输入的差异度可以由两个输入向量的差异度向量与相关度向量进行矢量内积得出其公式为当系统得到两个输入的差异度时可以通过比较该差异度是否小于某一个阈值该阈值由用户指定来判断两次计算是否相似总体结构图展示了基于设计并实现的系统总体结构图系统结构图对节点我们增加了面向能耗的调度模块在该模块中会保存所有节点当前的能耗状态并根据王肇国等基于机器学习特性的数据中心能耗优化方法当前节点的能耗情况进行任务分配在中包含了输入匹配模块能耗调节模块以及计算模块当接收计算的输入数据时首先将输入数据传给输入匹配模块如果找到匹配的输入则直接将存储的计算结果输出并通过能耗调节状态将本节点设置为低能耗状态如果没有相匹配的输入则调用计算模块进行或者计算下面分别介绍每个模块的具体设计和实现输入匹配模块该模块主要用于计算本次与之前的计算输入数据的相匹配度该模块中保存了之前计算结果以及对应的输入值该模块还保存了相关度向量任务的输入所有需要进行输入匹配的输入数据均需抽象为输入向量即向量类型如基于矩阵的机器学习算法大部分输入的都是矩阵那么矩阵的每一行就看成向量的一个维度然而与传统应用不同的是机器学习在计算输入数据的格式和数目上存在多样化如在应用中有两个输入分别为本地所有数据点和上次计算的聚类中心点坐标而推荐算法中输入一般是两个特征矩阵的输入分别为所有点之间的连接关系和每个点对应的评分值因此在本系统中对输入向量中每一个元素的类型提供了较高层的抽象接口用户可以根据需要在实现某一类型输入时实现该接口如在中本地数据块中的数据不会有变化因此在输入匹配的过程中我们只需存储并比较聚类中心点坐标因此输入向量应为所有聚类中心点的集合并且聚类中心点需要实现接口而对于类似于推荐算法等数据量较大或者多个输入都存在变化的应用用户应根据程序的语义使用提取特征值或者计算哈希等方法对输入数据进行合理的抽象以减少数据存储缓存量和输入匹配时的计算量计算结果的保存为了去除冗余计算我们有必要将之前的计算结果在本地进行缓存事实上在中会将计算的数据存储在分布式文件系统中因此仅需考虑计算结果的缓存问题在系统中会将的计算结果存储在本地目录中会在阶段从阶段拉取数据当整个计算任务结束后系统会将本地缓存的计算结果删除在本系统中当所在的计算任务结束后并不会马上删除所有的计算结果事实上每一次的输入和计算结果的输出路径会保存在维护的数据结果中当后面的输入与已存储的某一次输入相匹配时会将该次输入对应的计算结果的路径直接发给用户也可以手动设置清除点以清除缓存的中间计算结果相关度向量如上所述相关度向量主要用来表示输入数据的改变对计算结果的影响程度具体实现时相关度向量是一个类型的向量向量中每一个数值分别表示输入数据不同部分的变化对最终计算结果产生影响的可能性其中每一项数值应该在之间表示输入的变化不会导致计算结果的变化无关则表示输入的变化一定会导致输出的变化由于相关度向量的计算逻辑依赖于程序的语义本系统仅提供接口用于更新相关度变量的某一个维度相关度变量对于用户并不可见用户可以根据程序语义灵活地更新相关度向量如在中用户可以选择在函数结束后对相关度向量进行计算和更新在中应该在每个函数计算过程中对相关度向量进行更新相关度向量所有维度默认值为这意味着输入数据的任何改变都会影响最终的输出输入数据的匹配为了判断本次计算是否为冗余计算系统需要调用函数来查看本次计算与之前计算的相似度当函数返回为时表示本次计算可以认为是冗余计算具体地函数实现如图所示该函数传入当前的输入向量之前某一次计算的输入向量以及当前系统中的相关度向量首先系统通过调用用户定义的函数构建差异度向量因此用户需要定义函数来计算输入向量的不同然后通过差异度向量和相关度软件学报向量进行矢量内积最后得到两个输入的匹配度最后再将匹配度和用户设置的阈值进行比较如果匹配度小于阈值则匹配成功在匹配成功的情况下会直接将相匹配的输入所对应的保存的输出数据地址发送给并通知能耗模块匹配成功图具体输入匹配算法的基本实现能耗控制模块当能耗控制模块接收到匹配成功后会将系统设置为节能状态对支持网络唤醒的机器该模块会将该机器置为休眠状态当整个运行任务进入阶段后如果需要从该节点获取数据它首先会向发送请求当获取到具体数据的存储位置后会向对应的节点发送网络请求如果该节点已经处于休眠状态会被该网络请求唤醒唤醒后将数据传输给然后再次进入休眠状态对于机器学习类型的处理任务往往会占整个计算任务比较大的时间比重因此休眠状态可以较大程度地节省能耗但其缺点是有可能延迟计算任务获取数据的时间从而延长整个任务计算的时间对于不支持网络唤醒机制的机器或者对任务实时性要求较高的机器能耗模块会直接使用技术将本地处理器的频率降低当本地再次执行计算时再将处理器的频率调高用户可以通过修改配置文件的对应项来选择不同的能耗控制机制在该机器进入节能状态之前能耗控制模块需要向发送请求以更新本计算节点的状态信息调度模块在端我们增加根据当前节点所处的能耗状态进行任务调度的模块该模块中有一个优先级队列保存了所有节点及其状态信息该队列中的任务根据其优先级进行排列优先级最大的排在队头优先级最小的排在队尾在正常运行状态每个节点的优先级使用以下公式进行计算即单位时间内执行的任务的数目这里我们忽略了整个计算过程中任务的多样性因此若一个节点的优先级越高就意味着其单位时间内执行的任务数目越多因此如果可以尽可能地将较多的任务发给它那么就可以使得在不严重影响性能的情况下空闲出更多的物理节点这些空闲的物理节点可以被置为低能耗状态或者休眠状态以节省能源在一个物理节点被能耗控制模块置于低能耗状态休眠或者低处理器频率之前它会首先向发送请求以更新本计算节点的状态信息调度模块接收到这个信息之后会更新对应节点的能耗信息同时它会将当前节点的优先级除即然后将该节点重新放入优先级队列中适当的位置这样做的目的主要是为了避免低能耗的节点再次被分配新的任务从而避免某一个节点频繁地在低能耗和高能耗之间切换当系统需要分配一个新的任务到某一个节点时它会从队头开始查找直到找到某一个节点拥有空闲的可运行位置它就会将该任务分配到该节点上应用示例本节以和为例来介绍如何使用相关接口在不严重影响计算精准度的情况下达到节省计算能耗的目的王肇国等基于机器学习特性的数据中心能耗优化方法算法是机器学习中的经典算法一般需要多个计算任务迭代运行以达到数据收敛的效果这里我们以为例介绍如何通过去除冗余计算来实现降低能耗的目的由于的计算主要在于我们仅去除所导致的冗余计算输入数据的格式的主要负责对本地数据重新归类因此需要两个输入一个是需要归类的数据点这个数据点存在于本地另一个是上一次迭代计算出的新的中心点的集合这里输入向量表示所有中心点的集合因此描述中心点的类需要实现接口初始化时会将新计算的中心点加载到向量数组中并从本地文件系统中加载需要归类的数据点该数据点会作为函数的输入在函数中分别计算每个点到哪个中心点最近并作为结果输出相关度的计算在中相关度向量的长度为聚类的数目在相关度向量中每一个值代表着该聚类中心点的变化对本地计算输出结果的影响当本地所有数据均使用函数处理完之后会使用一个函数对已有数据进行合并事实上函数会计算本地数据中属于每一个聚类点的数目以及这些数据点坐标各维度数值之和在函数计算结束时用户可以使用如图所示的代码通过调用接口对相关向量进行更新为本地数据点中属于第个聚类点的数目为本地数据点总数目它们的比值作为相关向量中对应维度的值该计算的核心思想是第个中心点的相关度可理解为本地数据点中属于该聚类的比例由于计算是对本地数据进行分类当本地数据点属于某一聚类的比例较大时该对该聚类中心点的计算结果影响也较大也就是说当本地数据点大部分属于中心点已收敛的聚类时其他数据对不收敛聚类中心点的计算影响较小在后面这种情况下计算则可能为冗余计算图相关度向量更新算法匹配方法在初始化完成之后系统会调用函数对本次的输入进行输入匹配而在函数中会调用用户实现的函数来计算差异度向量中函数的具体实现如图所示由于输入向量的每一个维度都是聚类的中心点因此函数传入的是两个输入向量在相同维度上的中心点通过函数的定义我们可以看出中心点在具体实现过程中也是多维度的向量该函数首先计算了两个中心点的距离平方当该值小于时返回表示两个点可以被认为相等而当该值大于时返回该值与的比值变量为用户在应用中设置的收敛值当中心点变化范围小于收敛值时则认为该中心点所在的聚类收敛图中接口的实现算法和都是机器学习中的经典算法并且需要多次迭代计算才能达到数据收敛的效果下面软件学报我们介绍使用本系统实现节能算法数据的输入格式中有两个输入一个是本地存储的点之间的连接关系这个输入会以矩阵的形式存储在本地且在整个计算过程中不会有任何变化另一个是每一个点的权重值该值为上一轮计算的结果每一个点的权重值组成需要匹配的输入向量因此描述每一个点及其对应的权重值的类需要实现接口与类似当初始化时会将上一轮所计算的所有点的权重加载到向量数组中并使用更新系统中保存的输入向量相关度向量的计算就目前的实现来看在应用中相关度向量的长度为所有点的数目相关度向量中只有两个数值或用于表示这个点是否属于本地数据块与不同相关度向量与计算结果无关只与本地点的关联关系有关因此在数据被存储到本地时用户就可以计算相关度向量具体算法如图所示当数据被加载到本地时遍历数据中的所有点将相关向量中该点对应的维度置为因此中输入匹配的核心算法是两次输入中如果存储在本地的所有点的权重值相等那么这两次输入可以认为相匹配图相关度向量更新算法匹配方法在中当一个点的权重值变化范围小于用户设置的收敛度时我们认为该点已经收敛因此比较两个点的函数如图所示由于输入向量为所有点的权重值因此函数的两个参数为同一个点两次不同计算的权重值当这两个权重值小于用户设置的收敛度时则直接返回否则返回表示两个点不匹配由于输入向量和相关度向量的长度均等于所有点的数目因此当点较多时匹配计算的时间会比较长进而影响系统的性能我们通过设置匹配计算的频率来降低匹配计算对系统性能的影响系统提供了的接口通过该接口可以指定匹配计算调用的周期在具体实验中我们将的值设置为也就是说平均执行个计算会进行一次匹配计算图实输入匹配算法验本节将具体介绍对本系统采用的评测方法以及相应的测试结果具体内容包含实验环境节能效果以及计算误差的分析实验环境我们首先使用功率插座测试了配置处理器内存和硬盘的单节点各状态的能耗情况评测根据一个分配在一个节点上的原则进行对于应用我们使用中的聚类数据生成程序产生个数据点基于个聚类作为输入每个数据点为维的向量最终将这些点归并到王肇国等基于机器学习特性的数据中心能耗优化方法个聚类中最大迭代次数设置为次的每一个数据块大小设置为每一次任务会分配个和个对于应用由于受现有数据大小的限制我们定义了一个随机的数据生成程序具体过程如下对于每个点利用基于平均值的随机分布决定该点的连接数然后从其余点中随机选取个点作为连接的终点我们使用自定义的数据生成程序产生个数据点其中每个点的平均连接数为最大迭代次数设置为次首先我们进行了应用能耗的评估测试节能效果本节介绍了能耗的评估测试结果对于和应用输入的差异度阈值被设置成即若差异度小于则认为两次输入匹配首先介绍和应用中的电能计量方法和节能效果对于原应用的消耗计算我们通过功率插座获得单个节点执行的实时功率从而获得该节点的消耗电能目前本系统针对的是同构数据中心因此可以认为所有节点的功率情况相似将所有节点的的电能累加从而获得阶段消耗的电能然后利用功率插座获得执行节点的实时功率即阶段消耗的电能之后通过累加即可获得单次迭代执行的总电能消耗基于每次迭代计算的相似性整个计算的总能耗可以由单次迭代消耗的电能乘以迭代次数得到对于优化后的电能计算我们分别考虑了两种处理方式一种是简单地将处理冗余的数据块的节点空闲我们将其称为基于空闲的节能方法在这种方式下原来用来计算的时间都将变成空闲时间其功率计算可以通过将原来的计算时间的功率替换成空闲状态下单节点的功率来完成考虑到在阶段需要处理的数据相同其功率以及消耗的电能可以认为不变这里主要是采用替换的方法来估计节省下来的电能通过相同的方法计算应用的总电能消耗另一种是采用休眠的方式来处理原来的计算时间即通过休眠的方式处理冗余计算通过的数据请求或者的任务分配请求唤醒该节点我们将其称为基于休眠的节能方法这种情况下该节点的功率得到进一步降低不过需要相应的硬件支持总电能的计算方式与前一种方法相似可以通过将原来的计算时间功率替换成休眠状态下的功率来估计电能消耗实时功率对比实时功率对比原程序基于空闲的节能方法基于休眠的节能方法功率功率图和图中显示了和应用中单次迭代的的实时功率对比情况原程序基于空闲的节能方法基于休眠的节能方法时间图实时功率对比时间图实时功率对比最后通过计算每次迭代所有的的电能消耗和的电能消耗我们可以获得每次迭代的电能消耗图和图显示了和单次迭代执行的优化前后的电能对比情况从中可以看出在应用中通过简单的基于空闲的节能方法我们也能获得的电能节省而通过基于休眠的节能方法原程序中的消耗电能可被节省在应用中基于空闲的节能方法能够节省的电能而通过基于休眠的节能方法能够节省的电能在实际运行过程中针对次的迭代执行从第次迭代执行之后在总共个数据块中个数据块拥有超过的点属于已经收敛的聚类所以之后的次迭代执行中能够应用相应的节能方法而在中第次迭代执行后可以发现全部个数据块的所有输入均相匹软件学报电能消耗阶段电能消耗阶段电能消耗原程序基于空闲的基于休眠的节能方法节能方法电能消耗阶段电能消耗阶段电能消耗基于空闲的基于休眠的节能方法节能方法原程序图电能电能配因此均可被认为是冗余计算所以后面的次迭代都可进行节能优化电能消耗图电能消耗图展示出应用次迭代总电能消耗的情况图显示了应用次迭代总电能消耗的情况其中基于空闲的节能方法能够为应用节省左右的电能消耗而通过基于休眠的节能方法整个应用中将近的电能消耗能够被节省对于应用基于空闲的节能方法能够节省总电能消耗原程序总电能消耗电能电能的总电能消耗而通过基于休眠的节能方法整个应用中将近的电能消耗能够被节省基于空闲的基于休眠的节能方法节能方法原程序图总电能消耗基于空闲的基于休眠的节能方法节能方法图总电能消耗计算误差下面我们分别对于两个应用进行计算误差方面的分析对于应用通过比较收敛的聚类中心点变化来表示去除冗余计算而导致的误差对于计算后得到的每个聚类的中心点具体计算公式如下其中表示通过使用本系统在节能状态下计算出的聚类中心点表示原系统计算出的对应的聚类中心点是所有聚类中心点的平均距离我们用这种方式来说明一个聚类在两次计算的稳定性如果误差较小说明两次计算得出的聚类具有较高的稳定性具体误差值如图所示平均误差为其中最大值为的点误差值小于为了查看对所有数据点的影响随机选取个点输入为与相比其中仅的点在最终归类的结果上会有影响对于应用通过比较去除冗余计算后所有点的结果与原程序计算所得结果来显示去除冗余计算所带来的误差具体计算公式如下王肇国等基于机器学习特性的数据中心能耗优化方法其中表示其中第个点使用本系统计算后的结果表示第个点的原系统的计算结果对于我们设置最大迭代次数为次在本系统次迭代后所有均处于收敛状态图展示了其误差分布图其中最大误差值为的点的误差值小于平均误差为误差分布最小值中位数最大值图和的误差分布结束语本文针对数据中心的能耗问题利用机器学习算法对结果误差的容忍和计算自身的冗余性对计算的输入进行建模并通过匹配输入以及计算结果重用的方式去除不必要的冗余计算从而达到节能的目的本文从能耗和精确度两个方面对系统进行了分析实验结果表明在保证误差控制在一定范围内的前提下本系统有效地节约了系统的能耗下一步的工作将具体研究本系统在异构环境下的工作情况以及对更多的数据中心应用进行测试致谢在此我们向对本文工作给予支持和建议的同行尤其是上海交通大学陈榕老师表示感谢李洁微软研究院展示大数据与机器学习的魅力宿艺专家称年我国数据中心耗电量达亿千瓦时软件学报王肇国等基于机器学习特性的数据中心能耗优化方法王肇国男吉林长春人博士生张为华男博士副教授会主要研究领域为多核内存数据库全系统员主要研究领域为计算机体系结构软件模拟器纠错编译器优化易涵男硕士生主要研究领域为分布式计算多核内存数据库