

 Word2vec  TextRank 

 
(  527200)
: 【】。
【】 Word2vec
, ,  TextRank ,
, 
。
【】 Word2vec  TextRank , 
, 。
【】, 。
【】
, 。
:  Word2vec TextRank  
: TP391 G250



1

, 



, 

, 

Word2vec[4] TextRank ,  Word2vec

。、

, 

, , 

,  TextRank , 

。

, 

: , 
, ,  N 
。, 
, , 

, , 
。

2



; 



, 。

。

[1]

[5-6], 

 TextRank 。
 TextRank , 

, , 

, 

, 

[2]

。 
[3]

, 

,   TextRank

, , , 

 LDA , 

。

。

, 

: , ORCID: 0000-0001-9941-3670, E-mail: ningafei@126.com。

20



 271 

2016 

6

。[7]

, 

[8]

。

。
[3], 

[9], 

。

。

,

, 。



 Word2vec[4,15], 

:  TF-IDF [10]、

TextRank , 





。,

, 。

。
 TF-IDF 

3



, 

 [3], 

, , 

, 

, , 

。

。

。

 LDA[11]

TextRank 

[12-13], LDA 

 PageRank[16]。TextRank 

, “–”“–”

, , , 

, “–”, 

。TextRank  PageRank 

, 

, , ,

。

, 



。

, 

 Word2vec ,

, , , 

,  TextRank

 TextRank[1]。

,

, [13]
 Word2vec ,  Word2vec 

, 
。

 K , 

Word2vec  Google  2013 

, 

, [17]

。
[2] TextRank , 

(Continuous Bag-Of-Words, CBOW) Skip- gram[17]

。
[12] LDA , 



, , 
。[3] PageRank 

 [14]。Word2vec , 
 K ,

,  LDA 



,  TextRank

。

。, ,
, 

, 
。[14]

。 1  CBOW 

, 

: Input Layer(); Projection Layer(

CBOW 

XIANDAI TUSHU QINGBAO JISHU

21


 ); Output Layer(    ) 。   ,     

 2 , Skip-gram 

(Context(w), w), : Context(w) w  c 

, : 、、。

。

(Input Layer) W(t)  R m , 
(2)。
1 T

T t 1



 c≤ j≤c

log p(Wt  j | Wt )

(2)

, c ,  Skip-gram 
 n-Skip-gram  n , T 。
Skip-gram (3):
p(w O | w I ) 

vˋwTO v w I
O

w 1

,
1

CBOW 

(3)

|v|

 exp(vˋwT v w )

v w  vˋ
w 

I

w 。

CBOW , Skip-gram (Output

(1) :  Context(w) 2c 

Layer) Huffman 。

     ,   1  Input Layer   
V(Context(w)1), V(Context(w)2), …, V(Context(w)2c) 
Rm。, m 。
(2)    :            Input
Layer  2c , (1):
2c

X w   V(Context(w)i )  R m

(1)

i 1

, Xw  w ,  2c ,
V(Context(w)i), m 
, R 。
(3) : , 
, 
2

 Huffman 。
Huffman ,  N(=|D|), 
 D ,  N–1 ,  1 
。

4

Skip-gram 


[2-3,10], 

。 Word2vec , 

, ,
 TopN 。[1], 

、

, 

。 N , 

。 Word2vec 

, 

, 。

, 

, , ,

N 。 Skip-gram 

, 

。

 4 :

Skip-gram 

22



 271 
(1)  ICTCLAS①
 N 
, 
,  S1  S2,  S1  N ,
;

,

Sˋ
1

(3)

ˋ
ˋ
 S1  S2

, 

N ;

ˋ
ˋ
 S1  S2

, 
(6):
R(w i )  



j:w j  w i

e(w j , w i )
O(w j )

R(w j )  (1   )

1
|V|

(6)

e(wj, wi) w j  w i , V ,   [0,1]
, (Damping Factor), 
 0.85。

, 

(4)  Word2vec  Sˋ
1 , ,
 D 。
 CBOW  Skip-gram 
,  D  K 
, ,  D 
, (4):
ei  f j
|| ei ||  || f j ||

 TextRank , 
 1, , ,

ˋ
D  [w1 , w 2 ,  w m ]  (Sˋ
1  S1 ) , ;

Sim(ei , f j )  cos  

6

, R(wi) wi , O(wj) wi ,

(2)  S1  S2 , 
, 、、,

2016 


。,  3  6 {V, V1, V2,
V3, V4, V5}, 
 1, ,
 V  5  0.2, 
 5  V  1, 
, 

(4)

。

, ei  i , fj 
 j ,  i  j 
Sim(ei, fj),  ei, fj 。
 n,  Word2vec 
,  n×n , 
, 
(5):
 w11

w
M(Sim(w i w j ))   21
 

 w n1

w12  w1n 

w 22  w 2n 
   

w n2  w nn 

(5)

3



, M(Sim(wi wj)), wij

, 

 ij 。, , 

, 

,  wii 

, , 。

 i ,  1, 

, 

, 。

 1, 

, 

, 

。TextRank 

, 

, 

(7)。

①http://ictclas.nlpir.org/.

XIANDAI TUSHU QINGBAO JISHU

23


S(w j ) 



j:w j  w i

e(w j , w i )

(7)

Bi  M(T(w i w j ))  Bi 1  (1   )

, S(wj) wj , e(w j , w i )

e
k

(11)

, e  1,  k 。
, 

 w j  w i 。
, 
, : 
, 
, , 
(7), , 
TP(wi); ,
 Word2vec , (5), 
,  M(Sim(wiwj))。
, (8)
:


M(Sim(w i w j ))
1
TP(w i )     
TP(w j )   
R(w j ) 
 j:w  w O(M(Sim(w i w j )))

j:w j  w i O(w j )
j
i


1
 (1   )
|V|

(8)

,   [0,1] , 
, +=1,  0.5, 

, 。, 
,  TopN 
。
 Word2vec  TextRank :
 Word2vec , 
(5); 
(10), ,
。

5




, 、、、
。,  10 
,  90 , ,
 4 500 。 4GB 
 Word2vec ,  38 
 120MB 。

 50%,

 TextRank ,

M(Sim(wi wj)),  wj

 90  3、5、7、10 

 wi , (5), O(wj) wj ,

。

R(wj) wj , V 。

, , 

, ,

。

(9):
 w11

w
M(T(w i w j ))   21
 

 w n1

w12  w1n 

w 22  w 2n 
  

w n2  w nn 

, 
(9)

 wi , , 
(10)。
M(Sim(w i w j ))
O(M(Sim(w i w j )))



1
O(w j )

(10)

 M(T(w iw j)),  Bi 
     ,           (6)  

24



,  Word2vec 
。
 P、
 R  F , :

, 

(11)。

 TF-IDF ,  TextRank
,  4 

,  wij  wj  i 

w ij  

,  3、5、7、10 

P 




R



F-measure 

2PR
PR

(12)
(13)
(14)

, 

 271 

2016 

6

(4)  Word2vec  TextRank 

, 
 3、5、7、10 。

,  TextRank 

 4 , 、

, , 

 F 。

 Word2vec 

 1– 3 ,  TF-IDF

。

, , 

 Word2vec  TextRank ,

;  TextRank 

 Word2vec , 

;  Word2vec 

, :
(1) 

, ; 
Word2vec  TextRank 

。
(2) , 

, , 

。

。
1

(3)  Word2vec , 

4 



3

5

7

10

TF-IDF

0.305

0.263

0.241

0.238

TextRank

0.332

0.329

0.323

0.321

Word2vec

0.275

0.303

0.321

0.357

Word2vec+TextRank

0.314

0.336

0.376

0.398



, , 
。
(4) ,  Spark 
, 。
,  Word2vec  TextRank 


2

4 



, 

3

5

7

10

TF-IDF

0.312

0.272

0.248

0.231

TextRank

0.327

0.334

0.331

0.323

Word2vec

0.281

0.311

0.327

0.346

Word2vec+TextRank

0.312

0.339

0.383

0.395



3


, , 
。

6






。 Word2vec

4  F 

,  TextRank 

3

5

7

10

, 

TF-IDF

0.308

0.268

0.244

0.234

, 

TextRank

0.330

0.332

0.326

0.322

Word2vec

0.278

0.306

0.324

0.352

, 

Word2vec+TextRank

0.312

0.338

0.380

0.396



, 
, :
(1)  TF-IDF 
。
(2)  TextRank 
。
(3) 
。

, 
。
, , 
 TextRank  Word2vec 
,  TextRank  Word2vec
。, 

, , 
,
。
XIANDAI TUSHU QINGBAO JISHU

25



：
[1]

Application, 2008, 31(2): 298-302.)

Mihalcea R, Tarau P. TextRank: Bringing Order into Texts
[C]. In: Proceedings of Conference on Empirical Methods in
Natural Language Processing, Barcelona, Spain. 2004: 404-411.

[2]

 .  TextRank  [J]. 
 , 2013(9): 30-34. (Xia Tian. Study on Keyword

Extraction Using Word Position Weighted Text Rank [J]. New
Technology of Library and Information Service, 2013(9):
30-34.)
[3]

 ,  .  LDA  TextRank 

[J].  , 2014(7-8): 41-47. (Gu Yijun, Xia
Tian. Study on Keyword Extraction with LDA and TextRank
Combination [J]. New Technology of Library and Information
Service, 2014(7-8): 41-47.)
[4]

Goldberg Y, Levy O. Word2vec Explained: Deriving Mikolov
et al. 's Negative-sampling Word-embedding Method [OL].
ArXiv, 2014. arXiv: 1402.3722v1.

[5]

Frank E, Paynter G W, Witten I H, et al. Domain-Specific
Keyphrase Extraction [C]. In: Proceedings of the 16th
International Joint Conference on Artificial Intelligence,
Stockholm, Sweden. San Francisco: Morgan Kaufmann
Publishers Inc., 1999: 668-673.

[6]

Turney P D. Learning Algorithms for Keyphrase Extraction
[J]. Information Retrieval, 2000, 2(4): 303-336.

[7]

 ,  ,  ,  . 
 [J].  :  , 2006,

42(2): 156-162. (Geng Huantong, Cai Qingsheng, Yu Kun,
et al. A Method Based on the Co-occurrence of Automatic
Text Keyphrase Extraction Method [J]. Journal of Nanjing

Journal of Machine Learning Research, 2003, 3: 993-1022.
[12]  ,  .  LDA  [J]. 
 , 2010, 36(19): 81-83. (Shi Jing, Li Wanlong. Topic

Words Extraction Method Based on LDA Model [J].
Computer Engineering, 2010, 36(19): 81-83.)
[13]  ,  ,  ,  . 
[J].  , 2012, 29(11): 4224-4227. (Liu Jun,
Zou Dongsheng, Xing Xinlai, et al. Keyphrase Extraction
Based on Topic Feature [J]. Application Research of
Computers, 2012, 29(11): 4224-4227.)
[14]  ,  ,  .  Word2vec 
[J].  , 2015(4): 54-59. (Li Yuepeng,
Jin Cui, Ji Junchuan. A Keyword Extraction Algorithm Based
on Word2vec [J]. E-science Technology & Application,
2015(4): 54-59.)
[15]  . Word2vec  [J]. 
 , 2015(2): 145-148. (Zhou Lian. Exploration of the

Working Principle and Application of Word2vec [J]. Sci-Tech
Information Development & Economy, 2015(2): 145-148.)
[16] Page L, Brin S, Motwani R, et al. The PageRank Citation
Ranking: Bringing Order to the Web [R]. Stanford InfoLab,
1999.
[17] Tomas M, Kai C, Greg C, et al. Efficient Estimation of Word
Representations in Vector Space [OL]. ArXiv, 2013. arXiv:
1301.3781v3.

:
: , , , 

University: Natural Science Edition, 2006, 42(2): 156-162.)
[8]

[11] Blei D M, Ng A Y, Jordan M I. Latent Dirichlet Allocation [J].

 ,  ,  . 

、 ;

 [J].  , 2008, 34(7): 81-83. (Liu Fei, Huang

: 。

Xuanjing, Wu Lide. The Method of Using Association Rule
Mining Text Topic Words [J]. Computer Engineering, 2010,
27(8): 2853-2856.)
[9]

 ,  ,  ,  . 
      [J].        , 2010, 27(8):

2853-2856. (Jiang Changjin, Peng Hong, Chen Jianchao,

。

:

et al. Keyword Extraction Algorithm Based on Combination

 http://www.infotech.ac.cn 。

of Words and Synonyms [J]. Computer Application Research,

[1]  . train_set.zip.  – 4500

2010, 27(8): 2853-2856.)

 .

[10]  ,  .  TFIDF 
  [J].        , 2008, 31(2): 298-302. (Xu

Wenhai, Wen Youkui. Chinese Keywords Extraction Based on
TFIDF

26

:

Method

[J].

Information



Studies:

Theory

&

[2] . validation_set.zip. – 90 
.
: 2016-03-01
: 2016-04-19

 271 

2016 

6

Using Word2vec with TextRank to Extract Keywords
Ning Jianfei Liu Jiangzhen
(Department of Electronic Information, Luoding Polytechnic, Luoding 527200, China)
Abstract: [Objective] This study extracts keywords through combining the internal structure of each single document
and the word vector of the corpus. [Methods] First, we used Word2vec to represent all words’ vector from the
document corpus and then calculated their similarities. Second, modified the TextRank algorithm and assigned weights
to the keywords in accordance with their similarities and adjacency relations. Finally, we built a probability transfer
matrix for the iterative calculation of the lexical graph model and then extracted keywords. [Results] The Word2vec
and TextRank were integrated and extracted keywords effectively. [Limitations] The proposed method needs much
training with the corpus to establish word vector and relation matrix. [Conclusions] The relationship among words from
the document sets could help us modify the words relationship from a single document, and then increase the accuracy
of extracting keywords from the individual document.
Keywords: Keyword extraction Word2vec TextRank Graphical model Word vector

OCLC  RLUK , 
OCLC (RLUK), , 
、, 。
《: 》(Strength in Numbers: The Research Libraries UK (RLUK) Collective
Collection)。
 RLUK ,  RLUK , 。
 RLUK , (), 
, 。
:
(1) RLUK  2 940 (),  2 090 ;
(2) RLUK ,  467 ,  254 ;
(3)  RLUK ,  RLUK , ;
(4) RLUK  46 ;
(5) RLUK , (ARL): , (42%) RLUK 
 ARL , (58%)。
(: http://www.oclc.org/en-US/news/releases/2016/201601sheffield.html)
()

XIANDAI TUSHU QINGBAO JISHU

27