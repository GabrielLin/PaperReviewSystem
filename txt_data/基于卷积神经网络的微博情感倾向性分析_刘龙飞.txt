中文信息学报
ＩＮＧ
ＪＯＵＲＮＡＬ ＯＦ ＣＨＩＮＥＳＥＩＮＦＯＲＭＡＴＩＯＮ ＰＲＯＣＥＳＳ

第 ２９ 卷 第 ６ 期
２０１５ 年 １１ 月

ｌ．２９，Ｎｏ．６
Ｖｏ
，２０１５
Ｎｏｖ．

文章编号：１００３－００７７（
２０１５）
０６－０１５９－０７

基于卷积神经网络的微博情感倾向性分析
刘龙飞 ，杨 亮 ，张绍武 ，林鸿飞
（大连理工大学 信息检索实验室，辽宁 大连 １１６０２４）
摘

要：微 博 情 感 倾 向 性 分 析 旨 在 发 现 用 户 对 热 点 事 件 的 观 点 态 度 。由 于 微 博 噪 声 大、新 词 多、缩 写 频 繁、有 自 己

的固定搭配、上下文信息有限等原因，微博情感倾向 性 分 析 是 一 项 有 挑 战 性 的 工 作 。 该 文 主 要 探 讨 利 用 卷 积 神 经
网络进行微博情感倾向性分析的可行性，分别将字级 别 词 向 量 和 词 级 别 词 向 量 作 为 原 始 特 征 ，采 用 卷 积 神 经 网 络
来发现任务中的特征，在 ＣＯＡＥ２０１４ 任务 ４ 的语料上进行了 实 验。实 验 结 果 表 明，利 用 字 级 别 词 向 量 及 词 级 别 词
向量的卷积神经网络分别取得了 ９５．
４２％ 的准 确 率 和 ９４．
６５％ 的 准 确 率。 由 此 可 见 对 于 中 文 微 博 语 料 而 言，利 用
卷积神经网络进行微博情感倾向性分析是有效的，且使用字级别的词向量作为原始 特 征 会 好 于 使 用 词 级 别 的 词 向
量作为原始特征。
关键词：深度学习；情感倾向性分析；卷积神经网络；词向量
中图分类号：ＴＰ３９１

文献标识码：Ａ

Ｃｏｎｖ
ｏ
ｌ
ｕ
ｔ
ｉ
ｏｎａ
ｌＮｅ
ｕ
ｒ
ａ
ｌＮｅ
ｔｗｏ
ｒｋ
ｓｆ
ｏ
ｒＣｈ
ｉ
ｎ
ｅ
ｓ
ｅ Ｍｉ
ｃ
ｒ
ｏ－ｂ
ｌ
ｏ
ｅｎ
ｔ
ｉｍｅｎ
ｔＡｎａ
ｌ
ｓ
ｉ
ｓ
ｇＳ
ｙ
ｆ
ｅ
ｉ
ｆ
ｅ
ｉ，ＹＡＮＧ Ｌ
ｉ
ａｎｇ，ＺＨＡＮＧ Ｓｈａｏｗｕ，ＬＩＮ Ｈｏｎｇ
ＬＩＵ Ｌｏｎｇ
（
ｉ
ｎａ）
ｌ
ｉ
ａｎ，Ｌ
ｉ
ａｏｎ
ｉ
ｎｇ１１６０２４，Ｃｈ
ｆＴｅ
ｃｈｎｏ
ｌ
ｏｇｙ，Ｄａ
ｌ
ｉ
ａｎ Ｕｎ
ｉ
ｖｅ
ｒ
ｓ
ｉ
ｔ
ｎ
ｆ
ｏ
ｒｍａ
ｔ
ｉ
ｏｎＲｅ
ｔ
ｒ
ｉ
ｅ
ｖａ
ｌＬａｂｏ
ｒ
ａ
ｔ
ｏ
ｒ
Ｉ
ｙｏ
ｙ，Ｄａ
Ａｂ
ｓ
ｔ
ｒ
ａ
ｃ
ｔ：Ｃｈ
ｉ
ｎｅ
ｓ
ｅｍｉ
ｃ
ｒ
ｏ－ｂ
ｅｎ
ｔ
ｉｍｅｎ
ｔａｎａ
ｌ
ｓ
ｉ
ｓａ
ｉｍｓｔ
ｏｄ
ｉ
ｓ
ｃ
ｏｖｅ
ｒｔ
ｈｅｕｓ
ｅ
ｒａ
ｔ
ｔ
ｉ
ｔ
ｕｄｅｔ
ｏｗａ
ｒ
ｄｓｈｏ
ｔｅ
ｖｅｎ
ｔ
ｓ．Ｔｈ
ｉ
ｓｔ
ａ
ｓｋｉ
ｓ
ｌ
ｏｇｓ
ｙ
ｅｎｏ
ｉ
ｓ
ｅ
ｓ，ｒ
ｉ
ｃｈ ｎｅｗ ｗｏ
ｒ
ｄｓ，ｎｕｍｅ
ｒ
ｏｕｓａｂｂ
ｒ
ｅ
ｖ
ｉ
ａ
ｔ
ｉ
ｏｎｓ，ｖ
ｉ
ｒ
ｏｕｓｃ
ｏ
ｌ
ｌ
ｏ
ｃ
ａ
ｔ
ｉ
ｏｎ，ｔ
ｏｇｅ
ｔ
ｈｅ
ｒ ｗｉ
ｔ
ｈｔ
ｈｅ
ｃｈａ
ｌ
ｌ
ｅｎｇｅｄｂｙｉｍｍｅｎｓ
ｇｏ
ｉ
ｎｅ
ｓ
ｅ
ｆｐｅ
ｒ
ｆ
ｏ
ｒｍｉ
ｎｇＣｈ
ｌ
ｉｍｉ
ｔ
ｅｄｃ
ｏｎ
ｔ
ｅｘ
ｔ
ｕａ
ｌｉ
ｎ
ｆ
ｏ
ｒｍａ
ｔ
ｉ
ｏｎｐ
ｒ
ｏｖ
ｉ
ｄｅｄｉ
ｎｔ
ｈｅｓｈｏ
ｒ
ｔｔ
ｅｘ
ｔ
ｓ．Ｔｈ
ｉ
ｓｐａｐｅ
ｒｅｘｐ
ｌ
ｏ
ｒ
ｅ
ｓｔ
ｈｅｆ
ｅ
ａ
ｓ
ｉ
ｂ
ｉ
ｌ
ｉ
ｔ
ｙｏ
ｍｉ
ｃ
ｒ
ｏ－ｂ
ｏｎｖｏ
ｌ
ｕ
ｔ
ｉ
ｏｎａ
ｌｎｅｕ
ｒ
ａ
ｌｎｅ
ｔｗｏ
ｒ
ｋｓ．Ｔｏａｖｏ
ｉ
ｄｔ
ａ
ｓｋ－ｓｐｅ
ｅｎ
ｔ
ｉｍｅｎ
ｔａｎａ
ｌ
ｓ
ｉ
ｓｂｙｃ
ｌ
ｏｇｓ
ｃ
ｉ
ｆ
ｉ
ｃｆ
ｅ
ａ
ｔ
ｕ
ｒ
ｅ
ｓ，ｃｈａ
ｒ
ａ
ｃ
ｔ
ｅ
ｒｌ
ｅ
ｖｅ
ｌｅｍ－
ｙ
ｂｅｄｄ
ｒ
ｅａｄｏｐ
ｔ
ｅｄｆ
ｏ
ｒｃ
ｏｎｖｏ
ｌ
ｕ
ｔ
ｉ
ｏｎａ
ｌｎｅｕ
ｒ
ａ
ｌｎｅ
ｔｗｏ
ｒ
ｋｓ（
ＣＮＮ）．Ｏｎｔ
ｈｅＣＯＡＥ ４
ｔ
ｈｔ
ａ
ｓｋ
ｒ
ｄｌ
ｅ
ｖｅ
ｌｅｍｂｅｄｄ
ｉ
ｎｇａ
ｉ
ｎｇａｎｄ ｗｏ
／ｎｅｇａ
ｃ
ｏ
ｒ
ｈｅｃｈａ
ｒ
ａ
ｃ
ｔ
ｅ
ｒｌ
ｅ
ｖｅ
ｌＣＮＮａ
ｃｈ
ｉ
ｅ
ｖｅ
ｓａｓ
ｅｎ
ｔ
ｉｍｅｎ
ｔｐ
ｒ
ｅｄ
ｉ
ｃ
ｔ
ｉ
ｏｎ （
ｉ
ｎｂｏ
ｔ
ｈｂ
ｉ
ｎａ
ｒ
ｓ
ｉ
ｔ
ｉ
ｖｅ
ｔ
ｉ
ｖｅｃ
ｌ
ａ
ｓ
ｓ
ｉ
ｆ
ｉ
ｃ
ａ
ｔ
ｉ
ｏｎ）ａ
ｃ－
ｐｕｓ，ｔ
ｙｐｏ
ｃｕ
６５％ ａ
ｃ
ｃｕ
ｒ
ａ
ｃｙ．Ｔｈｅｒ
ｅ
ｓｕ
ｌ
ｔ
ｓｓｈｏｗｔ
ｈａ
ｔｔ
ｈｅ
ｔ
ｔ
ｅ
ｒｔ
ｈａｎｔ
ｈｅ ｗｏ
ｒ
ｄｌ
ｅ
ｖｅ
ｌＣＮＮ ｙ
ｉ
ｅ
ｌ
ｄ
ｉ
ｎｇ９４．
ｆ９５．
４２％ ，ｓ
ｌ
ｉ
ｔ
ｌ
ｒ
ａ
ｃｙｏ
ｇｈ
ｙｂｅ
ｎＣｈ
ｉ
ｎｅ
ｓ
ｅｍｉ
ｃ
ｒ
ｏ－ｂ
ｃ
ｏｎｖｏ
ｌ
ｕ
ｔ
ｉ
ｏｎａ
ｌｎｅｕ
ｒ
ａ
ｌｎｅ
ｔｗｏ
ｒ
ｋｓｍｏｄｅ
ｌｉ
ｓｐ
ｒ
ｏｍｉ
ｓ
ｉ
ｎｇｉ
ｅｎ
ｔ
ｉｍｅｎ
ｔａｎａ
ｌ
ｓ
ｉ
ｓ．
ｌ
ｏｇｓ
ｙ
Ｋｅ
ｒ
ｄ
ｓ：ｄｅ
ｅｐｌ
ｅ
ａ
ｒ
ｎ
ｉ
ｎｇ；
ｓ
ｅｎ
ｔ
ｉｍｅｎ
ｔａｎａ
ｌ
ｓ
ｉ
ｓ；
ｃ
ｏｎｖｏ
ｌ
ｕ
ｔ
ｉ
ｏｎａ
ｌｎｅｕ
ｒ
ａ
ｌｎｅ
ｔｗｏ
ｒ
ｋｓ；
ｗｏ
ｒ
ｄｅｍｂｅｄｄ
ｉ
ｎｇ
ｙ
ｙｗｏ

兴趣 ［１］。

１ 引言

目前已有研究所采用的方法大多数都基于词袋
模型，而这种模型无 法 捕 获 到 很 多 有 关 情 感 倾 向 性

随着 社 交 网 络 的 不 断 发 展，人 们 更 愿 意 通 过 微

分析的语言现象特征。例如，“反法西斯联盟击溃了

博、博客社区来表达自己的观点，发表对热点事件的

法西斯”和“法西斯 击 溃 了 反 法 西 斯 联 盟”这 两 个 词

评论，从而使通过 微 博、博 客、影 评 以 及 产 品 评 价 等

组拥有相同的词袋 模 型 表 示 方 法，而 前 一 个 带 有 积

来了解社交网络用户的情感倾向得到了学术界的广

极的感情色彩，后 一 个 带 有 消 极 的 感 情 色 彩。 除 此

泛关注。根据微博内容进行情感倾向性分析是一个

之外，还有很多研究者使用人工标注的数据（情感词

具 有 挑 战 性 的 任 务，近 年 来 引 发 了 学 者 极 大 的

典及句法分析等），虽然采用这些方法可以有效地提

收稿日期：２０１５－０７－０３ 定稿日期：２０１５－０９－０５
基金项目：国家自然科学基金（
６１２７７３７０，６１４０２０７５）、国家 ８６３ 高科 技 计 划 资 助 项 目 （
２００６ＡＡ０１Ｚ１５１）、辽 宁 省 自 然 科 学
基金（
２０１２０２０３１，
２０１４０２０００３）、教育部留学回国人员科研启动 基 金 和 高 等 学 校 博 士 学 科 点 专 项 科 研 基 金 （
２００９００４１１１０００２），
中央高校基本科研业务费专项资金资助

中 文 信 息 学 报

１６０

２０１５ 年

高情感分析的准确性但由于需要较多的人工标注数

本文 与 Ｃ
ｉ
ｃ
ｅ
ｒ
ｏｄｏｓＳａｎ
ｔ
ｏｓ 工 作 的 不 同 之 处 在

据从而限制了这些方法在其他领域以及跨语言的推

于，本文分别利用字 级 别 向 量 和 词 级 别 向 量 进 行 实

广

验，而 没 有 学 习 词 语 的 构 造 特 征。 本 文 与 Ｃ
ｉ
ｃ
ｅ
ｒ
ｏ
工作的另一个不同之处
在
于，
ｉ
ｃ
ｅ
ｒ
ｏｄｏｓ
ｄｏｓＳａｎ
ｔ
ｏｓ
Ｃ

［
２］

。卷积神经网络模型可以从大量未标注的文本

中学习到先验知识，避 免 依 赖 于 具 体 任 务 的 人 工 特
征设计，可以在一定 程 度 上 解 决 短 文 本 上 下 文 信 息
有限的问题。
要提 取 微 博 文 本 特 征，目 前 主 要 做 法 是 对 微 博
进行分词，匹配情感词典，选用其中的情感词或者情
感的相关得分作为特征，但是微博属于短文本范畴，
噪声大、新词多、缩写频繁、有自己的固定搭配、上下
文信息有限，对微博做分词歧义明显，往往得到的是
不好的切分。例如，“我发现了一个高大上网站”，在
该句中，“高大上网站”如果使用传统分词技术，会被
切分为“高 大／上／网 站”或 者 “高 大／上 网／站 ”，这 样
的切分无法体现句 子 的 正 确 语 义，甚 至 后 一 种 切 分
还将“网站”切分导致丢失评价对象 ［３］。为了解决上

Ｓａｎ
ｔ
ｏｓ在利用卷积层学 习 句 子 特 征 时，使 用 了 大 小
单一的卷积核，而不 同 大 小 的 卷 积 核 获 取 的 特 征 是
不同的，本文参考了 Ｋｉｍ 等 人 的 工 作 ［１０］，利 用 多 个
不同大小的卷积核 学 习 句 子 级 别 的 特 征 向 量，然 后
对特征向量进行串接，构造新的句子特征向量。
２ 情感分析
２．
情感分析自从 ２００２ 年由 ＢｏＰａｎｇ 提出之后，获
得了很大程度的关 注，特 别 是 在 线 评 论 的 情 感 倾 向
性分析上获得了很大的发展。由于不需要大量标注
语料，无监督情感分 析 方 法 一 直 受 到 许 多 研 究 者 的
青睐，但同 时 效 果 也 低 于 有 监 督 的 情 感 分 析 方 法。

述问题，本文引入字级别特征，将单个字作为输入特

ｅ
ｌ
ｌ
ｅｎ
ｔ，ｐｏｏ
ｒ）的
ｅｘｃ
Ｔｕｒｎｅｙ１１ 首次提出基于种子词（
”
“
”
“
非监督学习 方 法，使 用 ｅｘｃ
ｅ
ｌ
ｌ
ｅｎ
ｔ 和 ｐｏｏ
ｒ 两个种

征，通过多个拥有不 同 大 小 卷 积 核 的 并 行 卷 积 层 学

子词与未知词在搜索网页中的互信息来计算未知词

习微博文本特征。

的情感极性，并 用 以 计 算 整 个 文 本 的 情 感 极 性。 后

［ ］

本文训练了一个包含多个并行卷积层的卷积神

续的非监督情感分析方法大都是基于生成或已有的

经网络，不同卷 积 层 拥 有 大 小 不 同 的 卷 积 核。 本 文

情感词典或者相关资源进行情感分析。罗毅 ［３］等人

分别将字级别特征和词级别特征作为原始特征进行

通过构建二级情感 词 典，对 不 同 级 别 情 感 词 作 不 同

了实验，利 用 字 级 别 特 征 的 卷 积 神 经 网 络 取 得 了

增强，使用 Ｎ－ｇ
ｒ
ａｍ 获取文本特 征，利 用 构 建 的 情 感

４２％ 的准确率，利用词级别特征的卷积神经网络
９５．

词典进行微博情感倾向性分析。情感词典的构建过

取得了 ９４．
６５％ 的 准 确 率。 实 验 表 明，对 于 中 文 微

程需要大量的人工 标 注，在 跨 领 域 应 用 方 面 有 很 大

博语料而言，利用卷 积 神 经 网 络 进 行 微 博 情 感 倾 向
性分析是有效的，且 将 字 级 别 词 向 量 作 为 原 始 特 征

的限制。使用 Ｎ－ｇ
ｒ
ａｍ 模型，当 Ｎ 较大时，会导致特
征维度太大而难以训练。包含多个并行卷积层的卷

会好于将词级别词向量作为原始特征。

积神经网络通过卷积和池化操作，既充分利用 了 Ｎ－

本文的 结 构 如 下：第 二 章 介 绍 了 一 些 相 关 工
作。第三章详细介绍了本文使用的卷积神经网络结
构。第四章详细说 明 了 本 文 的 实 验 设 定，介 绍 了 实
验结果，并对实 验 结 果 进 行 了 详 细 的 讨 论。 第 五 章
是文章的总结。

ｒ
ａｍ 的特征，又不会造成维度灾难。
ｇ

３ 卷积神经网络模型
３．
１ 句子级别的表示和评分
字级别特征：以单个字作为句子的基本组成单

２ 相关工作

位，对单个字训练词向量。
词级别特征：利 用 分 词 器 对 句 子 进 行 分 词，以
词（包含长度为 １ 的 词）作 为 句 子 的 基 本 组 成 单 位，

２．
１ 卷积神经网络
卷积神经网络利用卷积层可以学习局部特

对单个词训练词向量。
以“中国足球加油！”为例，字级别的句子组成为

征 ［４］。在自然语言处理中，
ＣＮＮ 模型在很多方面取

“中 ＋ 国 ＋ 足 ＋ 球 ＋ 加 ＋ 油 ＋ ！”，词级别的句子组成

得了很多非常好的成绩，例如语法解析 ［５］、搜索词检

为“中国 ＋ 足球 ＋ 加油 ＋ ！”。

索 ［６］、句子 建 模 ［７］及 其 他 传 统 的 自 然 语 言 工 作 ［８］。

给定包含 Ｎ 个基本单位 ｛
ｒ１ ，
ｒ２ ，…ｒＮ ｝的句 子
ｘ，本 文 接 下 来 的 工 作 是 计 算 其 句 子 级 别 的 表 示

Ｃ
ｉ
ｃ
ｅ
ｒ
ｏｄ
ｏ
ｓＳ
ａ
ｎ
ｔ
ｏ
ｓ等人

提出了 Ｃｈ
ａ
ｒ
ＳＣＮＮ 模型，两个

［
９］

卷积层分别学习词语的构造特征和句子的语义特征。

ｒｓｘｅｎｔ 。字级别句子的基 本 单 位 是 单 个 的 字，词 级 别 句

刘龙飞等：基于卷积神经网络的微博情感倾向性分析

６期

１６１

子的基本单位是分词之后的词。在计算句子级别的
特征时，会遇到 两 个 主 要 的 问 题：不 同 句 子 的 长 度
不同，重要的信 息 会 出 现 在 句 子 中 的 任 意 位 置。 利
用卷积层对句子建立模型，计算句子级别的特征，可
以解决上面提到的两个问题。通过卷积操作可以得
到句子中每个基本 单 位 （字 或 者 词 语）的 局 部 特 征，
然后对得到的局部 特 征 进 行 最 大 化 操 作，从 而 得 到
一个固定长度的句子特征向量。
在包含 Ｎ 个 基 本 单 位 ｛
ｒ１ ，
ｒ２ ，…ｒＮ ｝的 句 子 ｘ
中，卷积层对每个大 小 为 ｋ 的 连 续 窗 口 进 行 矩 阵 向
量操作。本文假定向量 ｚｎ ∈ !ｄｋ 是以句子中第ｎ 个
／２ 个基本单位的词
基本单位为中心的前后各 （
ｋ－１）
向量的串接，其中 ｄ 为 句 子 中 基 本 单 位 向 量 化 表 示
后向量的长度。
Ｔ
（
ｚｎ ＝ （
ｒｎ－（ｋ－１）／２ ，…，
ｒｎ＋（ｋ－１）／２）
１）
ｓ
ｃ
ｅ
ｎ
ｔ
ｌ
ｕ
卷积层计算计算句子特征向量ｒｘ ∈ ! 的第ｊ
个元素的过程如式（
２）所示。

［
ｒｓｅｎｔ］
Ｗ ｚｎ ＋ｂ１］
ａｘ ［
ｊ ＝ ｍ
ｊ
１＜ｎ＜Ｎ

（
２）

其中，Ｗ ∈ !ｃｌｕ×ｄｋ 是 该 卷 积 层 的 权 重 矩 阵。 如
图 １ 所示，用该权重 矩 阵 计 算 给 定 句 子 中 每 个 基 本

图 １ 基于卷积方法抽取句子级别特征

卷积窗口的大 小 ｋ 不 同，获 取 的 局 部 信 息 也 不
同。 因 此，本 文 利 用 并 行 的 多 个 卷 积 层，学 习 不 同

中所有基本单位的 窗 口 取 最 大 值，就 抽 取 了 一 个 在

ｒ
ａｍ 的信息。每 个 卷 积 层 经 过 最 大 池 化 操 作 后
Ｎ－ｇ
都会生成一个固定 长 度 的 句 子 特 征 向 量，本 文 将 所

窗 口大小为ｋ 的条件下长度为ｃ
ｌｕ 的句子特征向量。

有卷积层生成的句 子 特 征 向 量 进 行 串 接，得 到 一 个

图 １ 中窗口大小 ｋ 为 ３。

新的句子特征向量 ［９］。包含多个不同窗口的并行卷

单位（字或词）的窗 口 大 小 为 ｋ 的 局 部 信 息，对 句 子

积层的架构如图 ２ 所示。

图 ２ 通过基于不同窗口大小的卷积方法利用多个不同大小的卷积核抽取句子级别特征

其中，Ｗ１ｉ，
ｂ１ｉ 是 模 型 需 要 学 习 的 参 数，卷 积 单

１
ｉ
是由用户指定的超参数。 上下文窗 口
元的数量ｃ
ｌｕ

中 文 信 息 学 报

１６２

的大小 ｋ
ｉ 是由用 户 指 定 的 超 参 数。ｍａｘ（．）表 示 最

２０１５ 年

用来学习窗口大小为 ３ 的给定

数似然函数（
ｔ
ｉ
ｖｅｌ
ｏｇ－ｌ
ｉ
ｋｅ
ｌ
ｉ
ｈｏｏｄ）进 行 训 练。 给
ｎｅｇａ
定一个句子 ｘ，参数 集 合 为θ 的 模 型 对 每 个 情 感 标

如图 ２ 所示，本文在卷积层之后，加入了 ＲｅＬＵ

签τ ∈ Τ 计算一个得分ｓθ（
ｘ）
τ 。为了将这些得分转
换为给定句子的情感标签和模型参数集θ 的条件 概

层，将 ＲｅＬＵ 作为激活函数。 通过加入 ＲｅＬＵ 层 可

率分布，我们在所有签情感标签τ ∈ Τ 的得 分 进 行

大化操作。图中 Ｗ

１１

句子的特征向量。

以加速随 机 梯 度 下 降 的 收 敛 速 度

。将所有窗口

［
１０］

ｆ
ｔｍａｘ 操作：
Ｓｏ

生成 的 句 子 特 征 向 量 串 接 后 得 到 的 新 特 征 向 量

θ）＝
τ｜ｘ，
ｐ（

如下：

ｅｓ
ｘ）
τ
θ（
ｓ
（
∑ ｅθ ｘ ）ｉ

（
５）

ｉ∈Τ

（
ｒｓｅｎｔ ＝ｒｓｅｎｔ１ ｒｓｅｎｔ２  … ｒｓｅｎｔｉ
３）
其中， 表示 串 接 操 作，
ｒｓｅｎｔｉ 表 示 由 上 下 文 窗

对上述公式取对数：
（）
ｌ
ｘ）
ｌ
ｏｇｐ （
ｏｇ （∑ ｅｓθ ｘ ｉ ） （
６）
θ）＝ｓθ（
τ｜ｘ，
τ－

口大小为ｋｉ 的 卷 积 核 通 过 卷 积 核 最 大 化 操 作 之 后

ｉ∈Τ

本文 使 用 随 机 梯 度 下 降 （
ＳＧＤ）最 小 化 负 似 然

得到的句子特征向量。
最后，表示句子 ｘ 的全局特征的向量ｒｓｘｅｎｔ 被传递

函数：

θａ

给包含两个全连接层的神经网络进行处理，计算该句
子属于每个情感标签τ ∈ Τ 的得分，如式（
４）所示。
３
２ ｓ
２
３
ｅ
ｎ
ｔ
（
４）
ｓ（
ｘ）＝ Ｗ ｈ（
Ｗ ｒ ｘ ＋ｂ ）
＋ｂ

∑

ｏｇｐ （
－ｌ
θ）
ｙ｜ｘ，

（
７）

（
ｘ，
ｙ）∈Ｄ

其中，
ｘ 表示训练预料 Ｄ 的一条句子，
ｙ 表示该句 子
的情感标签。

其中，矩阵 Ｗ２ ∈ !ｈｌｕ×（ｃｌ１ｕ＋ｃｌ２ｕ＋…＋ｃｌｉｕ），矩阵 Ｗ３ ∈
!｜Τ｜×ｈｌｕ ，向量ｂ２ ∈ !ｈｌｕ ，向量ｂ３ ∈ !

是模型需要

Τ

学习的参数。激 活 函 数 ｈ（．）使 用 的 正 切 函 数。 隐
藏层单元数目 ｈ
ｌｕ 是有用户指定的超参数。

４ 实验
４．
１ 情感分析数据集

３．
２ 模型训练

本 文 采 用 ＣＯＡＥ２０１４ 任 务 ４ 微 博 数 据 集 （表

微博情感倾向性分析本质上是一个基于主题的

１），该 数 据 集 共 ４００００ 条 数 据，其 中 官 方 公 布 了

文本分类问题，将微博短文本做两类分类，最终归纳

５０００ 条微博的极 性。 由 于 没 有 标 准 的 训 练 集 和 测

到正面和负面两种情感类别中。

试集，本文利用 该 ５０００ 条 数 据，进 行 １０ 倍 交 叉 验

本文的模型 是 通 过 最 小 化 训 练 集 Ｄ 上 的 负 对

证。利用数据集提供的 ４００００ 条数据训练词向量。

表 １ ＣＯＡＥ２０１４ 数据样例
消极

积极
奥迪车质量值得信赖。

奥迪和人寿保险一样都是垃圾！再不买了！

三星手机很好用，比较人性化。

三星手机真垃圾，电池一点也不给力。关键时候 手机自动关机。

儿子住院自付部分，保险居 然 全 给 报 销 了，这 个 保 险 上 保险这玩意儿啊，就是他忽悠你交上，然后不想 教 得 时 候 退 回 来 所 剩
无几的。

的一点也不亏啊，嘿嘿嘿。

的向量表示。

４．
２ 卷积神经网络

２．
１ 字级别的词向量
４．

词向量在卷积神经网络模型中具有非常重要的

本文 以 字 作 为 句 子 的 基 本 单 位，为 每 个 字 训 练

作用。词向量在训 练 过 程 中，可 以 获 取 句 法 和 语 义

一个词向量。在运行 ｗｏ
ｒｄ２ｖｅ
ｃ工具过程中，本文设

。最近的一

定出现次数超过五次的字会被加入字典中。最终得

些工作表明通过使 用 无 监 督 学 习 得 到 的 词 向 量，可

到了一个包含 ５２００ 条目的字 典。 对 于 没 有 出 现 在

。在本 文 的 实 验

字典中的字符的词向量会被随机初始化。训练过程

信息，这在情感分析中是至 关 重 要 的
以极大 地 提 高 模 型 的 准 确 率
中利 用 ｗｏ
ｒｄ２ｖｅ
ｃ工 具

［
１３］

［
１４－１６］

，进 行 无 监 督 的 词 向 量 学

［
１７］

习。ｗｏ
ｒｄ２ｖｅ
ｃ 实 现 了 ＣＢＯＷ （
ｃｏｎ
ｔ
ｉ
ｎｕｏｕｓ ｂａｇ－ｏ
ｆ－
ｒ
ｗｏ
ｒｄｓ）和 ＳＧ（
ｓｋ
ｉ
ａｍ）两 种 结 构，用 于 计 算 词 语
ｐ－ｇ

中的参数设置如表 ２ 所示。
２．
２ 词级别的词向量
４．
本文首先利用分词工具对语料进行分词。分词

刘龙飞等：基于卷积神经网络的微博情感倾向性分析

６期

之后，以词作为句子的基本单位，为每个词训练一个
词向量。在运行 ｗｏ
ｒｄ２ｖｅ
ｃ工具过程中，本文设定出
现次数超过五次的词会被加入字典中。最终得到了
一个包含 １９０２０ 条 目 的 字 典。 对 于 没 有 出 现 在 字
典中的词语的词向量会被随机初始化。训练过程中
的参数设置如表 ２ 所示。
表 ２ 字级别和词级别 ｗｏ
ｒ
ｄ２ｖ
ｅ
ｃ可调参数的设置
值

可调参数
词向量维度
迭代次数

１

算法选择

ｓｋ
ｉ
ａｍ
ｒ
ｐ－ｇ

参数如表 ３ 所示。
表 ３ 模型参数设置
参数名
词向量维度

ｋ

上下文窗口大小

ｌ１１ｕ
ｃ

卷积单元数量

ｋ２

上下文窗口大小

ｒ
ｄ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ：利 用 ｗｏ
ｒｄ２ｖｅ
ｃ训 练 出 的
 ＣＮＮ－ｗｏ
词级别的词向量 进 行 试 验。 在 实 验 过 程 中，词 向 量
保持不变，只学习模型的其他参数。
ｒ
ｄ－ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ：利 用 ｗｏ
ｒｄ２ｖｅ
ｃ训 练
 ＣＮＮ－ｗｏ
出的词级别的词 向 量 进 行 试 验。 在 实 验 过 程 中，词
向量会被微调，同时学习模型的其他参数。

字级别

词级别

３００

３００

２

２

１００

１００

３

３

１００

１００

５

５

ｃ
ｌ

卷积单元数量

ｋ３

上下文窗口大小

ｌ１３ｕ
ｃ

卷积单元数量

１００

１００

ｌｕ
ｈ

隐藏层单元数量

３００

３００

１２
ｕ

ｒ
ｉ
ａｍ 和 ｂ
ｉ
－ｇ
－
 ＳＶＭ ｂｏｗ２： 向 量 特 征 是 ｕｎ
ｒ
ａｍ 特征，利用 ＳＶＭ 分类。
ｇ
ｒ
ｒ
ｉ
ａｍ、
ｂ
ｉ
ａｍ
－ｇ
－ｇ
 ＳＶＭ ｂｏｗ３：向 量 特 征 是 ｕｎ

微调，同时学习模型的其他参数。

［ ］
练过程中 采 用 Ａｄａｄｅ
ｌ
ｔ
ａ 更 新 规 则 １８ ，对 乱 序 的 微
批次样本中进行随机梯度下降（
ＳＧＤ）。模型的其他

１

ｒ
ｉ
ａｍ 特 征，利
－ｇ
 ＳＶＭ ｂｏｗ１：向 量 特 征 是 ｕｎ
用 ＳＶＭ 分类。

ｒ
ｄ－ｒ
ａｎｄ－ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ：将 词 级 别 的 词
 ＣＮＮ－ｗｏ
向量进行随机初 始 化。 在 实 验 过 程 中，词 向 量 会 被

１ｅ－３

本文对多个卷积神经网络模型进行了实验。训

ｄ

本文对多个模型进行了实验。

只学习模型的其他参数。

４．
２．
３ 超参数

参数

４．
４ 结果与讨论

ｒ
ｄ－ｒ
ａｎｄ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ：将 词 级 别 的 词 向 量
 ＣＮＮ－ｗｏ
进行随机初始化。在实验过程中，词向量保持不变，

１０

采样值

［ ］
ＳＶＭ 的实验 １９ 。

和ｔ
ｒ
ｒ
ｉ
ａｍ 特征，利用 ＳＶＭ 分类。
－ｇ

３００

上下文窗口

１６３

ｒ
ａ
ｃ
ｔ
ｅ
ｒ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ：利 用 ｗｏ
ｒｄ２ｖｅ
ｃ训 练
 ＣＮＮ－ｃｈａ
出的字级别的词 向 量 进 行 实 验。 在 实 验 过 程 中，词
向量保持不变，只学习模型的其他参数。
ｒ
ａ
ｃ
ｔ
ｅ
ｒ－ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ： 利 用 ｗｏ
ｒｄ２ｖｅ
ｃ
 ＣＮＮ－ｃｈａ
训练出的 字 级 别 的 词 向 量 进 行 试 验。 在 实 验 过 程
中，词向量会被微调，同时学习模型的其他参数。
各个模型的实验结果如表 ４ 所示。
表 ４ 不同模型的准确率
模型

ＣＯＡＥ

ＳＶＭ ｂｏｗ１

８９．３６

ＳＶＭ ｂｏｗ２

９１．
７４

ＳＶＭ ｂｏｗ３

９２．
１３

ｒ
ｄ－ｒ
ａｎｄ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ
ＣＮＮ－ｗｏ

９１．
９４

词袋向量作 为 输 入，利 用 线 性 核 ＳＶＭ 进 行 了 微 博

ｒ
ｄ－ｒ
ａｎｄ－ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ
ＣＮＮ－ｗｏ

９３．
０６

情感倾向性分类。本文对 三 种 类 型 的 Ｎ－ｇ
ｒ
ａｍ 词 袋

ｒ
ｄ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ
ＣＮＮ－ｗｏ

９３．
８０

ＣＮＮ－ｗｏ
ｒ
ｄ－ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ

９４．
６５

ＣＮＮ－ｃｈａ
ｒ
ａ
ｃ
ｔ
ｅ
ｒ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ

９４．
２９

ｒ
ａ
ｃ
ｔ
ｅ
ｒ－ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ
ＣＮＮ－ｃｈａ

９５．
４２

４．
３ 对比实验
本文与传统的词袋模型进行了对比，将 Ｎ－ｇ
ｒ
ａｍ

模型进 行 了 测 试：ｂｏｗ１Ｎ ∈ ｛
１｝，
１，
ｂｏｗ２Ｎ ∈ ｛
２｝，ｂｏｗ３Ｎ ∈ ｛
１，
２，
３｝。其中，
ｂｏｗ１ 是传统的词袋
向量，
ｒ
ｉ
ａｍ 或
ｂｏｗ２ 向 量 中 的 每 一 个 元 素 表 示 ｕｎ
－ｇ
ｒ
ｂ
ｉ
ａｍ 特 征，而 ｂｏｗ３ 向 量 中 的 每 一 个 元 素 表 示
－ｇ
ｒ
ｒ
ｒ
ｉ
ａｍ、
ｂ
ｉ
ａｍ 或 者 ｔ
ｒ
ｉ
ａｍ 特 征，其 中 的 特 征
ｕｎ
－ｇ
－ｇ
－ｇ
值使用 ＴＦ－ＩＤＦ 方 法 计 算，并 使 用 了 ｌ
ｉ
ｂＳＶＭ 进 行

４．
４．
１ Ｒａｎｄｏｍ ｖｓ．ｗｏ
ｒｄ２ｖｅ
ｃ
通过 比 较 ＣＮＮ－ｗｏ
ｒｄ－ｒ
ａｎｄ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ（
９１．
９４％ ）和

中 文 信 息 学 报

１６４

ＣＮＮ－ｗｏ
ｒｄ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ（
９３．
８０％ ）的准 确 率，可 以 发 现，利
用预训练的词向量作为原始输入进行情感倾向性分
析的准确率要高于利用随机初始化的词向量作为原

２０１５ 年
表 ５ 词向量相似度比较
词语

词语

余弦相似度

手机

三星

０．６６８

手＋机

三＋星

０．
７２７

车险

保险

６３７
０．

好的效果。实验表 明，利 用 卷 积 神 经 网 络 模 型 进 行

车＋险

保＋险

６８７
０．

自然语言处理时，无 监 督 方 式 预 训 练 的 词 向 量 是 十

酸奶

牛奶

８０５
０．

分重要的。

酸＋奶

牛＋奶

０．
８５１

始输入进行的情感倾向性分析的准确率。原因在于
利用 ｗｏ
ｒｄ２ｖｅ
ｃ工具训 练 出 的 词 向 量 包 含 了 上 下 文
语义信息，因此在进 行 句 子 情 感 分 析 时 可 以 得 到 更

４．
２ Ｓ
ｔ
ａ
ｔ
ｉ
ｃｖｓ．Ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ
４．
通 过 比 较 ＣＮＮ－ｃｈａ
ｒ
ａ
ｃ
ｔ
ｅ
ｒ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ（
９４．
２９％ ）和
ＣＮＮ－ｃｈａ
ｒ
ａ
ｃ
ｔ
ｅ
ｒ－ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ （９５．
４２％ ），ＣＮＮ－ｗｏ
ｒ
ｄ－
（
）
（
和
ｓ
ｔ
ａ
ｔ
ｉ
ｃ ９３．
８０％
ＣＮＮ－ｗｏ
ｒ
ｄ－ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ ９４．
６５％），

另一个原因在于：传统的分词技术往往对微 博
“我发现了一个高大上网站”，
造成歧义的切分，例如，
“高大上网站”如果使用传统分词技术，会
在该句中，

ｒ
ｄ－ｒ
ａｎｄ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ（
９１．
９４％）和 ＣＮＮ－ｗｏ
ｒ
ｄ－ｒ
ａｎｄ－
ＣＮＮ－ｗｏ
ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ（
９３．
０６％）的准确率，可以发现，在卷积神经

被切分为“高大／上／网站”或者“高大／上网／站”，这样

网络的训练过程中对预训练的词向量进行微调，可以

将“网站”切分导致丢失评价对象。而将字级别特征

进一步提升模型的准确率。实验表明，在模型训练过
程中对词向量进行微调，可以让预训练的词向量更加

作为输 入，通 过 并 行 的 卷 积 层 可 以 学 习 到 不 同 Ｎ－
ｒ
ａｍ 的信息，例 如 “高 大 上”（
Ｎ＝３）、“高 大 上 网 站”
ｇ

适应于专门的任务，从而进一步提高准确率。

（
ｉ
ｅ
ｂ
ａ分词工具和ＩＣＴＡＬＡＳ 分
Ｎ＝５）。本文分别用 Ｊ

４．
３ Ｃｈａ
ｒ
ａ
ｃ
ｔ
ｅ
ｒ－ｌ
ｅｖｅ
ｌｖｓ．Ｗｏ
ｒｄ－ｌ
ｅｖｅ
ｌ
４．
通过比较 ＣＮＮ－ｗｏ
ｒｄ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ（
９３．
８０％ ）和 ＣＮＮ－

词工具进行分词，得到了相近的实验结果。

ｃｈａ
ｒ
ａ
ｃ
ｔ
ｅ
ｒ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ（
９４．２９％ ），ＣＮＮ－ｗｏ
ｒｄ－ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ
（
）
（
９４．
６５％ 和 ＣＮＮ－ｃｈａ
ｒ
ａ
ｃ
ｔ
ｅ
ｒ－ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ ９５．
４２％ ）

的切分无法体现句子的正确语义，甚至后一种切分还

ｒ
４．
４ Ｂａｇ－ｏ
ｆ－Ｎ－ｇ
ａｍ ｖｓ．ＣＮＮ
４．
通过比较 ＳＶＭ ｂｏｗ３（
９２．
１３％ ）和 ＣＮＮ－ｃｈａ
ｒ－

的准确率，可以发现，使用字级别词向量作为原始特

ａ
ｃ
ｔ
ｅ
ｒ－ｎｏｎ－ｓ
ｔ
ａ
ｔ
ｉ
ｃ（
９５．
４２％ ）的 准 确 率，可 以 发 现，在
微博情感倾向性分 析 中，卷 积 神 经 网 络 模 型 要 优 于

征要好于使用词级别词向量作为原始特征。实验表

传统的词袋模型。通过比较 ＳＶＭ ｂｏｗ１（
８９．
３６％ ）、

明，对于中文语料而言，使用字级别词向量作为原始

９１．
７４％ ）和 ＳＶＭ ｂｏｗ３（
９２．
３１％ ）的准
ＳＶＭ ｂｏｗ２（

特征会好于使用词级别词向量作为原始特征。

确率，可 以 发 现，
ｒ
ｒ
ｉ
ａｍ 和 ｔ
ｒ
ｉ
ａｍ 特 征 让 准 确 率
ｂ
－ｇ
－ｇ

结合实验结果及分析原因主要在于：字级别特

有了明显提 升。 而 当 Ｎ 较 大 时，会 造 成 维 度 灾 难，

征的粒度比词级别 的 粒 度 小，字 级 别 词 向 量 相 比 于

导致模型难以训练。而包含多个并行卷积层的卷积

词级别词向量可以学习到更加具体的特征。

神经网络，可以利用不同大小的卷积核学习不同 Ｎ－

表 ５ 展示了 利 用 ｗｏ
ｒｄ２ｖｅ
ｃ工 具 训 练 的 字 级 别
词向量相 加 得 到 的 词 级 别 词 向 量 相 似 度 与 直 接 用

ｒ
ａｍ 的信息，通过 池 化 操 作 降 低 维 度，从 而 使 得 模
ｇ
型的准确率得以提高。

ｒｄ２ｖｅ
ｃ工具训 练 得 到 的 词 级 别 词 向 量 相 似 度 之
ｗｏ
间的比较。通过对比可以得出利用字级别词向量相

５ 总结

加得到的词级别词向量之间的相似度要高于直接用
ｒｄ２ｖｅ
ｃ工具训 练 得 到 的 词 级 别 词 向 量 之 间 的 相
ｗｏ
似度。

本文探讨了利用卷积神经网络进行微博情感倾
向性分析的可行性，并 利 用 卷 积 神 经 网 络 模 型 取 得

但是也存在一些词语组合不存在这种情况。例

了优于传统词袋模 型 的 准 确 率，以 此 证 明 了 卷 积 神

如，“三元”与 “牛 奶 ”之 间 的 相 似 度 为 ０．
７８３，因 为

经网络在微博情感倾向性分析中的可行性。本文利

“三元”是一个牛奶 品 牌，所 以 两 者 之 间 的 相 似 度 较

用字级别词向量及词级别词向量的卷积神经网络分

高，而“三”＋ “元”与“牛”＋ “奶”之 间 的 相 似 度 要 小

别取得了 ９５．
４２％ 的 准 确 率 和 ９４．
６５％ 的 准 确 率，

于 ０．
７８３。出现这种情况的可能 原 因 是 由 于 语 料 中

实验结果可见，对于中文微博语料而言，利用卷积神

关于“三元”的内容 不 多，以 至 于 字 级 别 的 词 向 量 没

经网络进行微博情 感 倾 向 性 分 析 是 有 效 的，且 使 用

有较好地学到相关的信息。

字级别的词向量作为原始特征会好于使用词级别的

刘龙飞等：基于卷积神经网络的微博情感倾向性分析

６期

词向量作为原始特征。

参考文献

１６５

ａｎｄ．２０１４．
ｌ
［
１０］ Ｋｉｍ Ｙ．Ｃｏｎｖｏ
ｌ
ｕ
ｔ
ｉ
ｏｎａ
ｌｎｅｕ
ｒ
ａ
ｌｎｅ
ｔｗｏ
ｒ
ｋｓｆ
ｏ
ｒｓ
ｅｎ
ｔ
ｅｎｃ
ｅ
［
］
，
／
／
ｃ
ｌ
ａ
ｓ
ｓ
ｉ
ｆ
ｉ
ｃ
ａ
ｔ
ｉ
ｏｎ Ｃ Ｐｒ
ｏ
ｃ
ｅ
ｅｄ
ｉ
ｎｇｓｏ
ｆｔ
ｈｅＥＭＮＬＰ ２０１４．
［
１１］ Ｔｕ
ｒ
ｎｅｙＰ Ｄ．Ｔｈｕｍｂｓｕｐｏ
ｒｔ
ｈｕｍｂｓｄｏｗｎ？：ｓ
ｅｍａｎ
ｔ
ｉ
ｃ

［
１］ Ｐａ
ｎｇＢ，Ｌｅ
ｅ Ｌ．Ｓ
ｅ
ｅ
ｉ
ｎｇｓ
ｔ
ａ
ｒ
ｓ：Ｅｘｐ
ｌ
ｏ
ｉ
ｔ
ｉ
ｎｇｃ
ｌ
ａ
ｓ
ｓｒ
ｅ
ｌ
ａ
ｔ
ｉ
ｏｎ－
ｈ
ｉ
ｓｆ
ｏ
ｒｓ
ｅ
ｎ
ｔ
ｉｍｅ
ｎ
ｔｃ
ａ
ｔ
ｅ
ｒ
ｉ
ｚ
ａ
ｔ
ｉ
ｏｎ ｗ
ｉ
ｔ
ｈｒ
ｅ
ｓ
ｅ
ｃ
ｔｔ
ｏｒ
ａ
ｔ
ｉ
ｎｇ
ｓ
ｐ
ｇｏ
ｐ
／／Ｐｒ
ｓ
ｃ
ａ
ｌ
ｅ
ｓ［
Ｃ］
ｏ
ｃ
ｅ
ｅ
ｄ
ｉ
ｎｇ
ｓｏ
ｆｔ
ｈ
ｅ４３
ｒ
ｄ Ａｎｎｕ
ａ
ｌ Ｍｅ
ｅ
ｔ
ｉ
ｎｇｏｎ
Ａｓ
ｓ
ｏ
ｃ
ｉ
ａ
ｔ
ｉ
ｏｎｆ
ｏ
ｒＣｏｍｐｕ
ｔ
ａ
ｔ
ｉ
ｏｎ
ａ
ｌＬ
ｉ
ｎｇｕ
ｉ
ｓ
ｔ
ｉ
ｃ
ｓ．Ａｓ
ｓ
ｏ
ｃ
ｉ
ａ
ｔ
ｉ
ｏｎｆ
ｏ
ｒ
Ｃｏｍｐｕ
ｔ
ａ
ｔ
ｉ
ｏｎ
ａ
ｌＬ
ｉ
ｎｇｕ
ｉ
ｓ
ｔ
ｉ
ｃ
ｓ，２００５：１１５－１２４．
［
２］ 梁军，柴 玉 梅，原 慧 斌，等 ．基 于 深 度 学 习 的 微 博 情
感分析［
５）：１５５－１６１．
Ｊ］．中文信息学报，２０１４，２８（
［
３］ 罗毅，李 利，谭 松 波，等 ．基 于 中 文 微 博 语 料 的 情 感
倾向性分 析 ［
Ｊ］．山 东 大 学 学 报 （理 学 版 ），２０１４，４９
（
１１）：１－７．
［
４］ ＬｅＣｕｎ Ｙ，Ｂｏ
ｔ
ｔ
ｏｕＬ，Ｂｅｎｇ
ｉ
ｏ Ｙ，ｅ
ｔａ
ｌ．Ｇｒ
ａｄ
ｉ
ｅｎ
ｔ－ｂａ
ｓ
ｅｄ
／／Ｐｒ
ｏ－
ｌ
ｅ
ａ
ｒ
ｎ
ｉ
ｎｇ ａｐｐ
ｌ
ｉ
ｅｄ ｔ
ｏ ｄｏ
ｃｕｍｅｎ
ｔｒ
ｅ
ｃ
ｏｇｎ
ｉ
ｔ
ｉ
ｏｎ ［Ｃ］
ｅ
ｅｄ
ｉ
ｎｇｓｏ
ｆｔ
ｈｅＩＥＥＥ，１９９８，８６（
１１）：２２７８－２３２４．
ｃ
［
］
，
，
５ Ｙ
ｏ
ｒｓ
ｉ
ｎｇ
ｌ
ｅ－ｒ
ｉ
ｈ Ｗ ＨｅＸ Ｍｅ
ｅ
ｋＣ．Ｓ
ｅｍａ
ｎ
ｔ
ｉ
ｃｐ
ａ
ｒ
ｓ
ｉ
ｎｇｆ
ｅ
ｌ
ａ－
／／Ｐｒ
ｔ
Ｃ］
ｉ
ｏｎｑｕ
ｅ
ｓ
ｔ
ｉ
ｏｎａ
ｎ
ｓｗｅ
ｒ
ｉ
ｎｇ［
ｏ
ｃ
ｅ
ｅ
ｄ
ｉ
ｎｇ
ｓｏ
ｆＡＣＬ２０１４．
［
６］ Ｓｈｅｎ Ｙ，ＨｅＸ，ＧａｏＪ，ｅ
ｅｍａｎ
ｔ
ｉ
ｃｒ
ｅｐ
ｒ
ｅ－
ｔａ
ｌ．Ｌｅ
ａ
ｒ
ｎ
ｉ
ｎｇｓ
ｏｎｖｏ
ｌ
ｕ
ｔ
ｉ
ｏｎａ
ｌｎｅｕ
ｒ
ａ
ｌｎｅ
ｔｗｏ
ｒ
ｋｓｆ
ｏ
ｒｗｅｂ
ｅｎ
ｔ
ａ
ｔ
ｉ
ｏｎｓｕｓ
ｉ
ｎｇｃ
ｓ
／／Ｐｒ
ｓ
ｅ
ａ
ｒ
ｃｈ［
Ｃ］
ｏ
ｃ
ｅ
ｅｄ
ｉ
ｎｇｓｏ
ｆｔ
ｈｅｃ
ｏｍｐａｎ
ｉ
ｏｎ ｐｕｂ
ｌ
ｉ
ｃ
ａ
ｔ
ｉ
ｏｎ
ｏ
ｆｔ
ｈｅ２３ｒ
ｄｉ
ｎ
ｔ
ｅ
ｒ
ｎａ
ｔ
ｉ
ｏｎａ
ｌｃ
ｏｎ
ｆ
ｅ
ｒ
ｅｎｃ
ｅｏｎ Ｗｏ
ｒ
ｌ
ｄｗｉ
ｄｅｗｅｂ
ｃ
ｏｍｐａｎ
ｉ
ｏｎ．Ｉ
ｎ
ｔ
ｅ
ｒ
ｎａ
ｔ
ｉ
ｏｎａ
ｌ Ｗｏ
ｒ
ｌ
ｄ Ｗｉ
ｄｅ Ｗｅｂ Ｃｏｎ
ｆ
ｅ
ｒ－
ｅｎｃ
ｔ
ｔ
ｅ
ｅ，２０１４：３７３－３７４．
ｅ
ｓＳ
ｔ
ｅ
ｅ
ｒ
ｉ
ｎｇＣｏｍｍｉ
［
］
，
７ Ｂ
ｌ
ｕｎｓ
ｏｍ Ｐ Ｇｒ
ｅ
ｆ
ｅｎｓ
ｔ
ｅ
ｔ
ｔ
ｅＥ，Ｋａ
ｌ
ｃｈｂ
ｒ
ｅｎｎｅ
ｒＮ．Ａｃ
ｏｎｖ－
／／
ｅｎ
ｔ
ｅｎｃ
ｅ
ｓ［
Ｃ］
ｌ
ｕ
ｔ
ｉ
ｏｎａ
ｌｎｅｕ
ｒ
ａ
ｌｎｅ
ｔｗｏ
ｒ
ｋｆ
ｏ
ｒｍｏｄｅ
ｌ
ｌ
ｉ
ｎｇｓ
ｏ
Ｐｒ
ｆｔ
ｈｅＡｓ
ｓ
ｏ
ｃ
ｉ－
ｏ
ｃ
ｅ
ｅｄ
ｉ
ｎｇｓｏ
ｆｔ
ｈｅ５２ｎｄＡｎｎｕａ
ｌＭｅ
ｅ
ｔ
ｉ
ｎｇｏ
ａ
ｔ
ｉ
ｏｎｆ
ｏ
ｒＣｏｍｐｕ
ｔ
ａ
ｔ
ｉ
ｏｎａ
ｌＬ
ｉ
ｎｇｕ
ｉ
ｓ
ｔ
ｉ
ｃ
ｓ．２０１４．
［
８］ Ｃｏ
ｌ
ｌ
ｏｂ
ｅ
ｒ
ｔＲ，Ｗｅ
ｓ
ｔ
ｏｎＪ，Ｂｏ
ｔ
ｔ
ｏｕＬ，ｅ
ｔａ
ｌ．Ｎａ
ｔ
ｕ
ｒ
ａ
ｌｌ
ａ
ｎｇｕ
ａ
ｅ
ｇ
（
）
［
］
ａ
ｌ
ｍ
ｏ
ｓ
ｔ
ｆ
ｒ
ｏ
ｍ
ｓ
ｃ
ｒ
ａ
ｔ
ｃ
ｈ
Ｊ
．
Ｔ
ｈ
ｅ
Ｊ
ｏ
ｕ
ｒ
ｎ
ａ
ｌ
ｏ
ｆ
Ｍ
ａ
ｒ
ｏ
ｃ
ｅ
ｓ
ｓ
ｉ
ｎ
－
ｐ
ｇ
ｃ
ｓ
ｅ
ａ
ｒ
ｃ
ｈ，２０１１，１２：２４９３－２５３７．
ｈ
ｉ
ｎ
ｅＬｅ
ａ
ｒ
ｎ
ｉ
ｎｇＲｅ
［
９］ ｄｏ
ｏｎｖｏ
ｌ
ｕ
ｔ
ｉ
ｏｎａ
ｌｎｅｕ
ｒ
ａ
ｌ
ｓＳａｎ
ｔ
ｏ
ｓ Ｃ Ｎ，Ｇａ
ｔ
ｔ
ｉ Ｍ．Ｄｅ
ｅｐｃ
［
］
／
／
ｎｅ
ｔｗｏ
ｒ
ｋｓｆ
ｏ
ｒｓ
ｅｎ
ｔ
ｉｍｅｎ
ｔａｎａ
ｌ
ｓ
ｉ
ｓｏ
ｆｓｈｏ
ｒ
ｔｔ
ｅｘ
ｔ
ｓＣ
ｙ
Ｐｒ
ｏ
ｃ
ｅ
ｅｄ
ｉ
ｎｇｓｏ
ｆｔ
ｈｅ ２５
ｔ
ｈＩ
ｎ
ｔ
ｅ
ｒ
ｎａ
ｔ
ｉ
ｏｎａ
ｌ Ｃｏｎ
ｆ
ｅ
ｒ
ｅｎｃ
ｅ ｏｎ
Ｃｏｍｐｕ
ｔ
ａ
ｔ
ｉ
ｏｎａ
ｌＬ
ｉ
ｎｇｕ
ｉ
ｓ
ｔ
ｉ
ｃ
ｓ （ＣＯＬＩＮＧ）．Ｄｕｂ
ｌ
ｉ
ｎ，Ｉ
ｒ
ｅ－
刘龙飞（
１９８９—），硕 士 研 究 生，主 要 研 究 领 域 为

ｏ
ｒ
ｉ
ｅｎ
ｔ
ａ
ｔ
ｉ
ｏｎ ａｐｐ
ｌ
ｉ
ｅｄ ｔ
ｏ ｕｎｓｕｐｅ
ｒ
ｖ
ｉ
ｓ
ｅｄ ｃ
ｌ
ａ
ｓ
ｓ
ｉ
ｆ
ｉ
ｃ
ａ
ｔ
ｉ
ｏｎ ｏ
ｆ
／／Ｐｒ
ｒ
ｅ
ｖ
ｉ
ｅｗｓ［
Ｃ］
ｏ
ｃ
ｅ
ｅｄ
ｉ
ｎｇｓｏ
ｆｔ
ｈｅ４０
ｔ
ｈａｎｎｕａ
ｌｍｅ
ｅ
ｔ
ｉ
ｎｇ
ｏｎａ
ｓ
ｓ
ｏ
ｃ
ｉ
ａ
ｔ
ｉ
ｏｎｆ
ｏ
ｒｃ
ｏｍｐｕ
ｔ
ａ
ｔ
ｉ
ｏｎａ
ｌｌ
ｉ
ｎｇｕ
ｉ
ｓ
ｔ
ｉ
ｃ
ｓ．Ａｓ
ｓ
ｏ
ｃ
ｉ
ａ－
，
：
ｉ
ｏｎｆ
ｏ
ｒＣｏｍｐｕ
ｔ
ａ
ｔ
ｉ
ｏｎａ
ｌＬ
ｉ
ｎｇｕ
ｉ
ｓ
ｔ
ｉ
ｃ
ｓ ２００２ ４１７－４２４．
ｔ
［
１２］ Ｋｒ
ｉ
ｚｈｅ
ｖ
ｓｋｙ Ａ，Ｓｕ
ｔ
ｓｋｅ
ｖｅ
ｒＩ，Ｈｉ
ｎ
ｔ
ｏｎ Ｇ Ｅ．Ｉｍａｇｅｎｅ
ｔ
ｃ
ｌ
ａ
ｓ
ｓ
ｉ
ｆ
ｉ
ｃ
ａ
ｔ
ｉ
ｏｎ ｗｉ
ｔ
ｈｄｅ
ｅｐｃ
ｏｎｖｏ
ｌ
ｕ
ｔ
ｉ
ｏｎａ
ｌｎｅｕ
ｒ
ａ
ｌｎｅ
ｔｗｏ
ｒ
ｋｓ
［
］
／
／
Ｃ Ａｄｖａｎｃ
ｅ
ｓｉ
ｎｎｅｕ
ｒ
ａ
ｌｉ
ｎ
ｆ
ｏ
ｒｍａ
ｔ
ｉ
ｏｎｐ
ｒ
ｏ
ｃ
ｅ
ｓ
ｓ
ｉ
ｎｇｓｙ
ｓ－
ｅｍｓ．２０１２：１０９７－１１０５．
ｔ
［
１３］ Ｃｏ
ｌ
ｌ
ｏｂｅ
ｒ
ｔＲ．Ｄｅ
ｅｐｌ
ｅ
ａ
ｒ
ｎ
ｉ
ｎｇｆ
ｏ
ｒｅ
ｆ
ｆ
ｉ
ｃ
ｉ
ｅｎ
ｔｄ
ｉ
ｓ
ｃ
ｒ
ｉｍｉ
ｎａ
ｔ
ｉ
ｖｅ
／／Ｐｒ
ｒ
ｓ
ｉ
ｎｇ［
Ｃ］
ｏ
ｃ
ｅ
ｅｄ
ｉ
ｎｇｓｏ
ｆｔ
ｈｅＩ
ｎ
ｔ
ｅ
ｒ
ｎａ
ｔ
ｉ
ｏｎａ
ｌＣｏｎ
ｆ
ｅ
ｒ－
ｐａ
ｅ ｏｎ Ａｒ
ｔ
ｉ
ｆ
ｉ
ｃ
ｉ
ａ
ｌＩ
ｎ
ｔ
ｅ
ｌ
ｌ
ｉ
ｅ ａｎｄ Ｓ
ｔ
ａ
ｔ
ｉ
ｓ
ｔ
ｉ
ｃ
ｓ．２０１１
ｅｎｃ
ｇｅｎｃ
（
）
ＥＰＦＬ－ＣＯＮＦ－１９２３７４ ．
［
１４］ Ｌｕｏｎｇ Ｍ Ｔ，Ｓｏ
ｃｈｅ
ｒＲ，Ｍａｎｎ
ｉ
ｎｇ Ｃ Ｄ．Ｂｅ
ｔ
ｔ
ｅ
ｒ ｗｏ
ｒ
ｄ
ｒ
ｅｐ
ｒ
ｅ
ｓ
ｅｎ
ｔ
ａ
ｔ
ｉ
ｏｎｓ ｗｉ
ｔ
ｈｒ
ｅ
ｃｕ
ｒ
ｓ
ｉ
ｖｅ ｎｅｕ
ｒ
ａ
ｌ ｎｅ
ｔｗｏ
ｒ
ｋｓ ｆ
ｏ
ｒ
［
］
／
／
ｍｏ
ｒ
ｌ
ｏｇｙ Ｃ Ｐｒ
ｏ
ｃ
ｅ
ｅｄ
ｉ
ｎｇｓ ｏ
ｆｔ
ｈｅ ＣｏＮＬＬ－２０１３，
ｐｈｏ
２０１３，１０４．
［
ｏ
ｒＣｈ
ｉ
ｎｅ
ｓ
ｅ
ａ
ｒ
ｎ
ｉ
ｎｇｆ
１５］ ＺｈｅｎｇＸ，Ｃｈｅｎ Ｈ，ＸｕＴ．Ｄｅ
ｅｐＬｅ
／／Ｐｒ
Ｃ］
Ｗｏ
ｒ
ｄＳｅｇｍｅｎ
ｔ
ａ
ｔ
ｉ
ｏｎａｎｄ ＰＯＳ Ｔａｇｇ
ｉ
ｎｇ［
ｏ
ｃ
ｅ
ｅｄ－
ｉ
ｎｇｓｏ
ｆｔ
ｈｅＥＭＮＬＰ．２０１３：６４７－６５７．
［
］
ｔ
ｈ
１６ Ｓｏ
ｔａ
ｌ．Ｐａ
ｒ
ｓ
ｉ
ｎｇｗｉ
ｃｈｅ
ｒＲ，Ｂａｕｅ
ｒＪ，Ｍａｎｎ
ｉ
ｎｇＣＤ，ｅ
／／Ｐｒ
ｃ
ｏｍｐｏ
ｓ
ｉ
ｔ
ｉ
ｏｎａ
ｌｖｅ
ｃ
ｔ
ｏ
ｒｇ
ｒ
ａｍｍａ
ｒ
ｓ［Ｃ］
ｏ
ｃ
ｅ
ｅｄ
ｉ
ｎｇｓ ｏ
ｆ
ｔ
ｈｅＡＣＬｃ
ｏｎ
ｆ
ｅ
ｒ
ｅｎｃ
ｅ．２０１３．
［
］
，
１７ Ｍｉ
ｋｏ
ｌ
ｏｖ Ｔ Ｓｕ
ｔ
ｓｋｅ
ｖｅ
ｒＩ，Ｃｈｅｎ Ｋ，ｅ
ｔａ
ｌ．Ｄｉ
ｓ
ｔ
ｒ
ｉ
ｂｕ
ｔ
ｅｄ
ｒ
ｅｐ
ｒ
ｅ
ｓ
ｅｎ
ｔ
ａ
ｔ
ｉ
ｏｎｓｏ
ｆ ｗｏ
ｒ
ｄｓａｎｄｐｈｒ
ａ
ｓ
ｅ
ｓａｎｄｔ
ｈｅ
ｉ
ｒｃ
ｏｍ－
［
］
／
／
Ｃ
ｓ
ｉ
ｔ
ｉ
ｏ
ｎ
ａ
ｌ
ｉ
ｔ
ｒ
ｏ
ｃ
ｅ
ｅ
ｄ
ｉ
ｎ
ｓ
ｏ
ｆ
ｔ
ｈ
ｅ
Ａ
ｄ
ｖ
ａ
ｎ
ｃ
ｅ
ｓ
ｉ
ｎ
Ｐ
ｏ
ｙ
ｇ
ｐ
ｓ
ｔ
ｅｍｓ．２０１３：３１１１－
Ｎｅｕ
ｒ
ａ
ｌＩ
ｎ
ｆ
ｏ
ｒｍａ
ｔ
ｉ
ｏｎＰｒ
ｏ
ｃ
ｅ
ｓ
ｓ
ｉ
ｎｇＳｙ
３１１９．
［
］
１８ Ｚｅ
ａ
ｔ
ｅ
ｉ
ｌ
ｅ
ｒ Ｍ Ｄ．ＡＤＡＤＥＬＴＡ：ａｎａｄａｐ
ｔ
ｉ
ｖｅｌ
ｅ
ａ
ｒ
ｎ
ｉ
ｎｇｒ
ｍｅ
ｔ
ｈｏｄ［
Ｊ］．ａ
ｒＸｉ
ｖｐ
ｒ
ｅｐ
ｒ
ｉ
ｎ
ｔａ
ｒＸｉ
ｖ：
１２１２．
５７０１，２０１２．
［
１９］ ＣｈａｎｇＣＣ，Ｌ
ｉ
ｎＣＪ．ＬＩＢＳＶＭ：Ａｌ
ｉ
ｂ
ｒ
ａ
ｒ
ｏ
ｒｓｕｐｐｏ
ｒ
ｔ
ｙｆ
［
］
ｖｅ
ｃ
ｔ
ｏ
ｒｍａ
ｃｈ
ｉ
ｎｅ
ｓＪ ．ＡＣＭ Ｔｒ
ａｎｓ
ａ
ｃ
ｔ
ｉ
ｏｎｓｏｎＩ
ｎ
ｔ
ｅ
ｌ
ｌ
ｉ
ｔ
ｇｅｎ
Ｓｙ
ｓ
ｔ
ｅｍｓａｎｄＴｅ
ｃｈｎｏ
ｌ
ｏｇｙ （
ＴＩ
ＳＴ），２０１１，２（
３）：２７．

杨亮（
１９８６—），博 士 研 究 生，主 要 研 究 领 域 为 情

机器学习、情感计算。

感分析、自然语言理解。

Ｅ－ｍａ
ｉ
ｌ：ｌ
ｉ
ｕｄ
ｒ
ａｇｏｎ
ｆ
ｌ
ｉ
ｌ．
ｄ
ｌ
ｕ
ｔ．
ｅｄｕ．
ｃｎ
ｙ＠ｍａ

Ｅ－ｍａ
ｉ
ｌ：ｙａｎｇ
ｌ
ｉ
ａｎｇ＠ｍａ
ｉ
ｌ．
ｄ
ｌ
ｕ
ｔ．
ｅｄｕ．
ｃｎ

张绍武（
１９６７—），博士，副教授，主 要 研 究 领 域 为
情感计算和搜索引擎。
Ｅ－ｍａ
ｉ
ｌ：ｚｈａｎｇｓｗ＠ｄ
ｌ
ｕ
ｔ．
ｅｄｕ．
ｃｎ