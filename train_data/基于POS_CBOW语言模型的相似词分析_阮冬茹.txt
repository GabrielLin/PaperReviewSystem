第卷第期河北科技大学学报年月文章编号基于语言模型的相似词分析阮冬茹潘洪岩高凯河北科技大学信息科学与工程学院河北石家庄摘要相似词分析是自然语言处理领域的研究热点之一在文本分类机器翻译和信息推荐等领域中具有重要的研究价值和应用意义针对新浪微博短文本的特点给出一种带词性的连续词袋模型该模型在连续词袋模型的基础上加入过滤层和词性标注层对空间词向量进行优化和词性标注通过空间词向量的余弦相似度和词性相似度来判别词向量的相似性并利用统计分析模型筛选出最优相似词集合实验表明基于语言模型的相似词分析算法优于传统语言模型关键词自然语言处理语言模型词向量相似词中图分类号文献标志码相似词分析是近些年自然语言处理领域的研究热点之一在文本分类机器翻译以及信息推荐等领域中有着广泛应用目前相似词的分析大都需要人为干预为主的方法借助人工标注词典来设定词的相似性但是随着社交网络中网络新词的不断涌现基于人工标注的方法已无法完成庞大的标注任务而且由于社交网络的短文本特征如数据量庞大书写不规范等传统方法已无法得到较好的分析结果现阶段自然语言处理深度学习等领域的相似词分析研究是解决这一问题的主要手段之一收稿日期修回日期责任编辑陈书欣基金项目河北省社会科学发展研究课题资助项目作者简介阮冬茹女河北怀安人副教授主要从事自然语言处理微博计算方面的研究通讯作者高凯副教授阮冬茹潘洪岩高凯基于语言模型的相似词分析河北科技大学学报第期阮冬茹等基于语言模型的相似词分析相关研究工作中等利用个语句对相似词的概念进行了阐述句子和句子个语句在句式结构上非常相似等定义了和和和和和等为相似词文献在神经网络语言模型基础上进行了完善重点解决了高维空间的维度问题利用词在高维空间的概率分布得到词与词的相似度等在等工作的基础上对神经网络做了进一步优化减少了神经网络的参数提升了训练速度并提出了一种新的神经网络语言模型运用单隐含层的神经网络生成词向量计算词的相似性并在文献中进一步优化提出了循环神经网络语言模型等提出了模型和连续模型这两种模型都是一种类前馈神经网络语言模型不同的是模型是预测相似词而模型是预测相近词随后等提出了将词的相似性关系应用于机器翻译领域成功地预测低频率词汇并提出了对短语的相似性分析和词向量的隐含语义关系分析等对稀疏空间向量的语义规律关系进一步进行研究和完善等针对和在词向量的相近性和歧义性上的缺陷提出了模型从而将准确率提高了约等利用与模型相结合的方法提升了神经网络语言模型在长文本和短文本中的处理效果文献中在词袋模型的基础上提出了段向量相对于词向量而言它克服了原有模型的一些缺陷在文本分类和语义分析等领域表现良好等利用模型在语义层面对文本做重复性检测利用混合模型将文本生成了向量进而计算文本的相似度等提出了基于语言模型的概率语言模型该模型通过对有序词序列生成词向量然后利用给出的词向量模型来预测词序列中下一个词向量该模型是表现较好的模型等提出了一种文档主题生成模型利用词袋的方法将文档的词生成向量从而利用概率分布生成主题该模型是一个三层贝叶斯概率模型词袋中的词是无序的所以简化了模型复杂度提高了训练速度等提出了一种模型来计算词向量的语义信息和情绪信息利用监督与非监督的混合方法从语料中训练得到的词向量不仅有语义信息还包含丰富的情绪信息在情绪分类方面表现较好在中文研究领域中词语的相似度计算大都依托于同义词林和中文等文献采用同义词词林作为语义体系对中文词语的同义词识别进行了初步研究吴思颖等采用了一种基于中文的中英文词语相似度计算方法解决了候选同义词集组合的权重和取舍问题实现了一个可以计算英英汉英汉汉词语之间相似度的算法近年来非监督方法成为了相似词研究的新兴方法石静等基于大规模语料的训练在一定程度上提升了汉语语义相似度计算的准确率并实现了不同语域的集成文献中通过构造领域类别核心词集对词向量间语义关系进行了语义相似度的领域词语聚类分析文献提出了一种新的分词方法利用生成词向量对中文词进行聚类分析本文针对微博短文本的特点对等在中的开源连续词袋模型进行了调整和改进给出了一种基于的语言模型该模型将结构调整为输入层过滤层投影层词性标注层和输出层通过过滤层对微博短文本进行修正然后在词性标注层使生成的词向量带有词性信息进而以空间向量的余弦值和向量的词性比较为条件计算词的相似性实验证明该方法在微博短文本分析中有较输入层高的准确率投影层输出层语言模型语言模型是等阐述的一种类前馈神经网络语言模型由输入层投影层和输出层组成模型结构如图所示语言模型不同于标准词袋模型其引入了连续分布式词表示的方法形成了新的连续词袋模型语言模型通过将语料库词映射到投影层得到词典然后通过共享投影层使语料库词映射到投影层唯一的位置再通过的上下文信息预测而其中每个都与上文的图语言模型河北科技大学学报年词序列无关语言模型的基本训练步骤如下步骤在输入层通过限定输入层的上下文大小然后在窗口中顺序读取语料库词序列通过哈希表得到投影层的相应词位置获得词的上下个词步骤在投影层对的上下文做步骤操作为上下文累加和步骤从投影层到输出层利用词的上下文信息通过式来生成词的向量值其中式为词向量回归分析操作来完成对的判断综上语言模型与等提出的前馈神经网络语言模型相似该模型去掉了隐含层加快了语言模型的训练速度且模型中每个词向量的计算只与滑动窗口限定的有关系减少了模型的训练参数降低了模型复杂度提高了模型准确率但是语言模型仍然需要大量的训练集而且训练模型的好坏与上一级任务有密切关系滑动窗口概念的引入忽略掉了滑动窗口中的上下文内容对词的相似性计算产生的干扰语言模型及相似词计算语言模型本文给出的带有词性的连续词袋输入层过滤层投影层标注层输出层语言模型其结构如图所示该模型在语言模型的基础上增加了过滤层和词性标注层过滤层的主要作用是修正短文本语料语序优化词向量空间从而使语言模型相对于前一阶段的工作更加独立词性标注层的作用是对所有的词向量进行词性标注使空间词向量在潜在语义关系的基础上建立语法关系从而提高相似词计算的准确率语言模型的过滤层微博作为一种抒发情感的载体通常会加入一些符号来辅助情感的表达这些附加信息虽然具有一定含义但在本文的实际工作中它改变了训练语料图语言模型的正常语句结构对训练模型产生了干扰又因为微博的短文本这一特点使得这些符号在语句中占据较大权重而这对于传统的长文本分析算法来说是无法处理的难题例如微博博文符号在未经过滤处理的情况下极有可能会与成为相似词所以需要修正其为去掉文本中的噪音信息语言模型的过滤层介于输入层和投影层之间使用整理的微博文本停用词表对训练语料进行语句修正从而达到优化词向量空间的目的过滤层算法步骤如下步骤初始化哈希表初始值为步骤循环读取训练语料句子的词计算哈希值并以哈希值为下标步骤初始化过滤层大小为停用词表个数循环读取停用词并计算通用词哈希值记录到过滤层表步骤遍历读取表每项的值并查询是否等于等于则将否则循环继续直到遍历完毕过滤完毕第期阮冬茹等基于语言模型的相似词分析语言模型的词性标注层语言模型是一种概率模型通过将语料中词的上下文信息生成相应的词向量映射到高维空间中然后以词向量在高维空间中的关系来计算词与词之间的相似度这样虽然提高了训练效率加快了计算速度但是同时忽略了上下文信息中一些不符合相似词定义的词向量例如图是词向量中国的可视化图在其临近向量中出现了当今近年来国内海外等词这些词的出现在句子中位置均与中国临近但是严格地从相似词定义上来讲这些词不图词向量中国可视化图是中国的相似词为了排除上述词的干扰得到更加准确的相似词结果引入了词性标注层语言模型的词性标注层介于投影层和输出层之间通过中文分词工具对生成词向量进行词性标注所用词性为计算所有汉语词性标记集针对词的多词性这一性质对词语的词性建立了词性体系为相似词的计算提供词性参考体系以便得出更加完善的相似词集词性体系的构造步骤如下步骤以为根节点创建以为根节点的所有子节点步骤以上一级子节点为根节点创建相应节点下的子节点步骤查看上一级节点是否有子节点如果有重复步骤否则构造完毕如图所示图词性体系基于语言模型的相似词计算语言模型生成的词向量不仅包含潜在的语义关系还包含着语法关系语法关系的加入完善了语义关系的不足在相似词计算中以余弦相似度为计算方式以语法关系为计算准则进行词向量的相似性计算例如计算词向量中国的相似词计算模型将会查找与词向量中国同在一个父类词性下的词再计算词向量的余弦相似度从而得到个词向量的相似度其中考虑到新词问题把未知词性的词也加入结果集本文采用了两种择优算法一是算法选择个最优结果二是通过建立统计模型选出最优结果集词向量计算算法是择优的经典算法之一通过排名得出前个最优项作为结果本文在相似词的计算中利河北科技大学学报年用了的思想通过结合余弦相似度和词性信息个条件对整个词向量空间遍历计算后对相似词进行排序选出前个词作为结果集个相似词计算的基本步骤如下步骤取词向量空间第个词向量在词性体系中查找的父类词性如果与为同一父类词性或为进入步骤否则查看向量空间是否遍历完是则结束计算否重复步骤操作步骤计算余弦相似度返回步骤否则倒叙如果遍历集合比较相似度值如果小于将该位置的值后移插入到该位置重复步骤通过在算法中加入词性分析使同一词性体系的词聚集在一起而不同词性的词向量则被排除在外例如重新利用语言模型对词向量中国做相似词计算发现与词向量中国相邻近的词向量当今近些年国内和海外等被排出了结果集如图所示词向量的统计分析模型算法中相似词的计算结果往往受到值限定从而导致一些较优词向量的丢失为了能够更加充分地获取最优结果集本文给出了图基于语言模型相似词计算的结果另一种相似词计算方法采用一种动态阈值的统计分析模型来选出结果集首先计算出余弦相似度大于的所有词向量获取相似度集合计算集合的三阶标准化矩统计分析出相似度值的概率分布如图所示根据相似度集合的偏度得出词向量相似度值的整体分布情况如果词向量相似度集合为正偏态阈值设为集合的平均数即结果集合为平均数的右侧部分如果集合偏度为负偏度那么阈值就选择集合的中位数即结果集合为中位数的右侧部分表为集合的概率分布和阈值选择情况表集合概率分布及阈值选取负偏度正偏度偏度分布状态阈值平均数中位数众数平均数众数中位数平均数中位数平均数中位数平均数或中位数图偏度与数值的概率分布三阶标准化矩偏度公式为推导后得出偏度值公式为珚珚输入词向量相似词计算算法步骤如下步骤取词向量空间第个词向量在词性体系中查找的父类词性如果与为同一父类词性或为进入步骤否则查看向量空间是否遍历完是则结束计算否重复步骤操作第期阮冬茹等基于语言模型的相似词分析步骤计算余弦相似度如果倒叙遍历集合比较相似度值如果小于将该位置的值后值后移插入到该位置重复步骤否则进入步骤步骤计算的偏度的三阶标准化矩如果的偏度为正偏态计算平均值以平均值为阈值筛选出最优词向量集合如果偏度为负计算中位数以中位数为阈值获取最优向量集合实验对比及分析本文所用实验数据为新浪微博语料语言为中英文混合利用分词工具对语料进行分词整理出了文本得到词数约亿词的训练集训练得出约万条词向量实验硬件环境为台处理器代核线程内存分别利用中的模型和模型进行了训练值为层数为的情况下没有加入反例训练使用线程训练通过个模型的训练过程与训练结果的对比分析可得如下结论表经过模型的过滤层之后微博语料集被过滤掉了约的噪声证明针对微博数据的过滤层是有效的且生成的词向量空间相对来说压缩了约从整个模型的训练过程分析输入层的过滤与向量空间的压缩减少了训练过程中的迭代计算量提高了模型的计算效率从表可知在同样条件下模型的训练时间也比模型的训练时间节省了左右在接下来的实验中分别利用语言模型和语言模型对词向量中国进行了相似词计算利用式对语言模型和语言模型的相似词结果进行评价准确率相似词数结果集总数从图和图计算结果来看语言模型加入词性分析后与原语言模型相比不同词性的词向量被排除之后使得相同词性的词向量聚集在一起例如语言模型结果集中的本国西方某国当今和各国等不符合定义的词向量被过滤除去为了对比个模型的准确率对和语言模型计算结果进行了分析如表所示表语言模型和语言模型参数表相似词计算分析模型模型训练集总词数样本总词数过滤后的词数未加入过滤层名词数动词数网络层数其他训练线程相似词数时间准确率词向量数值由表分析可知针对特定输入词中国和两种语言模型的结果集都以名词性的词为主但是语言模型往往会有一些与该名词相关的动词或者其他不相关的词在内而这些词是不符合相似词定义的通过对比两种模型的结果按照定义进行人工标注语言模型的中相似词数约为准确率约为而语言模型则为准确率约为显然在加入词性分析后语言模型的准确率较高结语本文针对微博短文本给出了一种带有词性的连续词袋模型语言模型通过加入过滤层河北科技大学学报年和词性标注层对词向量空间进行优化和提升相似词计算的准确率实验表明语言模型在词向量空间质量和相似词计算方面优于语言模型提出的模型通过加入词性标注层对词向量空间起到了优化作用但对于期望词量之间能包含更多的语义关系和语法关系的要求目前尚有改进空间这也是未来的工作重点参考文献第一届全国信息检索与内容安全学术会议北京中国学术期刊电章成志词语的语义相似度计算及其应用研究子杂志出版社吴思颖吴扬扬基于中文的中英文词语相似度计算郑州大学学报理学版石静吴云芳邱立坤等基于大规模语料库的汉语词义相似度计算方法中文信息学报郑文超徐鹏利用对中文词进行聚类的研究软件第三十三届中国控制会议论文集北京中国学术期刊电子杂志罗杰王庆林李原基于与语义相似度的领域词聚类出版社