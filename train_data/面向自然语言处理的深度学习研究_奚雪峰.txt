第卷第期年月自动化学报面向自然语言处理的深度学习研究奚雪峰周国栋摘要近年来深度学习在图像和语音处理领域已经取得显著进展但是在同属人类认知范畴的自然语言处理任务中研究还未取得重大突破本文首先从深度学习的应用动机首要任务及基本框架等角度介绍了深度学习的基本概念其次围绕数据表示和学习模型两方面重点分析讨论了当前面向自然语言处理的深度学习研究进展及其应用策略并进一步介绍了已有的深度学习平台和工具最后对深度学习在自然语言处理领域的发展趋势和有待深入研究的难点进行了展望关键词自然语言处理深度学习表示学习特征学习神经网络引用格式奚雪峰周国栋面向自然语言处理的深度学习研究自动化学报深度学习通过建立深层神经网络模拟人脑的机制进行解释并分析学习图像语音及文本等数据是目前机器学习研究中的一个热点领域传统机器学习工作的有效性很大程度上依赖于人工设计的数据表示和输入特征的有效性机器学习方法在这个过程中的作用仅仅是优化学习权重以便最终输出最优的学习结果与传统机器学习方法不同的是深度学习试图自动完成数据表示和特征提取工作并且深度学习更强调通过学习过程提取出不同水平不同维度的有效表示以便提高不同抽象层次上对数据的解释能力从认知科学角度收稿日期录用日期国家自然科学基金资助本文责任编委柯登峰苏州大学计算机科学与技术学院苏州苏州科技学院电子与信息工程学院苏州苏州市移动网络技术与应用重点实验室苏州来看这个思路与人类学习机理非常吻合在面对大量感知数据的处理过程中人脑对其中的重要信息有着特殊的敏感性例如即使是四岁孩童放学时间站在校门口观望大量的接送家长总是比较容易快速准确地发现家人熟悉的身影欣喜地扑进家人的怀抱因此在人工智能研究领域中对于如何模仿人脑开展高效的复杂数据处理引发了研究者的极大兴趣其中从仿生学角度开展的人脑生理结构研究以及从人脑应用角度开展的功能研究是两个典型的研究方向前者体现研究对象的结构特征后者体现研究对象的功能特征两类研究又是互相渗透相互支撑例如在对哺乳类动物开展的解剖研究中发现大脑皮质存在着层次化的系列区域在此基础上神经科学研究人员又通过测试视觉信号输入人脑视网膜后经大脑前额皮质层到达运动神经的时间推断发现大脑皮质层的主要功能在于将视觉信号通过复杂的多层网络模型后加以提取观测信息而并未直接对视觉信号进行特征处理这就说明人脑在识别物体过程中并未直接通过视网膜投影的外部世界进行感知而是需要依靠经过某种聚集和分解处理后的信息才能识别得到物体自动化这一过程中视皮层的功能主要是开展对视觉信号的特征提取和计算而非简单重现视网膜图像这种具有明确层次结构的人类视觉感知系统在大大降低了视觉感知处理数据量的同时还能够保留被感知物体关键的结构信息大脑这种分层次结构启发了研究人员开展多层次神经网络的研究最早出现的多层网络训练算法是采用初始值随机选定及梯度下降优化策略的神经网络但是这种多层结构的主要缺陷在于输入与输出间存在的非线性映射导致能量函数或网络误差函数空间含有多个局部极小点同时采用的又是使能量或误差单一减小的搜索方向容易导致局部收敛最小而非全局最优相关实验及理论发现局部收敛最优的情况会随着网络层数的增加而变得越来越严重似乎表明算法在向多层深度结构方向发展上并无优势可言这在一定程度上影响了深度学习的发展浅层学习结构的共同特点是仅含一种将单个原始输入信号映射到特定问题空间的简单特征结构基本上可以认为这类模型带有一层或没有隐层节点常见的此类结构有条件随机场隐马尔科夫模型支持向量机多层感知器及最大熵模型等这些模型大多应用在传统信号处理技术及机器学习研究中存在着对复杂函数表示能力有限对复杂问题泛化处理能力不足的局限性这种情况直到年才出现转机等利用深度可信网络结构对组成的每一层受限玻尔兹曼机结构进行无监督学习训练并将其用于手写数字识别任务中取得了错误率仅为的最好成绩不久之后等也提出了一种基于自动编码器的相关算法同样取得了较好结果这些算法尽管形式不同但他们都遵循相同的原理即在每一层局部使用无监督的训练算法以引导完成特征中间表示层的训练目标此后其他一些非或非结构的深度学习算法也陆续提出自年以来这些深度学习方法不仅在分类任务上取得显著结果而且在时序预测高维降秩纹理建模运动建模对象分割信息抽取及自然语言处理领域都有不俗表现此外尽管上述深度模型中普遍采用和结构能够以无监督学报卷的方式从未标注数据中学习到良好的结果但在面对特定任务领域时有监督反馈算法用来初始化深度结构的方式也有成功应用尽管当前深度学习还未有完备的理论体系支撑但并不妨碍在图像识别和语音识别等应用领域率先结出累累硕果年一种称为深度神经网络的机器学习模型在图像识别领域的评测上被采用把识别错误率从降到是图像识别领域近年来的最好结果而在此之前的年同样类似的技术在语音识别领域也取得惊人效果降低语音识别错误率达从而大大推进了应用技术产品的开发比如基于技术的微软全自动同声传译系统在年月中国天津的一次公开活动中流畅地实现了自动语音识别英文到中文的机器翻译以及合成中文语音输出的整个过程效果震惊全场尽管深度学习已经在上述图像和语音处理领域取得显著进展但是在同属人类认知范畴的自然语言处理任务中应用还未有重大突破本文重点分析了当前面向自然语言处理的深度学习研究进展并探讨了深度学习在自然语言处理领域的可能发展空间以图抛砖引玉下文第节描述深度学习的基本概念第节围绕数据表示和学习模型两方面重点分析讨论了当前深度学习在自然语言处理领域的研究现状应用策略及其平台工具第节对有待深入研究的难点和发展趋势进行展望最后是结束语深度学习概述深度结构与传统浅层学习的不同之处在于首先深度学习要求模型结构必须具有足够的深度通常要求具有层以上的隐层节点有的甚至可能达到多层这种多层非线性映射结构有助于完成复杂函数逼近其次深度学习特别强调特征学习的重要性通过非监督预训练算法将输入原始样本在原空间的特征逐层变化映射到一个新的特征空间进而有可能使用新特征更加容易实现分类或预测此外生成性预训练方法也避免了因为网络函数表达能力过强而可能出现的过拟合问题深度学习中深度的概念实际上来源于流图的属性表示如图所示流图可用于表示一个输入输出过程中所涉及的计算图中节点表示基本计算方法原始输入经过节点计算后生成的结果作为下一个节点的输入逐步计算传是一个包含手写数字图片的数据集期奚雪峰等面向自然语言处理的深度学习研究递定义流图深度从一个输入到一个输出的最长路径长度即为流图的深度图所示流图表示计算函数该结构具有深度图所示多层人工神经网络该结构表示计算函数具有深度对于输出层而言传统神经网络的深度一般定义为隐层数加如图的结构具有深度深度神经网络则可能有更高深度大于或等于的结构深度为的流图深度为的多层神经网络深度为的神经网络图深度的概念示例图表我们可以将深度结构看作一种因子分解大部分随机选择的函数通常都很难采用网络结构有效表示但是相对而言深度结构表示的有效性要高于浅层结构研究人员猜测这些可被深度结构但不能被浅层结构高效表示的函数中可能存在某种结构使得其能够被深层结构很好地泛化表示应用动机采用特征来表示待处理问题中的对象是所有应用任务的首要工作比如在处理文本分类时经常用词集合特征来表示文档之后采用不同的分类算法来实现分类类似的在图像处理任务中最为普遍的就是把图像用像素集合特征加以表示选取不同的特征对任务的最终结果影响较大因此在解决实际问题时如何选取合适的特征非常重要对于很多训练任务来说特征具有天然的层次结构在语音图像文本处理任务中处理对象的层次结构如表所示以图像识别为例最初的原始输入是图像的像素之后众多相邻像素可以组成线条多个线条组成纹理并进一步形成图案局部图案又构成了整个物体不难发现原始输入和浅层特征之间的联系较容易找到那么在此基础上能否通过中间层特征逐步获取原始输入与高层特征的联系呢等的实验通过有效的特征提取将像素抽象成更高级的特征证实了这一设想的可能性类似的结果也适用于语音特征传统机器学习方法过分依赖人工选取特征或表示不具备从数据中自动抽取和组织信息的能力尽管人工选择能够利用人类智慧和先验知识弥补这一缺陷但要达到能够深入理解问题的程度并挖掘合适的特征规则研究人员所需花费的时间代价也颇为昂贵这从某种程度上限制了机器学习向更聪明的人工智能方向迈进的步伐因此摆脱人工特征选择的局限性试图从大量可观测到的浅层感官数据中识别或解释关键特征便成为深度学习的主要思想这也是深度学习称为无监督特征学习的原因某种意义上凡是能够实现自动学习特征的方法都可以归为深度学习为什么深度学习方法可以实现自动学习特征呢等从不同角度探讨了可能的原因语音图像文本领域的特征层次结构任务领域原始输入语音样本频段浅层特征声音音调中间特征音素高层特征图像像素线条纹理图案文本字母单词词组短语训练目标单词语音识别局部物体图像识别句子段落文章语义理解自动首先如果表示的深度不够就可能无法有效表示特征对象通常情况下一个给定目标精度的函数采用深度为的网络结构就可以了如使用逻辑门但伴随而来的问题是需要大量计算节点从理论上证实了存在这样一类函数族即使用深度为的结构和个节点可以有效表示的函数族当深度降低为时节点数呈现指数级增长这意味着增加表示深度的方式可以更加节约计算成本其次深度学习的分层概念符合人类认知学习过程从认知科学角度来看人类的认知学习过程是分层进行的分层结构是认知学习的基本要求例如工程师在解决复杂问题的过程中必定会将任务加以分解形成多个较小的子任务来处理子任务和总任务也处于不同的认知抽象层面最后神经生物学的研究表明人脑中也存在某种分层结构这进一步从仿生学角度为深度学习的有效性提供了佐证神经生物学家等对人类大脑的研究表明大脑皮质存在着层次化的系列区域每个区域都包含一个不同抽象层次的输入及到另一个区域的信号流向首要任务深度学习的首要任务是尽可能采用一种简单的算法来实现所求解问题的分层特征表示经过特征的逐层变换使得原始样本特征可以映射变换到另一个新特征空间进而可以更加容易地利用特征完成分类或预测任务因此特别强调特征学习或表示学习的重要性这一点与传统机器学习方法是一致的所不同的是深度学习实现特征自动提取而传统机器学习更依赖于人工分析特征化学卷报基本框架上节已经提到深度学习的首要任务其实是特征学习如图所示深度学习模型本质上是一种基于原始特征或者说是未经过人类思维分析的数据输入通过多层非线性处理来学习复杂特征表示的方法如果结合特定的领域任务则深度学习可以通过自动学习的特征表示来构建新型分类器或生成工具以实现面向领域的分类或其他任务具体而言图表示了深度学习的基本框架算法流程如下所示步骤随机初始化构建一个学习网络设置训练网络层数步骤初始化无标注数据作为网络训练输入集初始化训练网络层步骤基于输入集采用无监督学习算法预训练当前层的学习网络步骤每层的网络训练结果作为下一层的输入再次构建输入集步骤如果小于网络层数则网络训练层算法跳转到步骤否则跳转到步骤步骤采用有监督学习方法来调整所有层的网络参数使误差达到要求步骤完成分类器如神经网络分类器构建或者完成深度生成模型如深度玻尔兹曼机构建图图深度学习基本模型深度学习通过学习数据的某种变换形式当构建分类器或预测器时更容易抽取有效信息以概率模型为例能够抓取到所观察输入数据潜在解释因素后验分布的那个表示往往是一种好的表示形式在以深度学习方法为主的特征学习研究中还有许多问题有待进一步探索解决比如说一个特征表示优于另一个表示的主要因素是什么给定一个表示对象我们如何学习好的特征表示诸如此类基本问题都有待研究解决深度学习基本框架上述基本框架中的步骤是深度学习的关键也称为逐层预训练如图所示图逐层预训练模型期奚雪峰等面向自然语言处理的深度学习研究逐层训练中的关键部分是自动编码器的构建在深度学习模型中自动编码器可以是一种尽可能重现输入信号的神经网络无监督构建自动编码器当原始输入确定后首先训练模型的第一层如图中最左侧的黑色框图表示编码器是整个模型的认知机构其将原始输入编码后形成第一层初级特征为了验证编码后的特征确实是原始输入的一种等价抽象表示没有丢失太多信息我们引入一个对应的解码器如图中最左侧的灰色框图它是这个模型的生成机构为了使认知和生成达成一致我们需要将编码后的特征经过解码器再生成目的是要与初始的原始输入做比较验证验证得到的结果误差定义为代价函数用于训练神经网络编码器和解码器当训练达到收敛目标后确定了具体各类参数的神经网络编码器就是我们需要的第一层模型而解码器可以不需要即可以得到原始数据的第一层抽象表示固定第一层神经网络编码器的参数并将第一层抽象输出作为输入再次重复操作陆续可以训练出第二层模型第三层模型以此类推直至训练得到满足要求的最高层模型有监督训练分类器通过上述训练后得到的自动编码器原始输入信号得到了不同的表达特征这些特征可以最大程度上代表原始输入信号但是这个自动编码器还不能用来实现分类功能为了实现分类我们需要在自动编码器最高层的编码层添加分类器结合标签样本基于标准神经网络的有监督训练方法调整参数参数调整方法分为两类一是仅仅调整最高层的分类器的参数二是通过标签样本调整所有自动编码器的参数也即实现对多层模型参数的精细调表整深度学习所构建的深层模型具有较多局部最优解逐层初始化方法的目的就是最终将深层模型调整到较为接近全局最优解的位置从而获得最佳效果表从不同角度比较了深层模型和浅层模型的特点浅层模型的一个主要局限性就是需要依赖人工经验来抽取作为模型输入的样本特征模型本身仅作为分类或预测工具因此在浅层模型实现的系统中起决定性作用的往往不是模型的优劣而是所选取的特征的优劣这也促使研究人员将研究精力重点投入到特征的开发和筛选中不仅对任务问题领域需要深刻的理解还需要花费大量时间反复实验摸索事实上逐层初始化深层模型也可以看作是特征学习的过程通过隐藏层对原始输入的一步一步抽象表示来学习原始输入的数据结构找到更有效的特征最终提高分类问题的准确性在获得有效特征之后模型整体训练也可以水到渠成面向自然语言处理的深度学习研究及应用深度学习在图像和语音领域取得了突出成果但是在自然语言处理上还未取得重大突破与语音和图像不同语言是一种经过人类大脑产生并加工处理的符号系统似乎模仿人脑结构的人工神经网络应该在自然语言处理领域拥有更多优势但实际情况并非如此同时近几十年来在基于统计的模型成为自然语言处理主流方法之后属于统计方法典型代表的人工神经网络在自然语言处理领域依然没有得到足够重视当然这一切在年等提出深度学习以后情况发生了变化当前结合深度学习模型开展自然语言处理相关应用已经取得了一定成果并成为研究热点之一语言模型是最早采用神经网络开展研究的自然语言处理问题年等提出词向量或方法浅层和深层模型比对分析模型浅层模型深层模型理论有成熟的理论基础理论分析困难模型层数层层训练难度容易复杂需要较多技巧仅需要简单特征的任务如发电机故障诊断需要高度抽象特征的任务如时间序列处理等语音识别图像处理等数据需求模型表达能力有限强大特征提取方式特征工程特征自动抽取凸代价函数没有局部最优点高度非凸的代价函数存在大量的局部最优点可以收敛到全局最优容易收敛到局部最优依赖更多先验知识依赖较少先验知识代价函数凸性先验知识依赖度自动化可以将词映射转换到一个独立的向量空间进一步结合非线性神经网络提出了模型受此启发等基于词向量方法及多层一维卷积神经网络实现了一个同时处理词性标注语块切分命名实体识别语义角色标注四个典型自然语言处理任务的系统取得了与当时业界最好性能相当接近的效果尤其难能可贵的是相比传统算法仅用多行语言代码实现的系统运行速度更快所需内存空间更小对等提出的神经网络语言模型的进一步研究等发现通过添加隐藏层的多次递归可以提高语言模型性能将其应用于语音识别任务的结果令人吃惊在提高后续词预测的准确率及总体降低词的识别错误率方面都超越了当时最好的基准系统类似的模型也被等用在统计机器翻译任务上其性能采用评分机制评判提高了将近个百分点递归自动编码器模型在句段检测任务中大大提高了值此外基于深度模型的特征学习还在词义消歧情感分析等自然语言处理任务中均超越了当时最优系统取得不俗表现深度学习在自然语言处理领域应用的可行性分析由上述应用可见自然语言处理领域中的深度学习技术已经表现出较强的生命力成为当前研究热点之一综合分析来看能够在自然语言处理领域中应用深度学习技术并取得良好效果我们认为主要有以下几点原因特征表示学习的需要自然语言处理任务中首先要解决的问题是处理对象的表示形式为了表示对象通常必须抽取一些特征如文本的处理中常常用词集合来表示一个文档传统依赖手工的方式抽取特征费时费力不仅获取过程比较随意且完备性较差同时根据处理任务或领域的不同特征提取工作要重复进行无法实现表示共享能否使得机器也能像人类一样实现自动获取特征表示并进行推理学习深度学习就试图来解决这个问题深度学习中的特征提取即指可以自动从数据中学习获取特征无监督特征和权重学习的需要目前大多数效果较好的自然语言处理任务和机器学习方法都依赖于标注数据在这种情况下基于学报卷标注语料库及有监督学习方式成为了主流手段但是就实际应用而言自然语言中大量存在的是未标注数据从这些未标注数据中挖掘信息就必须要考虑自动无监督方法深度神经网络采用无监督方式完成预训练过程恰恰提供了合适的训练模型学习多层分类表示的需求仿生学的研究表明完成人类学习的大脑结构表现为一种多层深层不同的皮质层不同皮质层对应于不同的学习表示结构从抽象到具体逐层递减表示的抽象程度越高越能更多地交叉支持具体的处理任务因此我们需要利用好的学习模型更多地抽取出有用的中间表示形式深度学习能够较好地抽取处理任务的多层分类表示此外人类自然语言具有递归特性比如自然语言中的句子事实上可以由词短语递归组合而成深度学习提供了较为方便的递归操作可以支持这种自然语言递归组合特性的功能如递归神经网络当前可用的技术及硬件平台支撑深度学习结构一般由多层神经网络结点组成其预训练过程通常需要高性能计算的支持随着技术的发展能够提供高性能计算的硬件平台目前逐渐成熟如多核计算图形处理单元等同时为深度网络结构中的组成单元提供算法支持的技术也有较好发展如等并且各类结合自然语言处理的语言模型算法等也逐渐得到优化性能得到提升这些硬件及软件技术的发展都为当前采用深度学习结构的自然语言处理提供了良好支撑环境面向自然语言处理的深度学习研究模型面向领域任务的深度学习研究及应用需要解决两个普适问题应用领域的原始特征表示选择合适的深度学习算法前者实际是数据的表示问题后者代表了深度学习结构问题即深度学习模型例如在图像处理领域一般会选取图像像素矩阵作为原始特征表示而在语音处理任务中则会选取最基本的语音单位如音素面向自然语言处理的深度学习研究同样需要考虑上述两个普适问题对于问题典型的有基于词向量空间词袋模型向量空间模型等的表示方式对于问题目前普遍认可的是需要根据自然语言的特点来选择合适的深度学习模型人类自然语言具有递归特性比如自然语言中的句子事实上是由词短语递归组合而成因此期奚雪峰等面向自然语言处理的深度学习研究递归特性是自然语言的重要特征考虑自然语言递归特性的深度学习模型有循环神经网络递归神经网络卷积神经网络及其系列改进模型考虑上述两个问题之后在自然语言处理中应用深度学习的方式主要有两类在深度学习模型中直接使用原始特征构建一类端到端系统完成处理任务在现有模型中将训练后的原始特征作为辅助特征扩充使用第种方式典型的工作如系统基于词向量方法及多层一维卷积神经网络完成了词性标注语块切分命名实体识别等系列任务类似的工作还有如基于递归神经网络实现情感分析句法分析等多项任务第种方式典型的工作如等将词向量作为额外的特征加入到现有最优系统中进一步提高了命名实体识别和短语识别的效果数据表示面向自然语言处理的深度学习首先要解决的是自然语言的表示问题在基于规则和统计的自然语言处理工作中最常见的是表示方法每个词表示为一个很长的向量其中只有一个维度的值为代表了当前的词其他绝大多数元素都为向量的维度是词表的大小如词话筒的向量可表示为而词麦克的向量则可表示为如果采用稀疏方式存储形式上非常简洁结合传统机器学习算法如最大熵支持向量机条件随机场等该方法可以胜任大多数自然语言处理的主流任务但其纯粹的向量表示形式仅是孤立地表示单个词无法表达词与词之间的相关性如上述词话筒和麦克的表示向量单纯从这两个向量中无法看出两个词是否存在关系即使是麦克和话筒这样的同义词也不例外提出一种利用相近邻词表示当前词的思想通过计算不同范围的上下文相近邻词从而得到当前表示词的多种不同表达值比如当前中心词前后的词都可以用来计算得到当前中心词的表达值基于这种思想所产生的词表达方式被称为这也被誉为现代统计自然语言处理中最为成功的思想之一词向量词向量表示方式延续并扩展了上述类似思想为了让相关或者相似的词在距离上更接近向量的距离可以用传统的欧氏距离来衡量提出了一种用表示词的方式通常被称为词向量词向量是一种低维实数向量如用这种方式表示的向量麦克和话筒的距离会远远小于麦克和天气词向量的方式是目前自然语言处理中应用深度学习的首选表示方式这种表示方法的好处在于首先如果采用传统的稀疏表示法在解决某些任务的时候比如构建语言模型可能会造成维数灾难而使用低维的词向量就可以避免类似问题其次从实践上看高维的特征如果要应用深度学习方法复杂度过高很难接受再有相似词的词向量距离相近这就让基于词向量设计的一些模型能够自带平滑功能词向量模型为文本中的每个单词构造一组特征较好地解决了自然语言中词一级的表示问题事实上也可以针对不同粒度进行推广如字向量句子向量和文档向量从而实现字短语文本等表示而在文本级别另外一种常见的表示方法是词袋模型词袋模型词袋模型是最早出现在自然语言处理领域中用来表示文档的方法词袋模型忽略文本的语法和语序用一组无序的单词来表达一个文档或一段文字文档中每个单词都是独立出现不依赖于其他单词是否出现文档或文字段仅仅看作是若干个词汇的集合例例根据上述两句话中出现的单词我们能构建出一个字典该字典中包含个单词每个单词有唯一索引注意它们的顺序和出现在句子中的顺序没有关联根据这个字典我们能将上述两句话重新表示为下述两个向量这两个向量共包含个元素其中第个元素表示字典中第个单词在句子中出现的次数因此词袋模型可认为是一种统计直方图在文本检索和处理应用中可以通过该模型很方便地计算词频词袋模型典型的应用是文档分类定义文档集合自动共有个文档将文档里面的所有单词提取出来后构成一个包含个单词的词典基于词袋模型每个文档都可以被表示成为一个维向量利用计算机就可以来完成海量文档的分类任务向量空间模型向量空间模型由于世纪年代提出并成功地应用于著名的文本检索系统向量空间模型概念简单把对文本内容的处理简化为向量空间中的向量运算并且它以空间上的相似度来表示语义的相似度直观易懂当文档被表示为文档空间的向量时就可以通过计算向量之间的余弦距离来度量文档间的相似性除了在信息检索领域的成功应用外向量空间模型也在自然语言处理的其他语义任务中有着令人印象深刻的结果如采用基于向量的词义表示方式来完成考试的同义词多项选择问题取得了的准确率相比之下当时的该项考试中考生的平均正确率也仅为类似的使用语义关系的向量表示来完成大学入学考试的推理多项选择问题取得了的准确率和人类考试平均正确率基本相当受向量空间模型思想启发在如何表示短语句子篇章等高一级的语言单元这一问题上我们认为可能的解决思路是以词向量为最小单位把同属一个短语句子或篇章的词向量映射到同一向量空间中类似的工作在短语篇章及文档的相似性判断中已经表现出较好的效果如等使用向量空间模型作为搜索引擎来衡量一个查询与文档之间的相似度学习模型词向量的获得一般都是依赖语言模型的训练常见的方式是在训练语言模型的过程中同时训练得到词向量定义定义语言单元集合短语子句篇章语言基础最小单元集合词字其中英文中的语言基础最小单元是词而汉语的语言基础单位可以是字定义语言模型可以形式化描述为给定一个字符串判断它属于自然语言的概率为其中简单的推论如下推论在实际应用模型中一般都求近似解如元语化学卷报法模型就是如此神经网络与元语法模型神经网络与语言模型的结合工作最早源自等提出一种使用神经网络构建二元语言模型的思想而等利用三层神经网络来构建元语法模型的工作就把神经网络与语言模型训练的结合推上了一个新的台阶如图所示最下方的表示前个词根据前个词预测下一个词是模型的终极目标其中模型使用了一个词向量库如定义所示图三层神经网络构建的模型定义词向量库定义为矩阵其中表示语料中的总词数表示词向量的维度表示从矩阵中取出一行向量值用来代表词所对应的词向量网络的输入层将串连拼接起来构成一个维的向量表示为计算方式直网络的第二层隐藏层基于接得到结果其中为隐藏层网络权重矩阵为网络输入层到隐藏层的偏置项并使用函数作为激活函数网络的第三层输出层共包含个节点使用激活函数将输出值归一化如式所示其中表示下一个词为的未归一化概率定义的计算如式式中为隐藏层到输出层的偏置项词特征输入层到输出层的权重矩阵隐藏层期奚雪峰等面向自然语言处理的深度学习研究到输出层的权重矩阵其中是隐藏层节点数量隐藏层权重矩阵矩阵和网络隐藏层的矩阵乘法是模型的主要计算量为了提升模型的计算速度后期研究者的相关工作都有对这一计算环节的简化式中的矩阵包含了从输入层到输出层的线性变换如果不需要线性变换的话可将置为线性变换虽然不能提升模型效果但是可以减少一半的迭代次数最后采用随机梯度下降法实现模型优化工作在得到语言模型的同时也得到了词向量值得注意的是与一般神经网络输入层仅带一个输入值而无需优化不同为了使得到的模型自带平滑功能该模型的输入层参数是需要调整优化的相比于传统含有复杂平滑设计的元语法模型而言该模型算法性能提升了约文献最主要的思想随后在下面三个重要工作中体现出来语言模型语言模型循环神经网络语言模型语言模型受文献的影响等提出了一种语言模型用于实现语言模型及词向量的训练这可以认为是自然语言处理中较早开始深度学习应用的尝试他们从最基本的受限玻尔兹曼机开始不断调整修改模型的能量函数最终获得了模型采用神经网络的形式可以表示为一般采用类似元语法模型的近似思想仅考虑上文到个词作为输入来预测下一个词语言模型在语言模型基础上等提出了一种带有层级思想的语言模型替换了文献提出的三层神经网络架构中计算成本最大的矩阵乘法在保证效果的基础上提升了速度这种层级的思想最初由等提出他们采用中的关系将其转化为二叉树后再作分类预测实验结果表明尽管提高了速度但却降低了性能似乎有点得不偿失等借鉴了层级的思想但在实验中使用一种自举学习的方法来自动构建平衡二叉树并将其用于替换网络最后一层在预测向量分类时采用了二叉树中的非叶节点模型最后构建得到的叶子节点就用来确定具体的词计算复杂度也从原来的降低到循环神经网络语言模型文献提出的模型中涉及大量训练参数等提出了一种循环神经网络语言模型用于降低训练参数的数量其采用优化算法取得了比元语法模型中的最优方法更好的效果随后的研究中等一直在上作各种改进包括速度及正确率循环神经网络与前面方法中使用的前馈网络训练的原理基本一致但是在结构上存在较大差别循环神经网络结构大致如图所示式和可以合并表示为其中表示词对应的词向量模型形如式中表示直接带有语义信息的隐藏层该隐藏层的维度为和词向量的维度保持一致矩阵表示第个词经过变换之后对第个词的贡献度式中等于和预测词向量的内积可以反映两者的相似度直接表示下一个词为的预测概率模型的理想实现是能够使用每个词的上文的所有词作为输入但是这样的实现成本极高神经网络结构抽象表示神经网络流转过程图循环神经网络结构图图是网络的抽象表示结构由于循环神经自动化网络多用在时序序列上因此输入层隐藏层和输出层都带有时序参数隐藏层计算公式表示为式中是句子中用表示的第个词的词向量向量表示隐藏层状态向量表示上一个隐藏层状态初始可以是含较小值如的一个向量随后的图表示循环神经网络的流转过程每当一个新词输入循环神经网络联合输入新词的词向量与上一个隐藏层状态计算下一个隐藏层状态重复计算得到所有隐藏层状态各隐藏层最终通过传统的前馈网络得到输出结果不同于取个词来近似预测下一个词的窗口模式循环神经网络可以真正充分地利用所有上文信息来预测下一个词这种方式实际上优劣并存如果一旦在实际使用中优化不足就可能丢失长距离信息导致预测词的性能甚至可能还比不上取个词的窗口模式为了降低最后隐藏层到输出层的复杂计算量等采用了一种分组的方法基于词频特点将个词分成组先通过次判断判断下一个词所属组别再通过若干次判断找出其属于组内的元素最后均摊复杂度约为略差于和所提模型的复杂度但是这种方法最大的优点是结构比较简单可以减少误差传递基于词向量的改进模型和在年首次提出了一种特殊的词向量计算方法文中系统地总结了他们基于词向量完成的多项自然语言处理任务如词性标注命名实体识别短语识别语义角色标注等工作不同于求近似解的元语法模型他们的词向量训练方法直接求解的近似解给出定义定义定义表示窗口连续个词的分值只有相对高低之分并不表示概率的特性分值越高表明这句话越是正常分值低表明这句话不合理极端情况如果随机把几个词堆积在一起值将表示为负分基于此和使用方法来训练词向量其中需要最小化目标函数如下式中为训练集中的所有连续的元短语是整个字典表示正样本表示负样本而函数学报卷是正样本的分值转换是负样本的分值转换式中的第一个求和枚举计算将训练语料中的元短语都作为正样本挑选出来了所有的负样本则通过第二个对字典的枚举构建得到表示用替换正常短语的中间词这样处理后最终得到短语大多数情况下肯定不是正确的短语可以作为负样本使用由式可见正样本最终的打分要比负样本至少高出分函数的结构基本上和文献中的网络结构一致它们的共同之处在于窗口中的个词所对应的词向量被串连形成一个长向量隐藏层都经过一层网络计算后得到不同点在于和模型的输出层只有一个节点表示得分而文献模型则拥有个节点此外采用代替激活函数以降低计算复杂度和模型中窗口值设定为字典大小值设定为利用维基百科英文语料和路透社语料训练周后得到了词向量相比其他词向量词向量主要特点有词向量仅包含小写单词也就是说不同于其他词向量对大小写词分开处理该词表不区分大小写它把单词都按照小写词加以处理词向量是通过半监督学习得到的因为词向量是在通过词性标注命名实体识别等多任务优化的半监督学习后得到的区别于其他方法中的无监督学习等在将和所实现的向量与和实现的向量做了对比实验并在其标注好的语料上运行了模型得到了另一份词向量等的系列论文介绍了将词表征为实数值向量的词向量工具包本文第节讨论了该工具包其主要用到模型和模型分别采用和框架进行设计模型和模型都包含三层架构即输入层投影层和输出层所不同的是前者在已知当前词的上下文的前提下预测当前词如图所示而后者是在已知当前词的前提下预测其上下文如图所示经过工具包训练得到的词向量具备很好的类比特性在一定程度上可以表示词语的语义和语法性质面向知识图谱的表示学习算法正是受此类比特性启发而提出的知识图谱包含大量实体实体的语义类别和期奚雪峰等面向自然语言处理的深度学习研究实体间的关系可以用三元组主体关系客体来表示算法将三元组中的关系看作主体到客体的翻译使得三元组满足线性转换利用特征表示向量描述实体和关系可以更加容易地计算实体之间的语义关系模型模型图词向量未来发展的关键等的实验结果也同样表明语料越大词向量效果就越好这一点同和的实验结果是一致的面向自然语言处理的深度学习应用策略提出了采用梯度下降法训练深度结构的系列建议其中大致可将训练过程分为无监督预训练模型参数初始化及后期优化模型调试等参考这一过程我们定义如下在自然语言处理领域深度学习的应用策略应用架构如图所示词向量的模型结构图图模型讨论上述其他所有模型除了循环神经网络语言模型以外本质上模型的输入层到隐藏层第一层都是等价的即使形式比较特别的语言模型如果把模型中的看成的拼接则也可以得到类似其他方法那样的等式所以上述诸多模型本质上非常相似差别主要在于隐藏层到输出层的语义定义采用最朴素的线性变换从隐藏层直接映射到每个词和将语言模型做了简化利用线性变换把隐藏层转换为分值和复用了词向量进一步强化了语义并用层级结构加速等则用了分组来实现加速此外和的实验结果表明相比于随机初始化将词向量作为初始值在不同任务上的效果都有显著提升同时发现训练语料越大实际效果越好在将词向量用作辅助特征时等的实验表明向量在命名实体识别和短语识别中的效果比和实现的向量稍好些而两者联合使用效果更佳近期等的研究发现了一个有意思的现象两个词向量之间的关系可以用两个向量的差来体现例如已经知道与的关系类似等价于与的关系现在给定判断是否近似于词向量例如实验中发现有词向量进一步发现居然就是最接近的词向量向量之间存在的这种线性平移关系极有可能成为面向自然语言处理的深度学习应用架构图步骤构建基本模型框架针对处理任务选择合适的神经网络结构构建深度学习基本模型框架步骤模型检查采用梯度下降法检查模型实现是否存在错误这对于整个过程至关重要步骤模型初始化主要涉及神经网络隐藏层偏置量和网络结点权重矩阵的参数初始化步骤模型优化主要涉及模型参数调整优化步骤模型调整检查模型是否能够满足过拟合要求如果没有调整模型参数使其能够满足过拟合要求如果达到过拟合要求那就采用正则化方法调整模型构建基本模型框架构建面向自然语言处理的深度学习模型首先要考虑基本表示结构可选的表示结构有或其次要考虑非线性化过程可选的非线性化函数有等如图所示函数及其反函数都具有单调递增特点可实现变量在区间的映射故经常作为神经网络阈值函数使用但是函数初始化权重集后能够激活近半数的神经元这与模仿大脑神经元稀疏性工作的原理似乎相悖同时也不利于深度网络训练与此相比函数具有单侧抑制性可以相对有效降低深度网络训练复杂度此外统计表明对于深度网络而言函数性能最佳使用频率也是最高函数类似计算代价相对低廉上述几种常用的非线性函数如图所示其公式如下自函数图函数图图动化函数图函数图函数函数函数图几种常用的非线性化函数可视化表示函数卷报函数学函数模型检查梯度下降法是常用的模型检查方法通过模型检查能够验证所实现的模型是否存在明显缺陷首先在检查模型之前需要选择合适的梯度表示其次循环计算调整参数最后比较输出值和实际结果之间的偏差以确保其一致模型初始化模型的初始化首先设置隐藏层的偏置量为并设置输出层的偏置量为假定权重值都为的情况下的最优值其次设置权重其中为前一层网络的结点数为后一层网络的结点数最后完成预训练过程模型优化模型优化主要涉及参数的训练设为参数为网络权重矩阵为网络单元的偏置常规优化算法有随机梯度下降共轭梯度下降形式化定义如下式中为损失函数为当前样本为参数向量为学习速率算法中对于学习速率的选择简单的办法是选定一个固定值作为全局变量使用并且学习速率随着时间动态逐步递减以确保模型收敛典型的递减方式如取倒数形式形式化可表示为在优化过程中不同的优化算法都有不同的优缺点需要区分不同应用场合加以选择使用比如在参数维度较低小于万维的情况下的效果最好而针对高维问题算法又要比其他两种算法更优此外如果是在小规模数据集上则或算法较优如果是在大数据集合中算法对模型参数的调整性能最佳大数据集合经常伴随大规模训练集为降低训练集的计算复杂度在每次迭代时仅利用部分训练集样本加以训练这里的部分训练样本其实是训练集的一个子集一般称为在实际优化过程中目前常用的是带的优化算法在深度学习网络中梯度表示为雅可比行列矩阵的形式每一单元的结果都依赖于前一步计算这可能会使梯度结果变化速度过快从而导致梯度下降局部变化的假设不再成立模型调整经过上述步骤得到的模型如果出现过拟合则需要在本阶段作正则化调整第一步最简单的方式是降低模型规模可以通过降低各种参数值达到这一目的如可以减少神经网络结点单元数网络层数及其他可用参数等其次可以使用标准或期奚雪峰等面向自然语言处理的深度学习研究的限制调整权重值或者采用稀疏化方式促使模型复杂度降低提升计算速度和模型的泛化能力面向自然语言处理的深度学习典型应用相比于图像和语音领域所取得的成果深度学习在自然语言处理上尽管还未取得重大突破但也在以下相关诸多领域如词性标注句法分析词义学习情感分析有着初步应用并取得较好效果分词和词性标注分词是指按照一定的规范将连续的字序列重新组合成词序列的过程词性标注则是指确定句子中每个词的词性如形容词动词名词等又称词类标注或者简称标注在英文分词和词性标注方面结合深度学习开展相关研究最有影响力的是等的研究工作他们基于词向量方法及多层一维卷积神经网络实现了一个同时处理词性标注语块切分命名实体识别语义角色标注四个典型自然语言处理任务的系统取得了与当时业界最好性能相当接近的效果在中文分词和词性标注方面等分析了利用深度学习来进行上述两项工作的可行性主要集中在特征发现数据表示和模型算法三方面工作在特征发现方面他们尝试采用深层神经网络来发现与任务相关的特征从而避免依赖于具体任务的特征工程在数据表示方面他们利用大规模非标注数据来改善中文字的内在表示然后使用改善后的表示来提高有监督的分词和词性标注模型的性能在模型算法方面他们提出算法替代方法在性能上接近当前最好的算法但计算开销更小特别有意思的是受英文的词向量的概念启发他们提出以中文的字为基本单位的字向量概念由此提供了深度学习利用中文大规模非标注数据开展预训练的可能性句法分析句法分析的主要任务是自动识别句子中包含的句法单位以及这些句法单位相互之间的关系即句子的结构通常的做法是给定一个句子作为输入利用语言的语法特征作为主要知识源构建一棵短语结构树提出一种句法分析器首次将神经网络成功应用于大规模句法分析中随后又基于同步网络训练句法分析器等使用改进了一种生成型句法分析器用于不同领域的句法分析任务他们还在特征学习基础上寻求进一步改进系统的方法基于深度循环图转移网络提出了一种应用于自然语言句法分析的快速判别算法该方法使用较少的文本特征所取得的性能指标与当时最好的判别式分析器和基准分析器相当而在计算速度上具有较大优势与此同时等也尝试采用递归神经网络模型用于解决增量式句法分析器中侯选附加短语的排序问题他们的工作首次揭示了利用递归神经网络模型获取足够的信息从而修正句法分析结果的可能性但是他们只在大约个句子的子集上做了测试相对来说测试集合显得有点少等在使用分析器生成侯选句法树的基础上利用递归神经网络模型实现再排序和他们的工作类似等提出了一种模型用于句法结构预测该模型将与递归神经网络模型相结合充分利用了短语的语法和语义信息与斯坦福分析器相比他们的系统不仅性能上提高了约取得了的值而且在训练速度上提高约等基于简单神经网络模型提出了一种自底向上的句法分析方法其主要优势在于结构简单计算开销少分析速度快且性能接近当前最好系统词义学习基于无监督学习机制的词义表示在自然语言处理中有着非常广泛的用途例如可以作为某些学习算法的输入或者是特殊词的特征表示但是目前大多数词义表示模型都依赖本地上下文关系且只能一词一义这存在很大局限性因为通常可能一个词有着多个含义并且对于学习词义而言全局上下文关系能够提供更多有用的信息等在和的基础上提出了一种新的深度神经网络模型用于词义学习该模型通过综合本地和全局文本上下文信息学习能够更好表达词义的隐藏词通过学习每个词的多义词表示来更好地解释同名歧义进一步在基于多个词向量表示词的多义性基础上通过对模型的改进使得词向量包含更丰富的语义信息实验表明相比于其他向量等的方法与人工标注语义相似度最为接近等提到了对语言的深度理解概念他们认为单个词的向量空间模型在词汇信息的学习中得到了充分成功的应用但是由于不能有效获取长短语的组合词义则在语言的进一步深度理解上产生了障碍他们提出了一种深度递归神经网络模自动化型该模型可通过学习短语和句子的组合向量来表示语义句子可以是任意句法类型和长度的句子该模型给句法树上的每个结点都分配一个向量和矩阵向量获取元素的本体语义矩阵捕获邻近单词和短语的变化信息该模型在三种不同的实验中取得了显著性能分别是副词形容词组合对的情感分布预测影评标记的情感分类情感关系分类如因果或名词之间的主题信息等情感分析情感分析又称为倾向性分析意见抽取意见挖掘情感挖掘主观分析等它是对带有情感色彩的主观性文本进行分析处理归纳和推理的过程如从评论文本中分析用户对手机的价格大小重量易用性等属性的情感倾向等提出一种称为主动深度网络的半监督学习算法用于解决情感分类问题首先在标注数据和无标注数据集上他们采用无监督学习算法来训练进而搭建并通过基于梯度下降算法的有监督学习方法进行结构微调之后结合主动学习方法利用标注好的评论数据来训练半监督学习框架将其与结构融合实现了一个面向半监督分类任务的统一模型实验表明该模型在种情感分类数据集上都有较为突出的性能中性能的提升部分得益于无标注训练数据的规模提高这就为大量丰富的无标注评论数据开辟了利用空间等提出了一种采用无监督学习方式从网络评论数据中学习如何提取有意义信息表示的深度学习方法并将其用于情感分类器的构建中在产品的类评论基准数据上的测试性能显著等基于提出一种深度学习模型应用于句子级的情感标注预测该模型采用词向量空间构建输入训练数据利用实现半监督学习实验表明该模型准确性优于同类基准系统针对词向量空间在长短语表达上缺乏表现力这一缺点等引入情感树库以增强情感训练和评价资源在此基础上训练完成的模型性能表现突出简单句的正负情感分类准确率从提高到短语情感预测从提高到针对词袋模型的缺陷等提出了一种基于段落的向量模型该模型实现了一种从句子段落和文档中自动学习固定长度特征表示的无监督学报卷算法在情感分析和文本分类任务中都有优异表现尤其是简单句的正负情感分类准确率相比模型提高了在等构建的模型基础上借助公司的词向量开源工具完成了亿个单词的新闻语料训练并将其用于包括情感树库等试验语料上的简单句情感分类任务取得了的当时最好性能这似乎再次验证了思想只要包含足够的训练数据深度学习模型总能够尽可能逼近真实结果机器翻译机器翻译是利用计算机把一种自然源语言转变为另一种自然目标语言的过程也称为自动翻译目前基于深度学习的统计机器翻译方法研究热点可以分为传统机器翻译模型上的神经网络改进采用全新构建的端到端神经机器翻译方法两种类型大多数统计机器翻译系统建模采用基于对数线性框架尽管已经取得较为成功的应用但依然面临如下局限性所选特征需要与模型本身成线性匹配特征无法进一步解释说明以便反映潜在语义针对上述局限等提出了一种附加神经网络模型用于扩展传统对数线性翻译模型此外采用词向量将每个词编码转化为特征向量作为神经网络的输入值该模型在中英和日英两类翻译任务中均获得了较好性能词对齐方法是机器翻译常用的基础技术等基于深度神经网络提出了一种新颖的词对齐方法该方法将多层神经网络引入隐马尔科夫模型从而利用神经网络来计算上下文依赖的词义转换得分并采用大量语料来预先训练词向量在大规模中英词对齐任务的实验表明该方法取得较好的词对齐结果优于经典的隐马尔科夫模型和与上述传统机器模型中的神经网络针对翻译系统局部改进所不同的是近来出现的神经机器翻译构建了一种新颖的端到端翻译方法其初始输入为整个句子并联合翻译输出的候选句子构成句子对通过构建神经网络并结合双语平行语料库来寻找条件概率最大时的候选句子对最终输出目标翻译句神经机器翻译试图构建并训练一个可以读取源句子直接翻译为目标句子的单一大型的神经网络从统计角度来看机器翻译可以等价为在给定输入源句子的情况下寻找条件概率最大时的翻译目标句子的值即求事实上目前提出的大多数神经机器翻译方期奚雪峰等面向自然语言处理的深度学习研究法都属于一类编码解码器模型其主要框架包含两部分首先编码器将输入的长度不固定的源句子编码转换为固定长度的向量之后解码器将向量解码输出为翻译的目标句这里的解码器就可以采用一类深度神经网络模型例如循环神经网络在使用循环神经网络作为编解码的框架中编码器读入输入句子经过编码输出为向量表示如下其中表示时刻时的隐藏状态是由多个隐藏状态序列生成的向量和是非线性函数例如等使用多层表示函数在给定上下文向量和前续已经预测得到的词序列的前提下循环神经网络训练的编码器用来预测下一个词表示如下其中基于循环神经网络每个条件概率可以建模如下其中是非线性多层函数可以由循环神经网络建模表示是循环神经网络的隐藏层类似的结构也可以采用循环神经网络和卷积神经网络混合表示编码解码器模型一个潜在的问题是所采用的神经网络需要能够把输入源句子的所有信息都压缩进入固定长度的向量中这在处理长句子时可能比较困难尤其是那些远比训练语料库中的长得多的句子等实验表明随着输入句子长度的增加编码解码器模型性能快速降低为了克服这个缺陷等引入了一个扩展的编码解码器模型该模型在翻译过程中也是每次根据上下文相关信息以及已经找到的目标单词通过引入注意力机制来自动学习目标词在源语言上的对齐目标单词和基本编码解码器模型不同的是该模型并不是试图把整个输入句子编码转换放进单个固定长度的向量中而是编码转换放进一个向量序列中当解码时就可以在向量序列中选择一个合适的向量子集用于解码这种方式使得神经网络翻译模型不必过度纠结于输入句子的长度实验同时也表明这种改进的编码解码器模型在处理长句问题时性能表现更好等基于多任务学习机制联合学习通过在一对多的序列到序列的机器翻译模型中共享源语言的表示构建了一种源语言到多个目标语言的翻译模型面向自然语言处理的深度学习平台工具面向自然语言处理的深度学习平台或工具较多根据开发语言的不同可以分为基于或等不同程序设计语言实现的算法库或框架根据实现的神经网络模型的不同可以分为面向等组件卷积神经网络循环神经网络递归神经网络实现的框架平台根据功能目标不同又可以分为提供深度学习基本功能实现的函数库工具包在函数库基础上面向领域任务构建的不同应用框架等下面从不同角度介绍几类典型的深度学习开源工具函数库工具包最早出现的较为完整实现深度学习框架的库函数包是由加拿大大学实验室等开发的是一个基于语言的库实现了深度学习相关模型及算法如等可有效支持涉及多维矩阵相关的定义优化及评估等数学运算具有以下特点有效集成是一个用实现的科学计算包一般和稀疏矩阵运算包配合使用使用集成编译函数全面兼容库函数可方便应用于平台在一类数据密集型的计算任务中与普通仅使用位浮点数的相比计算速度可提高多倍有效的符号区分能力可有效支持带有个或多个输入的扩展函数速度及可靠性表现优异即便取值很小也能计算得到的正确结果支持动态代码生成具有众多测试和自检单元可方便地检测和诊断多种类型的错误在基础上后续研究者陆续开发了众多深度学习框架如等采用语言实现的是一个追求简易高度模块化的神经网络库开发的主要目的在于将研究创意能够快速转换为深度学习实验的原型框架避免因为实验困难而错过了创意的验证的扩展性能非常好可以快速实现基于卷积神经网络循环神经网络或者两者混合实现的经典模型同时能够运行于和平台和前两个工具包都是在库基础上构建的稍有不同的地方在于还支持另一个函数库是一个开源软件库最早由自动化公司机器智能研究部门的谷歌大脑团队开发完成目的是为了搭建机器学习及深度神经网络研究平台该软件库采用数据流图模式实现数值计算数据流图中的结点表示数学运算图中的边表示多维数据阵列采用该软件库开发的平台架构灵活代码一次开发无需修改即可在单机服务器或移动设备上流畅运行支持多计算类似可以在各种设备上运行的轻量级函数库还有这也是奉行简单实用灵活方便主义的模板库基于实现支持多以及分布式系统在该函数库上扩展开发了和分布式深度学习框架也是一类高质量的软件工具包数据表征工具第一个在自然语言任务中取得较好性能的深度学习应用软件是由团队开发具有架构简单独立性强不依赖其他自然语言处理工具运行速度快等特点在等四个典型自然语言处理问题上取得的性能都与当时最好系统相当采用大约行的标准语言代码实现可以运行在配备内存且支持浮点运算的计算机平台上目前最新的版本是更新于年月特别强调它们在上花费个月时间所训练的词向量将词表征为多维向量可以用于不同的自然语言处理任务与此相类似的公司在年开源软件也是将词表征为实数值向量的有效工具使用第节中所提到词向量表示方式通过一个三层的神经网络模型训练可以将文本内容处理转化为维向量空间中的运算进一步文本语义上的相似度就可以用向量空间中的距离如欧氏距离相似度来表示在神经网络模型训练中根据词出现的频率采用编码设计隐藏层节点数目词频越高的词语所激活的隐藏层节点数目越少这就大大降低了计算复杂度实验表明优化的单机版本的在一天内可以训练上亿个词这种训练的高效性也是在自然语言处理中大受欢迎的一个重要原因经典神经网络模型能够将文本内容转换表示为向量形式开启了学报卷面向自然语言处理的深度学习应用热潮理论上基于向量表示所有的深度学习模型都用来处理不同的自然语言处理任务但在实践中使用频率最高效果最为突出的还是卷积神经网络循环神经网络和递归神经网络等深度神经网络组件最早由基于开发的一类小型函数库主要用于训练构成深度学习网络的组件如规模不大随后出现的是一个规模较大完整实现深度学习框架的平台工具支持可以运行在计算平台上这就为大规模数据处理提供了便利性采用语言实现了深度可信网络递归自动解码器等一类典型的深度神经网络组件为构建可靠的分布式处理的深度神经网络框架提供了良好的基础卷积神经网络工具卷积神经网络是一类典型经典的面向自然语言处理的深度学习模型上节提到的即是一种基于卷积神经网络原理的工具软件此外其他比较著名的卷积神经网络模型实现工具有以及第节提到的等是当前的最新版本采用实现训练过程基于算法是一个采用实现的卷积神经网络工具包循环神经网络等工具循环神经网络以及递归神经网络模型也是近年来在自然语言处理领域被认为是最有潜力的深度学习模型上文提及的很多函数库及工具包都提供了相应实现如采用语言实现基于的采用语言支持分布式大规模计算平台的等其他还有一些比较令人注目的开源工具如开发的基于循环神经网络语言模型的工具包支持中文及格式的语料开发的基于递归神经网络的工具包等当前在自然语言处理的各种任务中逐渐崭露头角存在的问题与未来的研究方向数据表示问题及展望自然语言在深度学习中用于初始输入的数开发的循环神经网络模型的递归神经网络模型期奚雪峰等面向自然语言处理的深度学习研究据源是字或词和图像语音分别采用像素点及音素作为初始数据源相比较前者已经包含了人类的语义解释是经过人类主观思考处理后形成的而后者是原始的还没有经过人类加工处理这一点是自然语言处理和其他两种应用最大的不同由此我们联想到这是否也是深度学习在图像语音方面能够取得巨大成功而在自然语言方面还没有成功的关键原因呢因为包含原始信号的情况下不容易丢失未知信息从而能够通过深度学习的不同分层特征表示更为全面地表征原始输入进一步为分类聚类等具体应用提供充分的特征支撑目前来看面向自然语言处理的深度学习中的数据表征主要还是概念只是可能在不同语言中具体的表示单位有所不同如英文中可以是单词或词缀中文中则换成了词组或字本质上还是通过某种映射规则将转换为向量表示在如何将深度学习与现有自然语言处理具体任务结合方面目前还没有比较明显有突破的方法或规律可以遵循现有工作中比较直接简单的做法是以词或短语作为原始输入构建向量类型的表达方式经过深度学习分层学习后得到的特征可以添加进现有基于特征的半监督学习系统中进行处理此外还有将深度学习模型与当前经典问题结合后产生的应用模型如结合树形或链式结构的递归神经网络或循环神经网络模型等因此考虑如何将深度学习与自然语言处理任务结合的具体落地应用也是值得研究的重点学习模型问题及展望面向自然语言处理的深度学习研究工作目前尚处于起步阶段尽管已有的深度学习算法模型如循环神经网络递归神经网络和卷积神经网络等已经有较为显著的应用但还没有重大突破围绕适合自然语言处理领域的深度学习模型构建等研究应该有着非常广阔的空间在当前已有的深度学习模型研究中难点是在模型构建过程中参数的优化调整方面主要如深度网络层数正则化问题及网络学习速率等可能的解决方案比如有采用多核机提升网络训练速度针对不同应用场合选择合适的优化算法等深度学习模型的训练过程中最为突出的问题是训练速度普遍来看深度学习模型的训练速度远比线性模型来得慢此外模型性能的优劣一般与训练数据集的规模有关数据集越大训练结果越好这一点非常符合目前主流的大数据应用趋势但是这也可能给学习模型的优化带来发展阻碍在极力追求产生大数据训练集的情况下是否会削弱对更优学习模型的研究热情呢其他问题及思考自动学习和人工结合围绕数据表示及特征提取问题已有大量文献分析了自然语言处理中的数据源特征和无监督自动学习方法深度学习一直强调学习特征采用自动的方法然而如果能够在训练过程中融合已有面向特定应用领域的显然的知识如人工选取的明显特征规律对于深度模型而言依然具有吸引力这就好比人类学习完全抛弃祖先的知识而白手起家开展工作是不可想象的但是要做到这点非常困难首先针对问题领域需要选择合适的模型架构比如针对自然语言的语义框架选择合适的深度结构其次人类知识的融合最佳的进入点应该是在模型的第一层类似线性模型一样总的目标是希望能够使模型具有自我学习的能力此外在自然语言处理领域已经有了大量的人工标注知识深度学习可以通过有监督学习得到相关的语义知识这种知识和人类总结的知识应该存在某种对应关系尤其是在一些浅层语义方面因为人工标注本质上已经给深度学习提供了学习的目标只是深度学习可以不眠不休地学习这种逐步靠拢学习目标的过程可能远比人类总结过程来得更快这一点从最近公司围棋人工智能软件短时间内连胜两位人类围棋高手的事实似乎能够得到验证自然语言的不确定性由于一词多义的存在使得即使采用词向量技术作为深度学习的原始输入信号也还是不能如图像或语音一样将所有原始信息确定地输入到深度学习模型中在深度学习模型分层表示原始输入信号的不同特征时这种不确定性所带来的误差有可能在不同层间被传递并局部放大解决这种一词多义所带来的不确定性的方法似乎还是要结合上下文语言情境因此突破自然语言字词短语小句等局部表示的局限性面向包含上下文全局信息的篇章文本来开展深层语义理解如篇章分析篇章理解等应该是重点发展的方向之一结束语相比于图像处理自然语言的分层抽象其实并不明显自然语言处理在深度学习中所采用的特征表示目前主要是机制尽管从语言表达的形式角度也可以构建字母单词词组短语句子等层次结构但从语义表达角度来看似乎没有如图像处理那样具有明显的抽象分层例如自动单词和词组词组和短语之间语义表达上面并没有非常明显的不同抽象层次不明显实质上就可能限制了特征表示的多样性从而无法最好地发挥深度学习多层特征表示的长处除了词向量之外是否还有更好的特征表示方式采用何种模型来构建明显分层机制等等此类问题也是面向自然语言处理的深度学习在未来发展中需要重点研究的内容当然尽管目前来看面向自然语言的深度学习还存在着各种各样的问题但是总体而言现有深度学习的特征自动表示及分层抽象思想为自然语言处理提供了一种将特征表示和应用实现独立分开的可行方法这将使得在领域任务和语言之间的泛化迁移变得较为容易致谢本文作者衷心感谢苏州大学李正华博士邹博伟博士及王中卿博士对本文写作的热情帮助孙志军薛磊许阳明王正深度学习研究综述计算机应用研究化学报卷乔俊飞潘广源韩红桂一种连续型深度信念网的设计与应用自动化学报期奚雪峰等面向自然语言处理的深度学习研究耿杰范剑超初佳兰王洪玉基于深度协同稀疏编码网络的海洋浮筏图像目标识别自动化学报自动化学报卷期奚雪峰等面向自然语言处理的深度学习研究田渊栋阿法狗围棋系统的简要分析自动化学报奚雪峰苏州大学计算机科学与技术学院博士研究生主要研究方向为自然语言理解篇章分析自动问答周国栋苏州大学特聘教授主要研究方向为自然语言理解中文信息处理信息抽取本文通信作者