软件年第卷第期利用对中文词进行聚类的研究郑文超徐鹏北京邮电大学网络技术研究院北京摘要文本聚类在数据挖掘和机器学习中发挥着重要的作用该技术经过多年的发展已产生了一系列的理论成果本文在前人研究成果的基础上探索了一种新的中文聚类方法本文先提出了一种中文分词算法用来将中文文本分割成独立的词语再对处理后的语料使用工具集应用深度神经网络算法转化为对应的词向量最后将词向量之间的余弦距离定义为词之间的相似度通过使用聚类算法将获取的词向量进行聚类最终可以返回语料库中同输入词语语意最接近的词本文从网络上抓取了年的网络新闻数据应用上述方法进行了实验取得了不错的实验效果关键词数据挖掘聚类分词词向量神经网络中图分类号文献标识码本文著录格式郑文超徐鹏利用对中文词进行聚类的研究软件引言算法设计在自然语言处理领域中文词聚类算法是被深入研究的课词袋模型题由一些属性相近的词组成的词可以看成是单个词语到语意词袋模型是在自然语言处理和信息检索中的一种常见一般概念的映射词聚类算法对信息检索语音识别等诸多领模型它将文本中出现的词汇想象成放在袋子中的零散而独域都有使用价值针对英语的研究中各种词聚类算法可以分为立的物品这样一来一个袋子就能代表一份文档在这种三种第一以各种启发式量度表示聚类过程中的元素的距离第二以统计模型给出距离量度并给定聚类结果的类总数第三同样以统计模型给出距离量度但增加某种量度如困惑度的数模型中文本段落或者文档都被看作是无序的词汇集合忽略语法甚至是单词的顺序如果一个词在文档中出现不止一次这可能意味着包含该词是否出现在文档中所不能表达的某种信目增长和减少目前针对中文已有一些研究但计算结果似息在应用词袋模型之前我们需要先将一段完整的文本乎没有英语那么成功处理成单个词的序列即对文本进行分词本文针对这种现状本文将中文词语看成一系列独立词的中文分词词袋模型这种模型将语言中词语之间的关系做了简化由于中文词之间是不存在明显的间隔的我们设计了一种仅仅考虑词语的统计特性之后使用深度神经网络算法将词转方法将连续的中文文本切成一系列词组的方法现有的分词方化为维向量它在传统三层神经网络算法的基础上做了延伸法大致可以分为基于词典的匹配基于概率统计的方法和基于将网络从三层扩展到多层最后用算法计算对这些向量进行聚类本文使用这种方法应用工具集进行了测试最终取得了不错的结果语法规则的方法本文使用的分词方法将词典和基于统计的方法结合起来首先使用中文词库对原始文本进行过滤如果某作者简介郑文超男硕士研究生主要研究方向云计算信息检索通信联系人徐鹏男副教授主要研究方向下一代网络云计算郑文超等利用对中文词进行聚类的研究图神经网络模型个词汇在词典中被发现则直接作为单个词识别出来否则跳作为基础模型在模型下每个词的概率仅与它前边的转到如下算法每次从待处理的文本中按照从左向右的顺序个词有关更进一步的如果我们识别出多种不同的个词的组合然后根据下面的条消除歧假设前元词相互独立可以将概率展开义规则确定最佳的备选词组合选择备选词组合中的第个词神经网络算法作为次迭代的分词结果剩余的个词进行下一轮的分词运算本文采用的神经网络算法由在年提出采用这种办法的好处是为传统的前向最大匹配算法加入了上用了一个三层的神经网络来构建语言模型另外他还下文信息解决了其每次选词只考虑词本身而忽视上下文相假设这种语言遵循语言模型图关词的问题条规则包括最下方的就是前个词模型会根据这备选词组合的长度之和最大个词预测下一个词表示词所对应的词向量备选词组合的平均词长最大整个模型中使用的词向量存储于矩阵的维数为备选词组合的词长变化最小其中表示词表的大小表示词向量的维度到的备选词组合中单字词的出现频率统计值最高转化就是从矩阵中取出一行经过分词处理之后原始的文本会被处理成一系列由空格网络的输入层第一层是将隔开的单个词接下来可以使用神经网络算法构建语言模型这个向量首尾相接拼起来形成一个维的向量下在构建语言模型的过程中得到词向量面记为网络的隐藏层第二层如同普通的神经网络直接语言模型使用计算得到其中为一个偏置项初始化值随机使用作为激活函数网络的第三层输出层节点表示语言模型是借由一个机率分布指派概率给特定的字符串其中代表语言模型中的某个词语言模型一共有个节点下一个词为的未归一化概率最后使多用于自然语言处理如语音识别机器翻译词性标注句用激活函数将输出值归一化成概率最终的计算法分析和资讯检索由于字词与句子都是任意组合的长度因公式为此在训练过的语言模型中会出现未曾出现的字串资料稀疏的问式子中的是隐藏层到输出层的参数它是一个维的题也使得在语料库中估算字串的机率变得很困难本文在这矩阵整个模型的多数计算集中在和隐藏层的矩阵乘法中里采用近似平滑的元语法以避免零概率问题模型式子中还有一个矩阵这个矩阵包含了从输入层到输出层的郑文超等利用对中文词进行聚类的研究表同计算机最为接近的个词表同中国最为接近的个词接近度的词亚洲海外核工业电信日本电影家我国世界乒乓球队美国接近度的词应用微机编程传感嵌入式人工智能软件自动化软硬件电脑余弦距离余弦距离直连边一般将将置为最后使用随机梯度下降法把这个许多应用中最后应用算法对输入的词进行聚类模型优化当优化结束之后我们就从输出中获取了某个词将相同的词聚集在一起表表中列出了部分实验结果对应的词向量获取到词向量表之后我们就可以计算不同词结论向量直接的余弦距离作为不同词之间的距离在这之后基于统计的中文词分类在自然语言处理领域有着重要的应使用聚类算法将近似的词聚集到一起用机器自动生成的词类可以取代文法的词类在分类基础上聚类建立的语言模型可以应用于语音识别汉字智能输入等算法接受输入量然后将种数据对象划分为许多领域众所周知基于词的语言模型在自然语言处理的许组聚类以便使得所获得的聚类满足同一聚类中的对象相似度多方面取得了巨大的成功然而基于词的语言模型也存在着较高而不同聚类中的对象相似度较小聚类相似度是利用各许多的问题如参数空间庞大训练数据不足数据稀疏等聚类中对象的均值所获得一个中心对象来进行计算的词的分类可以在一定程度上解决上述问题本文使用算法基本步骤工具集找到了一种较为方便的方法对中文词进行聚类并且从个数据对象任意选择个对象作为初始聚类中心取得了不错的效果根据每个聚类对象的均值计算每个对象与这些中心对象的距离并根据最小距离重新对相应对象进行划分参考文献重新计算每个有变化聚类的均值曾元颍词袋模型计算标准测度函数当满足一定条件如函数收敛时则算法终止如果条件不满足则回到步骤实验过程及结果分析维基百科语言模型遵循以上过程本文对改算法的效果进行了验证语料库使用了搜狗实验室的互联网语料库这个语料库中主要是互联网上过往的新闻数据使用格式化的方式进行存储总数据量为本文使用了其中十分之一的文本数据将数据格式化之后进行清洗只保留文档的正文内容去除标点符号曾俊瑀王方回归再应用上文中提到的中文分词方法进行分词分词过程中使用的词典为搜狗细胞词库之后应用工具计算词向量将输入的文本转换为词向量数据写入文件是由的研究人员发布袁方周志勇宋鑫初始聚类中心优化的算法计的神经网络工具包它完成了上文中所说的连续词袋模型算机工程并且对这种方法进行了一些改进能够将输入文本中的词转化为一系列词向量这个工具集已经开始应用在自然语言处理的