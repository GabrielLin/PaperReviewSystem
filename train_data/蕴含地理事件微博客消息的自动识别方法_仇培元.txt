 18   7 
2016  7 

Vol.18, No.7
Jul., 2016

：,,,.[J].,2016,18(7):886-893. [ Chou P Y, Lu F,
Zhang H C, et al. 2016. Automatic identification method of micro-blog messages containing geographical events. Journal of Geo-information Science, 18(7):886-893. ] DOI:10.3724/SP.J.1047.2016.00886


 1,2，  1， 1*，  1,2
1.  ，
 100101；2. ，
 100101

Automatic Identification Method of Micro-blog Messages Containing Geographical Events
QIU Peiyuan1,2, LU Feng1, ZHANG Hengcai1* and YU Li1,2
1. State Key Lab of Resources and Environmental Information System, IGSNRR, CAS, Beijing 100101, China;
2. University of Chinese Academy of Sciences, Beijing 100101, China

Abstract: Micro-blogs usually contain abundant types of geographical event information, which could compensate for the shortcomings of traditional fixed point monitoring technologies and improve the quality of emergency response. Identify the micro-blog
messages that containing the geographical event information is the prerequisite for fully utilizing this data source. The trigger-based
and the supervised machine learning methods are commonly adopted to identify the event related texts. Comparatively, the supervised machine learning methods have better performance than the trigger-based ones for unrestricted texts. Unfortunately, the lack
of large-scale tagged corpuses cause the supervised machine learning methods cannot be implemented to identify the geographical
event related messages. In this paper, we propose an automatic method for recognizing micro-blogs that are related to geographical
events based on the topic model and word vector. This method could achieve a satisfying identification result by increasing the corpus scale rapidly. Firstly, the topic model is capable to extract topics from documents. Thus, the web pages fetched by a search engine are grouped by the topics, and the corpus is obtained after combining the pages under the topics that are related to geographical
events through judging their keywords of each topic. Secondly, the distributed representation word vector model is introduced to
compensate the lack of context in the micro-blog, which is caused by its character count limit. These word vectors are integrated into the context semantic information from corpus training during the vector generation process. Thirdly, the correlation between the
micro-blog message and the given geographical event is calculated and applied to determine whether this message contains the specified geographical event or not. In addition, some heuristic rules are used to correct the error correlations of very short messages. Experiments where the rainstorm is set as the targeting geographical event are conducted to validate the feasibility of this approach.
The test conducted on Sina topic micro-blog shows that the F-1 of identification reaches 71.41% and is 10.79% higher than the traditional machine learning algorithm based on Support Vector Machine. Based on the premise that the precision loss is limited, the
recall rate would rise with an increase in the corpus scale. The recognition precision could achieve 60% in a dataset containing five
million micro-blog texts that simulating the actual data content and environment. These recognized event related micro-blogs could
be used to extract detailed information elements in the future.
Key words: micro-blog; geographical event; event text identification; topic model; word vector
*Corresponding author: ZHANG Hengcai, E-mail: zhanghc@lreis.ac.cn

：，，。，

：2015-09-07；：2015-11-03.
：“863”(2013AA120305)；
（41401460）。
：(1986-)，，，。E-mail: qiupy@lreis.ac.cn
*：(1985-)，，，，
。
E-mail: zhanghc@lreis.ac.cn

7

 ：

887

，。，
，。
，，。，，
，。
，， F-1 
 71.41%， SVM  10.79%。 500 
 60%。
：；
；
；
；


1 
，，
，
，“
”、
“721 ”、。
、、
。，
，
，。，
、、、
、[1]，
。，
，
，
。，
，
，
。

，
。，
，
。，，
。

：
；
，，
，[2]、
[3]、KNN[4]、[5-6]。

，
。，

 [7]。，
，
，
[4,8][2,9]。
，
，，
。，
，
，、
 [10-11]、
[12-13][14]。
，
[15]，
。
，
，
，

。

2 


。，
，、
[16]，
。，
，
。

。，
，，
，，
。

       

888

2016 

，
，


 [18]。LDA  Blei  [19]，

。，
[17]，

（Probabilistic Latent Semantic

，
、

。，

。“

，
，


”， 2  Dirich-

，
。：
（1）

let 。，



 LDA（Hierarchical LDA，HLDA）

；
（2）；
（3）
，

。HLDA  Blei  LDA 

。 1 。

， CRP（Chinese Restaurant Process）

Indexing，PLSI）
，

，

，
[20]。
：，
；， HLDA 
；，
，
，
，
。 2 ，
。，
，，；
，
。

 1 
Fig.1 Flowchart of the identification method

2.1 

，。

，、，
。
，
，，
。
，
，
。，
，
，。，
（Latent Dirichlet Allocation，
LDA）
，

 2 
Fig.2 An example of topic extraction and correlation
interpretation from the candidate corpuses about rainstorm

2.2 

，
。，
，
。
，
。（Distributed Representa-

7

 ：

889

tion），

 topic 

，
。Bengio 

rel event ( text,topic) （2）。

（Neural Network Language Model，NNLM） 
 [21]，
。，Mikolov  CBOW  Skip-gram 
[22] NNLM ，
。，
Skip-gram 
，
。 3 ，
 10 。

 3 
Fig.3 An example of related words computation
based on the word vector

2.3 
，

。
2.3.1 
，
，
，
。，
。

[

 w i  w j  wi = vec1i ,vec2i ,…,

[

]

]

vec ,…,vec ，w j = vec ,vec ,…,vec ,…,vec ，
k
i

n
i

1
j

2
j

k
j

n
j

relword(wi,wj)（1）。

∑vec ∙vec
n

(

)

rel word w i ,w j =

k
i

k=1

∑( vec )

æ
ç

n

èk=1

k
i

2

k
j

2
öæ n
k ö
÷∙ç∑ vec j ÷
ø èk=1
ø

( )

（1）

 text ={w1,w 2 ,…,w k ,…,w n} ，

 dic =(keyw1,keyw 2 ,…,keyw g ,…,keyw m)，

n

rel event ( text,topic) =

max(rel word (w k ,keyw g ))

∑1 ≤ g ≤ m
k=1

（2）

n

2.3.2 
（1）
，
，，
，“”、
“”。，
，
，，
。
，
，
（“”、
“ ”
），
。
 [23]，，“-”
、
“-”。

（http://www.datatang.com/data/44588）    。
 3000 ，
、、、、。
（what）（how），
，
， 10 ，
（），
 1 。
 1 
Tab.1 Some instances of speech patterns




vn

327

nv

170

nn

72

mqn

19

nmq

18

ndv

16

an

16

vmn

15

na

11

vbn

10

mnpv

10

vun

10

：a ；b ；d ；m ；n ；p
；q ；u ；v 

       

890

（2）
、
。
，
。，
。
，，
，

2016 

（https://code.google.com/p/word2vec/）。
（P）、（R） F- 3 
。3 
（3）-（5）。

P=
（3）


R=
（4）


。

F - =

，
，

。
2.3.3 

[0,1]，
，
。，
，
，
。

3 
3.1 
，
。，
“”、
“ ”、
“ ”、
“ 
” 24 ，、
， 10 041 。
：
（1）。“#
#”、
“##”、
“##”、
“#

(β

2

+ 1) × P × R

( β ∙P ) + R
2

（5）

F-
。，β 
，
1，
（（6）
）。
F -1 = 2 × P × R
（6）
P+R
，
， β = 0.5 
F-（（7）
）。

F -0.5 = 1.25 × P × R
0.25 × P + R

（7）

3.2 
3.2.1 

。
            0.505，    
P=69.71% ，R=73.20% ，F- 1  =71.41% ，F- 0.5  =
70.38%。[0.1,0.8]
， 4 ， F0.5 。
 4 ，F-0.5  F-1 
 71% 74%，
 F-0.5 ，F-1 。
，

#”、
“##”、
“##”、
“#
#”7 ，
，。
 500 
；
（2）500 。
， 4 993 581 
。 Java ，，
 NLPIR 2015 （http://ictclas.nlpir.org/），
HLDA  Mallet （http://mallet.cs.umass.
edu/；https://github.com/chyikwei/topicModels），skip-

 4 

gram  Google word2vec 

Fig.4 Identification results under different thresholds

7

 ：

891

，

5%， 20%， F-1  F-0.5 

，
。
3.2.2 

，，

，

。
（Support Vector Machine，
SVM） ，
[8]、
[24]-[26]
[24]

，
：
、

、
、
、
。， 5 ，4 
 SVM ， 1 
，，
 2 。

Tab.2 Performance of the identification approach for
micro-blogs containing rainstorm events
/（%） /（%） F-1 /（%） F-0.5 /（%）



69.71

73.20

71.41

70.38

SVM 

68.48

54.88

60.62

65.00

，
SVM ， F-1  F-0.5 。
，
，
。，
，
。。
，，
 2000、4000、6000、8000 
，
 5 。
，
，

 5 
Fig.5 Identification results using different scales of
candidate corpuses

 500 
，
。 2906 ，
 500 ，
 307 ， 61.40%。
 F-，
，，
。
，


 2 



。
3.2.3 

，
、

。
，。
，
。
3.3 
（1），
，
。，
 51，
 10 041，，
。，
，，
。
（2），
。，
，
（、、），
。
，，
，。
[27]、[28][29]，
 60%~70%，

。
（3），
。，

。

       

892

2016 

，，

(References)：

，

[ 1 ] ,,.

，

[J].,2011(5):5-10. [ Wang M, Ding Y, Bai

[30]，

L. Social media development status and trend analysis[J].

，。，
，
，

。，，

Information and Communications Technologies, 2011,5:510. ]
[ 2 ] Li R, Tao X, Tang L, et al. Using maximum entropy model for Chinese text categorization[A]. In: Yu J X, Lin X,
Lu H, et al(eds.). Advanced Web Technologies and Applications[C]. Springer-Verlag, 2004:578-587.



[ 3 ] Sankaranarayanan J, Samet H, Teitler B E, et al. Twitter

，

Stand: News in tweets[C]. Proceedings of the 17th ACM

。

SIGSPATIAL International Conference on Advances in

（4），
 xml 、
，。

Geographic Information Systems, 2009:1-10.
[ 4 ] Jiang S, Pang G, Wu M, et al. An improved K- nearestneighbor algorithm for text categorization[J]. Expert Systems with Applications, 2012,39(1):1503-1509.

，

[ 5 ] Kumar M A, Gopal M. A comparison study on multiple

，

binary-class SVM methods for unilabel text categorization

。，

[J]. Pattern Recognition Letters, 2010,31(11):1437-1444.

，

[ 6 ] Sakaki T, Okazaki M, Matsuo Y. Earthquake shakes Twit-

，，

ter users: real- time event detection by social sensors[C].

。，

Proceedings of the 19th International Conference on World

。

4 

Wide Web (WWW’
10), ACM, 2010:851-860.
[ 7 ] ,,,.[J].
,2011,25(2):15-20. [ Ding X, Song F, Qin
B, et al. Research on typical event extraction method in
the field of music[J]. Journal of Chinese Information Pro-



cessing, 2011,25(2):15-20. ]

，

[ 8 ] Miwa M, Sætre R, Kim J-D, et al. Event extraction with

，，

complex event classification using rich features[J]. Jour-

。，

nal of Bioinformatics and Computational Biology, 2010,8

。，

，

(1):131-146.
[ 9 ] Zhao L, Chen F, Dai J, et al. Unsupervised spatial event
detection in targeted domains with applications to civil
unrest modeling[J]. PLoS ONE, 2014,9(10):e110206.

。，

[10] Wang W, Stewart K. Spatiotemporal and semantic infor-

，

mation extraction from Web news reports about natural

 F-1  71.41%，

hazards[J]. Computers, Environment and Urban Systems,

SVM  10.79%。
 500 
 60%。
，
，
。，、

2015,50:30-40.
[11] Murthy D, Longwell S A. Twitter and disasters[J]. Information, Communication & Society, 2013,16(6):837-855.
[12] ,,. D-S 
[J].,2015,29(2):170178. [ Zhang H, Lu F, Qiu P. Extracting traffic information from micro- blog based on D- S evidence theory[J].



Journal of Chinese Information Processing, 2015,29(2):

。

170-178. ]

7

 ：

[13] ,,.

893

search, 2003,3:1137-1155.

[J].,2015,17(4):

[22] Mikolov T, Chen K, Corrado G, et al. Efficient estimation

416-422. [ Qiu P, Zhang H, Lu F. A pattern matching meth-

of word representations in vector space[C]. Proceedings

od for extracting road traffic information from internet

of Workshop at International Conference on Learning

texts[J]. Journal of Geo-Information Science, 2015,17(4):

Representations, 2013:1-12.

416-422. ]

[23] ,.[J].

[14] ,,,.

,2009,11(2):100-112,189. [ Liu T, Ma, J. Theories

[J].,2013,15(5):625-634. [ Wang

and methods of Chinese automatic syntactic parsing: A

S, Ji J, Zhang, X, et al. Change detection of geographic

critical survey[J]. Contemporary Linguistics, 2009,11(2):

features based on web pages[J]. Journal of Geo-Information Science, 2013,15(5):625-634. ]
[15] .
[D].:,2013. [ Zhang C. Interpretation

100-112,189. ]
[24] Naughton M, Stokes N, Carthy J. Sentence- level event
classification in unstructured texts[J]. Information Retrieval, 2009,13(2):132-156.

of event spatio-temporal and attribute information in Chi-

[25] ,,,.

nese text[D]. Nanjing: Nanjing Normal University, 2013. ]

[J].,2011,38(8):232-235. [ Xu X

[16] ,,,.

Y, Li B C, Zhang X F, et al. News text event extraction

          [J].   ,2011,40(4):502-

driven by event sample[J]. Computer Science, 2011,38(8):

508. [ Liu J, Li B, Shi L, et al. An automated retrieval

232-235. ]

method of geo-spatial event information based on ontolo-

[26] ,,,.

gy[J]. Acta Geodaetica et Cartographica Sinica, 2011,40

[J].,2010,4(1):34-44. [ Xu

(4):502-508. ]

H, Chen J, Zhou C, et al. Research on event type identifi-

[17] ,,.[J].
,2012,26(4):21-27,42. [ Zhang J, Xia Y, Yao J.
A review towards microtext processing[J]. Journal of Chi-

cation for Chinese event extraction[J]. Mind and Computation, 2010,4(1):34-44. ]
[27] Li C, Weng J, He Q, et al. TwiNER: Named entity recog-

nese Information Processing, 2012,26(4):21-27,42. ]

nition in targeted twitter stream[C]. Proceedings of the

[18] ,.[J].

35th International ACM SIGIR Conference on Research

,2011,34(8):1423-1436. [ Xu G, Wang H. The de-

and Development in Information Retrieval, 2012:721-730.

velopment of topic models in natural language processing

[28] Zhou D, Chen L, He Y. An unsupervised framework of ex-

[J]. Chinese Journal of Computers, 2011,34(8):1423-1436. ]

ploring events on twitter: filtering, extraction and catego-

[19] Blei D M, Ng A Y, Jordan M I. Latent dirichl et al. loca-

rization[C]. Proceedings of the 29 AAAI Conference on

tion[J]. Journal of Machine Learning Research, 2003,3:
993-1022.

Artificial Intelligence, 2015:2468-2474.
[29] Wu F, Weld D S. Open information extraction using Wiki-

[20] Blei D M, Griffiths T L, Jordan M I, et al. Hierarchical

pedia[C]. Proceedings of the 48th Annual Meeting of the

topic models and the nested Chinese restaurant process

Association for Computational Linguistics. 2010:118-127.

[A]. In: Advances in Neural Information Processing Sys-

[30] Weiss G M, Provost F. Learning when training data are

tems[M]. Cambridge, MA: MIT Press, 2004.
[21] Bengio Y, Ducharme R, Vincent P, et al. A neural probabilistic language model[J]. Journal of Machine Learning Re-

costly: The effect of class distribution on tree induction
[J]. Journal of Artificial Intelligence Research, 2002,19:
315-354.